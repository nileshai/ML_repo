{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# import bert\n",
    "# from bert import BertModelLayer\n",
    "import functools\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow_text as tftext\n",
    "import sentencepiece as spm\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "# from absl import logging\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "sys.path.extend([\"/space/users/jgeorge/git/tensorflow_experiments/tf2.3/models\"])\n",
    "\n",
    "# pylint: disable=g-import-not-at-top,redefined-outer-name,reimported\n",
    "# from official.modeling import model_training_utils\n",
    "\n",
    "from official.nlp.modeling.models import bert_classifier, bert_pretrainer\n",
    "# from official.nlp.modeling.models.bert_classifier import BertClassifier\n",
    "# from official.nlp.modeling.models.bert_pretrainer import BertPretrainer\n",
    "# from official.nlp import bert_modeling as modeling\n",
    "# from official.nlp import bert_models\n",
    "from official.nlp import optimization\n",
    "from official.nlp.bert import common_flags\n",
    "from official.nlp.bert import input_pipeline\n",
    "from official.nlp.bert import model_saving_utils\n",
    "from official.utils.misc import distribution_utils\n",
    "from official.utils.misc import keras_utils\n",
    "from official.nlp.bert import tokenization\n",
    "\n",
    "from official.nlp.albert import configs as albert_configs\n",
    "from official.nlp.bert import run_classifier as run_classifier_bert\n",
    "\n",
    "# from tensorflow.python.keras.engine import network\n",
    "\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging info [<StreamHandler stdout (NOTSET)>]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/13733552/logger-configuration-to-log-to-file-and-print-to-stdout\n",
    "log_filepath = \"/var/extra/users/jgeorge/tf2.0/input/dish/multi_logs.txt\"\n",
    "file_handler = logging.handlers.RotatingFileHandler(log_filepath, maxBytes=(1048576*5), backupCount=7)\n",
    "# file_handler = logging.FileHandler()\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "# logging.get_absl_handler().use_absl_log_file('absl_logging', os.path.join(main_data_folder,'Smithfield/AlwaysOn/logs'))\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "rootLogger = logging.getLogger()\n",
    "# customLogger = logging.getLogger('TestControl')\n",
    "rootLogger.setLevel(logging.INFO)\n",
    "# removing existing loggers\n",
    "while(len(rootLogger.handlers)>0):\n",
    "    rootLogger.removeHandler(rootLogger.handlers[0])\n",
    "\n",
    "# uncomment to add logs to a file    \n",
    "# rootLogger.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "rootLogger.addHandler(stream_handler)\n",
    "print('logging info',rootLogger.handlers )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##restricting no of gpus\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "device_to_use = gpus[3]\n",
    "tf.config.experimental.set_memory_growth(device_to_use,True)\n",
    "tf.config.experimental.set_visible_devices(device_to_use, 'GPU')\n",
    "print(tf.config.get_visible_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##setting direcory for downloading tfhub modules\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = '/space/engineering/tfhub_modules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_data_path='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/dishDataJan17.txt'\n",
    "df = pd.read_csv(dish_data_path,sep='\\t',header=None,names=['filename','text','granular_intent','ru_intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>granular_intent</th>\n",
       "      <th>ru_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INT-sv1appis14-1504137880316-305603_4567</td>\n",
       "      <td>can you send my bill to my mail?</td>\n",
       "      <td>billing-preferences</td>\n",
       "      <td>billing-preferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INT-va1appis15-1504373018548-41332</td>\n",
       "      <td>My Wally receiver has lost Satellite signal in...</td>\n",
       "      <td>comp_part_signal_loss-issue</td>\n",
       "      <td>comp_part_signal_loss-issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INT-sv1appis12-1503954587819-263368</td>\n",
       "      <td>I need a payment extension so i don't get my s...</td>\n",
       "      <td>payment_extension-request</td>\n",
       "      <td>payment_extension-request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed8e9b1-10f5-438d-c409-e616c3ff9ede</td>\n",
       "      <td>how can i find my local channels. it seems i d...</td>\n",
       "      <td>channel_package-issue</td>\n",
       "      <td>channel_package-issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INT-sv1appis13-1504099917638-293735</td>\n",
       "      <td>Wanted to speak with someone about my bill</td>\n",
       "      <td>representative-request</td>\n",
       "      <td>representative-request</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  \\\n",
       "0  INT-sv1appis14-1504137880316-305603_4567   \n",
       "1        INT-va1appis15-1504373018548-41332   \n",
       "2       INT-sv1appis12-1503954587819-263368   \n",
       "3      8ed8e9b1-10f5-438d-c409-e616c3ff9ede   \n",
       "4       INT-sv1appis13-1504099917638-293735   \n",
       "\n",
       "                                                text  \\\n",
       "0                   can you send my bill to my mail?   \n",
       "1  My Wally receiver has lost Satellite signal in...   \n",
       "2  I need a payment extension so i don't get my s...   \n",
       "3  how can i find my local channels. it seems i d...   \n",
       "4         Wanted to speak with someone about my bill   \n",
       "\n",
       "               granular_intent                    ru_intent  \n",
       "0          billing-preferences          billing-preferences  \n",
       "1  comp_part_signal_loss-issue  comp_part_signal_loss-issue  \n",
       "2    payment_extension-request    payment_extension-request  \n",
       "3        channel_package-issue        channel_package-issue  \n",
       "4       representative-request       representative-request  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_val,y_train,y_val = train_test_split(df,df['granular_intent'],train_size=0.9,random_state=42,stratify=df['granular_intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_exp_folder = '/space/users/jgeorge/projects/k/tensorflow2-question-answering/input/dish/data/jan17_2020/'\n",
    "main_exp_folder = '/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/var/extra/users/jgeorge/tf2.0/output/dish/models/bert_multilingual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_csv_file='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/train.txt'\n",
    "eval_csv_file='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/val.txt'\n",
    "\n",
    "df_train.to_csv(train_csv_file,sep='\\t',header=False,index=False)\n",
    "df_val.to_csv(eval_csv_file,sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a file with list of intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_file = '/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/intentlist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(intent_file,'w',encoding='utf-8') as out_f:\n",
    "    for intent in sorted(df_train['granular_intent'].unique()):\n",
    "        out_f.write(intent+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list = []\n",
    "with open(intent_file,'r') as inp_f:\n",
    "    for intent in inp_f:\n",
    "        intent_list.append(intent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meta_data = {\n",
    "    'max_seq_length':128,\n",
    "    'num_labels':len(intent_list),\n",
    "    'train_data_size':len(df_train),\n",
    "    'eval_data_size':len(df_val),\n",
    "    'default_label':'other-other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 128,\n",
       " 'num_labels': 142,\n",
       " 'train_data_size': 23146,\n",
       " 'eval_data_size': 2572,\n",
       " 'default_label': 'other-other'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meta_path = os.path.join(main_exp_folder,'input_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing metadata file\n",
    "with open(input_meta_path,'w',encoding='utf-8') as jf:\n",
    "    jf.write(json.dumps(input_meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading metadata file\n",
    "with open(input_meta_path,'r',encoding='utf-8') as jf:\n",
    "#     input_meta_data = json.loads(jf.read())\n",
    "    input_meta_data = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing & feeding into graph\n",
    "We will be reading the regular text file as input.   \n",
    "If we want to save time during training, we could tokenize the data upfront & store it as tfrecords    \n",
    "\n",
    "Writing as tfrecord is not necessary, but it is a more optimized file format for reading into \n",
    "tf.data api (you can even base your tf dataset on a textfile or even a python iterator)\n",
    "Also it's not necessary to use tf.data apis but this is much more optimized, like preloading data into gpu memory & optimization required if you are running across systems & all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=128\n",
    "bert_config = {}\n",
    "bert_config[\"initializer_range\"] = 0.02\n",
    "# we will use this for the Dropout probability between bert layer & final Dense layer\n",
    "bert_config[\"hidden_dropout_prob\"]=0.2\n",
    "num_labels = input_meta_data['num_labels']\n",
    "default_label = input_meta_data['default_label']\n",
    "delimiter = '\\t'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/var/extra/users/jgeorge/tf2.0/output/dish/models/bert_multilingual/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Dataset creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer to convert label to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelToId(tf.keras.layers.Layer):\n",
    "#     def __init__(self,model_proto):\n",
    "    def __init__(self,filepath,default_index,*args,**kwargs):\n",
    "        \"\"\" \n",
    "        filepath - path to the text file with 1 label per line\n",
    "        \"\"\"\n",
    "        super(LabelToId, self).__init__(trainable=False,dtype=tf.string,*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "        self.default_index=default_index\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        # need to convert label name to label index. So keeping line no as value & whole text line as key\n",
    "        # issue with using table lookup (both file based & key value tensorbased) in tf2.2 (tf2.x) - https://github.com/tensorflow/tensorflow/issues/38305\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.TextFileInitializer(self.filepath,\n",
    "                                          key_dtype=tf.string,key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "                                     value_dtype=tf.int64,value_index=tf.lookup.TextFileIndex.LINE_NUMBER),self.default_index)\n",
    "        self.built=True\n",
    "        \n",
    "    def call(self, input_index):\n",
    "        word_ids = self.table.lookup(input_index)\n",
    "        return word_ids\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(LabelToId, self).get_config()\n",
    "#         config.update({'filepath': self.filepath})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_input_dataset(file_path, default_label, label_path, batch_size=16, delimiter = '\\t', is_training=True):\n",
    "    dataset = tf.data.experimental.CsvDataset(file_path, record_defaults=[tf.constant(''),tf.constant('MISSING')],\n",
    "                                                   header=False,field_delim=delimiter,use_quote_delim=True,\n",
    "                                                   select_cols=[1,2])\n",
    "    label_dict = {}\n",
    "    with open(label_path) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            label_dict[line.strip()] = i\n",
    "        \n",
    "    default_index = label_dict.get(default_label)\n",
    "    label_to_id = LabelToId(intent_file,default_index)\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(100)\n",
    "        dataset = dataset.repeat()\n",
    "    # batching data\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # updating only label, text will be processed as part of training graph\n",
    "    dataset = dataset.map(lambda text, label: (text, label_to_id(label)),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a train dataset just to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16,), dtype=string, numpy=\n",
      "array([b'I would like to know if there any discounts available',\n",
      "       b'where is the channel line up', b'I would like to update my mail',\n",
      "       b'trying to change autopay', b'Removing a ppv',\n",
      "       b'I need to cancel my appointment... For today',\n",
      "       b'Smart package with heartland and my $3 Starz',\n",
      "       b'can I get my lineup of channels',\n",
      "       b'Get an extenstion and take off add ons',\n",
      "       b'I want my cable to be taken off for good',\n",
      "       b'got my new remote from dish yesterday. have not had any luck getting it to sync with my receiver. i have went thru both versions of trying to get the remote to sync and have had no luck.',\n",
      "       b'We have an appointment for tomorrow and want to know if we can add another room for no additional charge. Direct has an offer for 4 rooms included in their package at $50.00 per month 150 channels',\n",
      "       b'I need to buy a remote', b'need help setting my remote with tv ',\n",
      "       b'DO YOU OFFER A PHONE DEAL WITH DISH',\n",
      "       b'How do I enable the 2nd tv'], dtype=object)>, <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
      "array([106,  29,   0,  20,  99,  11,  36,  29,  97,   1, 128, 106, 127,\n",
      "       128, 106,  55])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-1cb11528cf86>:18: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
      "  dataset = dataset.map(lambda text, label: (text, label_to_id(label)),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_dataset = get_input_dataset(train_csv_file, default_label, intent_file, batch_size, delimiter,True)\n",
    "# evaluation_dataset = get_input_dataset(eval_csv_file, default_label, intent_file, batch_size, delimiter,False)\n",
    "for line in training_dataset.take(1):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# bert_config_dict = {\n",
    "#     \"hidden_dropout_prob\":0,\n",
    "#     'initializer_range': 0.02\n",
    "# }\n",
    "# bert_config = albert_configs.AlbertConfig.from_dict(bert_config_dict)\n",
    "\n",
    "# in some cases it might be inside assets folder\n",
    "bert_config_file = os.path.join(bert_model_dir,'albert_config.json')\n",
    "\n",
    "# bert_config = modeling.AlbertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "bert_config = albert_configs.AlbertConfig.from_json_file(bert_config_file)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert_config.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert_config = {'vocab_size': 30000,\n",
    " 'hidden_size': 1024,\n",
    " 'num_hidden_layers': 24,\n",
    " 'num_attention_heads': 16,\n",
    " 'hidden_act': 'gelu',\n",
    " 'intermediate_size': 4096,\n",
    " 'hidden_dropout_prob': 0,\n",
    " 'attention_probs_dropout_prob': 0,\n",
    " 'max_position_embeddings': 512,\n",
    " 'type_vocab_size': 2,\n",
    " 'initializer_range': 0.02,\n",
    " 'backward_compatible': True,\n",
    " 'embedding_size': 128,\n",
    " 'num_hidden_groups': 1,\n",
    " 'net_structure_type': 0,\n",
    " 'gap_size': 0,\n",
    " 'num_memory_blocks': 0,\n",
    " 'inner_group_num': 1,\n",
    " 'down_scale_factor': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model code, graph creation\n",
    "This section is the core logic of the model, here we are using tensorflow hub url for albert model. Using hub simplifies the code a lot      \n",
    "It's a slightly simplied version of official bert code, that code have functionality to load a non hub model. \n",
    "#### refer to models/official/nlp/bert/run_classifier.py\n",
    "Since in this notebook we are only using one gpu, we can even ignore the strategy part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = distribution_utils.get_distribution_strategy('mirrored',num_gpus=1)\n",
    "\n",
    "# strategy = tf.distribute.OneDeviceStrategy(\"device:GPU:2\")\n",
    "#since devices to use is set to 2 already, only 1 device is visible which is 0\n",
    "strategy = tf.distribute.OneDeviceStrategy(\"device:GPU:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary tryouts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.utils.register_keras_serializable()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###custom code from saved model folder (not hub url)\n",
    "# How does it differentiate between the bert vs albert - models/official/nlp/bert/bert_models.py\n",
    "  if isinstance(bert_config, albert_configs.AlbertConfig):  \n",
    "        kwargs['embedding_width'] = bert_config.embedding_size\n",
    "    return networks.AlbertTransformerEncoder(**kwargs)                                                                                                                 else:\n",
    "    assert isinstance(bert_config, configs.BertConfig)                                                                                                                   return networks.TransformerEncoder(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence piece encoding & other preprocessing for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /space/engineering/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocessor_url = \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1\"\n",
    "bert_preprocessor_loaded = hub.load(bert_preprocessor_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert model laoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilingual bert hub url\n",
    "bert_hub_url = \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# download from link given in https://github.com/tensorflow/models/tree/master/official/nlp/albert\n",
    "# specifically https://storage.googleapis.com/cloud-tpu-checkpoints/albert/checkpoints/albert_v2_large.tar.gz\n",
    "# this is not required if we are just using tensorflow hub, since the hub module didn't have a detailed config, \n",
    "# will load the config from this folder for reference  \n",
    "bert_model_dir='/space/engineering/pretrained_models/albert/albert_large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the used sentence piece model from the hub module, \n",
    "it will be present in the assests folder of the downloaded albert model\n",
    "Since we are using hub here & not directly downloading it, the path can be fetched from hub layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_path /space/engineering/tfhub_modules/67c5e34716a3dd645ca3507fac096a07b2c8607d/assets/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "bert_hub_loaded = hub.load(bert_hub_url)\n",
    "vocab_path = bert_hub_loaded.vocab_file.asset_path.numpy().decode('utf-8')\n",
    "print(f'vocab_path {vocab_path}')\n",
    "# or if you are using hub.KeraLayer\n",
    "# bert_model = hub.KerasLayer(bert_hub_url,trainable=True)\n",
    "# sentencepiece_path = bert_model.resolved_object.sp_model_file.asset_path.numpy()\n",
    "\n",
    "##if you have directly downloaded the model you could do this\n",
    "# sentencepiece_path = os.path.join(model_dir, \"assets\", \"30k-clean.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the graph\n",
    "#### trying out the multilingual bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tf.keras.layers.Input(shape=(), dtype=tf.string,name='input_text')\n",
    "tokenize = hub.KerasLayer(bert_preprocessor_loaded.tokenize)\n",
    "tokenized_inputs = [tokenize(input_text)] # bert can handle 2 input_texts (segments)\n",
    " \n",
    "bert_pack_inputs = hub.KerasLayer(bert_preprocessor_loaded.bert_pack_inputs,arguments=dict(seq_length=max_seq_length))\n",
    "encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "encoder = hub.KerasLayer(bert_hub_url,trainable=True)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n",
    "bert_output = tf.keras.layers.Dropout(rate=bert_config[\"hidden_dropout_prob\"])(pooled_output) \n",
    "initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config[\"initializer_range\"])\n",
    "output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(bert_output)\n",
    "    \n",
    "# model = tf.keras.Model(inputs={'input_ids':input_ids,\n",
    "#                                  'input_mask':input_mask,\n",
    "#                                  'segment_ids':segment_ids},\n",
    "#                          outputs=output),bert_model\n",
    "\n",
    "model = tf.keras.Model(inputs=input_text,\n",
    "                         outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor 'keras_layer_1/StatefulPartitionedCall:2' shape=(None, None) dtype=int32>,\n",
       " 'input_mask': <tf.Tensor 'keras_layer_1/StatefulPartitionedCall:0' shape=(None, None) dtype=int32>,\n",
       " 'input_type_ids': <tf.Tensor 'keras_layer_1/StatefulPartitionedCall:1' shape=(None, None) dtype=int32>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### writing a function to get training model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilingual_bert(bert_config,num_labels,max_seq_length,model_hub_url,preprocessor_hub_url):\n",
    "    bert_preprocessor_loaded = hub.load(preprocessor_hub_url)\n",
    "    input_text = tf.keras.layers.Input(shape=(), dtype=tf.string,name='input_text')\n",
    "    tokenize = hub.KerasLayer(bert_preprocessor_loaded.tokenize)\n",
    "    tokenized_inputs = [tokenize(input_text)] # bert can handle 2 input_texts (segments)\n",
    "    \n",
    "    bert_pack_inputs = hub.KerasLayer(bert_preprocessor_loaded.bert_pack_inputs,arguments=dict(seq_length=max_seq_length))\n",
    "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "    encoder = hub.KerasLayer(model_hub_url,trainable=True)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "    sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n",
    "    bert_output = tf.keras.layers.Dropout(rate=bert_config[\"hidden_dropout_prob\"])(pooled_output) \n",
    "    initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config[\"initializer_range\"])\n",
    "    output_dense = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(bert_output)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_text,outputs=output_dense),encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the classification model description/summary\n",
    "We are calling get_albert_model here just to print out model summary, otherwise we call it internally\n",
    "in another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_model,core_bert_model = get_multilingual_bert(bert_config=bert_config,\n",
    "                                                              num_labels=input_meta_data['num_labels'],\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               model_hub_url=bert_hub_url,\n",
    "                                                                preprocessor_hub_url=bert_preprocessor_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_text (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_3 (KerasLayer)      (None, None, None)   0           input_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_4 (KerasLayer)      {'input_word_ids': ( 0           keras_layer_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_5 (KerasLayer)      {'default': (None, 7 177853441   keras_layer_4[0][0]              \n",
      "                                                                 keras_layer_4[0][1]              \n",
      "                                                                 keras_layer_4[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           keras_layer_5[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 142)          109198      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 177,962,639\n",
      "Trainable params: 177,962,638\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classification_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'keras_layer_5',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'handle': 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_bert_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss function,  metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_fn(num_classes, loss_factor=1.0):\n",
    "    \"\"\"Gets the classification loss function.\"\"\"\n",
    "\n",
    "    def classification_loss_fn(labels, logits):\n",
    "        \"\"\"Classification loss.\"\"\"\n",
    "        labels = tf.squeeze(labels)\n",
    "#         log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "#         one_hot_labels = tf.one_hot(\n",
    "#             tf.cast(labels, dtype=tf.int32), depth=num_classes, dtype=tf.float32)\n",
    "#         per_example_loss = -tf.reduce_sum(\n",
    "#             tf.cast(one_hot_labels, dtype=tf.float32) * probs, axis=-1)\n",
    "        per_example_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits=logits)\n",
    "        #batch loss\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        loss *= loss_factor\n",
    "        return loss\n",
    "    return classification_loss_fn  \n",
    "\n",
    "\n",
    "def metric_fn():\n",
    "    return tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy',dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for running training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_keras_compile_fit(model_dir,\n",
    "                          strategy,\n",
    "                          model_fn,\n",
    "                          training_dataset,\n",
    "                          evaluation_dataset,\n",
    "                          loss_fn,\n",
    "                          metric_fn,\n",
    "                          init_checkpoint,\n",
    "                          epochs,\n",
    "                          steps_per_epoch,\n",
    "                          steps_per_loop,\n",
    "                          eval_steps,\n",
    "                          custom_callbacks=None):\n",
    "    \"\"\"Runs BERT classifier model using Keras compile/fit API.\"\"\"\n",
    "    ###slightly simplied version of official bert code \n",
    "    # refer to models/official/nlp/bert/run_classifier.py -   function run_keras_compile_fit\n",
    "    # if you running on a single gpu or on just cpu this strategy is not necessary\n",
    "    with strategy.scope():\n",
    "        #sub_model is the original bert\n",
    "        classification_model, sub_model = model_fn()\n",
    "        optimizer = classification_model.optimizer\n",
    "        \n",
    "        # this is not required for the hub version of the model, this restore method is trying to restor values,\n",
    "        # from a saved bert model (since we have only provided the sub_model to checkpoint)\n",
    "        # Let's saying we stopped training at some point & want to continue from that point next time,\n",
    "        # here we can instead load our classification_model & init_checkpoint can be our previous saved checkpoint file\n",
    "        if init_checkpoint:\n",
    "            checkpoint = tf.train.Checkpoint(model=sub_model)\n",
    "#             checkpoint = tf.train.Checkpoint(model=classification_model)\n",
    "            checkpoint.restore(init_checkpoint).assert_existing_objects_matched()\n",
    "#             checkpoint.restore(init_checkpoint).expect_partial()\n",
    "\n",
    "        classification_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=[metric_fn()])\n",
    "    #     ,experimental_steps_per_execution=steps_per_loop)\n",
    "\n",
    "        summary_dir = os.path.join(model_dir, 'summaries')\n",
    "        summary_callback = tf.keras.callbacks.TensorBoard(summary_dir, profile_batch='10,20')\n",
    "        checkpoint_path = os.path.join(model_dir, 'checkpoint')\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_path, save_best_only=True, save_weights_only=True)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "\n",
    "        if custom_callbacks is not None:\n",
    "            custom_callbacks += [summary_callback, checkpoint_callback, early_stopping]\n",
    "        else:\n",
    "            custom_callbacks = [summary_callback, checkpoint_callback, early_stopping]\n",
    "#       Note that we are only passing x & not y in fit function\n",
    "#       Refer to keras model.fit documentation for further details\n",
    "\n",
    "#       If `x` is a dataset, generator,\n",
    "#       or `keras.utils.Sequence` instance, `y` should\n",
    "#       not be specified (since targets will be obtained from `x`).\n",
    "        model_history = classification_model.fit(\n",
    "            x=training_dataset,\n",
    "            validation_data=evaluation_dataset,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "            validation_steps=eval_steps,\n",
    "            callbacks=custom_callbacks)\n",
    "\n",
    "        return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining various parameters for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n"
     ]
    }
   ],
   "source": [
    "steps_per_loop = 1\n",
    "learning_rate=1e-5\n",
    "epochs=20\n",
    "\n",
    "train_batch_size=16\n",
    "eval_batch_size=16\n",
    "\n",
    "train_data_size = input_meta_data['train_data_size']\n",
    "steps_per_epoch = int(train_data_size / train_batch_size)\n",
    "print(steps_per_epoch)\n",
    "\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / train_batch_size)\n",
    "eval_steps = int(math.ceil(input_meta_data['eval_data_size'] / eval_batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training & validation dataset object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16,), dtype=string, numpy=\n",
      "array([b'my hopper is not working',\n",
      "       b'how can I cancel the final four games',\n",
      "       b'I don\\xe2\\x80\\x99t want to add hbo',\n",
      "       b'where is the channel line up',\n",
      "       b'I am wondering when I will be reimbursed for my DISH Equipment? I was charged for not returning the equipment within 30 days but have sense sent it out about 2 weeks ago...',\n",
      "       b'need help setting my remote with tv ',\n",
      "       b'How do I cancel HBO| Showtime and whatever else is about to become an extra expense?',\n",
      "       b\"What's the difference between smart pack and flex pack? Can I just get local channels ,HBO Starz and Showtime?\",\n",
      "       b'i need to have my service added to my garage is this possible i have 3 joeys now',\n",
      "       b'Is there any possible way my appointment could be around 5pm',\n",
      "       b'Hi I think Im shutting down may account . My husband is not working and Its difficult to be paying $85. How can I be helped?',\n",
      "       b'i don want march madness on my package please remove it',\n",
      "       b'payment extenstion',\n",
      "       b'I would like to remove the dish protect silver from my account',\n",
      "       b'Please freeze account',\n",
      "       b'My tech was supposed to be here at 1:15'], dtype=object)>, <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
      "array([ 63,  30,  32,  29, 134, 128,  30,  33,  34,  13,   6,  30,  97,\n",
      "        30,  43,  15])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-1cb11528cf86>:18: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
      "  dataset = dataset.map(lambda text, label: (text, label_to_id(label)),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_dataset = get_input_dataset(train_csv_file, default_label, intent_file, train_batch_size, delimiter, is_training=True)\n",
    "evaluation_dataset = get_input_dataset(eval_csv_file, default_label, intent_file, train_batch_size, delimiter, is_training=False)\n",
    "## taking only 1 row & iterating & viewing output\n",
    "for line in training_dataset.take(1):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_multiplier = 1\n",
    "max_seq_length = input_meta_data['max_seq_length']\n",
    "num_labels = input_meta_data['num_labels']\n",
    "loss_fn = get_loss_fn(num_labels,loss_multiplier)\n",
    "\n",
    "def _get_classifier_model():\n",
    "    classifier_model,core_model = get_multilingual_bert(bert_config=bert_config,\n",
    "                                                              num_labels=num_labels,\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               model_hub_url=bert_hub_url,\n",
    "                                                                preprocessor_hub_url=bert_preprocessor_url)\n",
    "    ##This is basically Adam optimizer with weight decay after set no of warm up steps & \n",
    "    # before that an increasing learning rate from 0 to initial_lr\n",
    "    # refer to models/official/nlp/optimization.py for more details\n",
    "    classifier_model.optimizer = optimization.create_optimizer(init_lr=learning_rate,\n",
    "                                                               num_train_steps=steps_per_epoch*epochs,\n",
    "                                                               num_warmup_steps=warmup_steps)\n",
    "    return classifier_model,core_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f04fd5cfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f04fd5cfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f04fd5ccaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f04fd5ccaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "using Adamw optimizer\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n",
      "\n",
      "Got `type(handle)`: <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n",
      "Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n",
      "\n",
      "Got `type(handle)`: <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n",
      "Epoch 1/20\n",
      "  19/1446 [..............................] - ETA: 7:05 - loss: 4.9699 - test_accuracy: 0.0033WARNING:tensorflow:From /opt/custom/python/anaconda3/envs/tf2.3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "From /opt/custom/python/anaconda3/envs/tf2.3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1446/1446 [==============================] - 493s 341ms/step - loss: 4.4463 - test_accuracy: 0.1263 - val_loss: 3.4793 - val_test_accuracy: 0.3336\n",
      "Epoch 2/20\n",
      "1446/1446 [==============================] - 487s 337ms/step - loss: 2.7808 - test_accuracy: 0.4508 - val_loss: 2.0371 - val_test_accuracy: 0.5933\n",
      "Epoch 3/20\n",
      "1446/1446 [==============================] - 488s 337ms/step - loss: 1.7606 - test_accuracy: 0.6472 - val_loss: 1.4248 - val_test_accuracy: 0.7065\n",
      "Epoch 4/20\n",
      "1446/1446 [==============================] - 488s 337ms/step - loss: 1.2473 - test_accuracy: 0.7444 - val_loss: 1.1547 - val_test_accuracy: 0.7516\n",
      "Epoch 5/20\n",
      "1446/1446 [==============================] - 486s 336ms/step - loss: 0.9558 - test_accuracy: 0.7992 - val_loss: 1.0185 - val_test_accuracy: 0.7780\n",
      "Epoch 6/20\n",
      "1446/1446 [==============================] - 487s 337ms/step - loss: 0.7637 - test_accuracy: 0.8367 - val_loss: 0.9330 - val_test_accuracy: 0.7912\n",
      "Epoch 7/20\n",
      "1446/1446 [==============================] - 487s 337ms/step - loss: 0.6227 - test_accuracy: 0.8628 - val_loss: 0.8885 - val_test_accuracy: 0.7994\n",
      "Epoch 8/20\n",
      "1446/1446 [==============================] - 488s 338ms/step - loss: 0.5220 - test_accuracy: 0.8846 - val_loss: 0.8504 - val_test_accuracy: 0.8122\n",
      "Epoch 9/20\n",
      "1446/1446 [==============================] - 487s 337ms/step - loss: 0.4364 - test_accuracy: 0.9048 - val_loss: 0.8238 - val_test_accuracy: 0.8134\n",
      "Epoch 10/20\n",
      "1446/1446 [==============================] - 462s 320ms/step - loss: 0.3729 - test_accuracy: 0.9180 - val_loss: 0.8307 - val_test_accuracy: 0.8161\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model = run_keras_compile_fit(model_dir=output_folder,strategy=strategy,model_fn=_get_classifier_model,\n",
    "                                     training_dataset=training_dataset,evaluation_dataset=evaluation_dataset,\n",
    "                                      loss_fn=loss_fn,metric_fn=metric_fn,\n",
    "                                     init_checkpoint=None,\n",
    "                                      epochs=epochs,\n",
    "                                      steps_per_epoch=steps_per_epoch,\n",
    "                                      steps_per_loop=steps_per_loop,\n",
    "                                      eval_steps=eval_steps\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying training for a few more epochs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs=5\n",
    "init_checkpoint = tf.train.latest_checkpoint(output_folder)\n",
    "trained_model = run_keras_compile_fit(model_dir=output_folder,strategy=strategy,model_fn=_get_classifier_model,\n",
    "                                     training_dataset=training_dataset,evaluation_dataset=evaluation_dataset,\n",
    "                                      loss_fn=loss_fn,metric_fn=metric_fn,\n",
    "                                     init_checkpoint=init_checkpoint,\n",
    "                                      epochs=epochs,\n",
    "                                      steps_per_epoch=steps_per_epoch,\n",
    "                                      steps_per_loop=steps_per_loop,\n",
    "                                      eval_steps=eval_steps\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "We don't want to have dropout in the network.\n",
    "For the output have a softmax & a table lookup to on labels to return the label name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelLookup(tf.keras.layers.Layer):\n",
    "#     def __init__(self,model_proto):\n",
    "    def __init__(self,filepath,default,*args,**kwargs):\n",
    "        \"\"\" \n",
    "        filepath - path to the text file with 1 label per line\n",
    "        \"\"\"\n",
    "        super(LabelLookup, self).__init__(trainable=False,dtype=tf.int64,*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "        self.default=default\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        # need to convert label index to label name. So keeping line no as key & whole text line as label\n",
    "        # issue with using table lookup (both file based & key value tensorbased) in tf2.2 (tf2.x) - https://github.com/tensorflow/tensorflow/issues/38305\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.TextFileInitializer(self.filepath,\n",
    "                                          key_dtype=tf.int64,key_index=tf.lookup.TextFileIndex.LINE_NUMBER,\n",
    "                                     value_dtype=tf.string,value_index=tf.lookup.TextFileIndex.WHOLE_LINE),self.default)\n",
    "        self.built=True\n",
    "        \n",
    "    def call(self, input_index):\n",
    "        word_ids = self.table.lookup(input_index)\n",
    "        return word_ids\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(LabelLookup, self).get_config()\n",
    "#         config.update({'filepath': self.filepath})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenizerLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,filepath,default,*args,**kwargs):\n",
    "        \"\"\" \n",
    "        filepath - path to the text file with 1 label per line\n",
    "        \"\"\"\n",
    "        super(BertTokenizerLayer, self).__init__(trainable=False,dtype=tf.int32,*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "        self.default=default\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        # need to convert label index to label name. So keeping line no as key & whole text line as label\n",
    "        # issue with using table lookup (both file based & key value tensorbased) in tf2.2 (tf2.x) - https://github.com/tensorflow/tensorflow/issues/38305\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.TextFileInitializer(self.filepath,\n",
    "                                          key_dtype=tf.string,key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "                                     value_dtype=tf.int64,value_index=tf.lookup.TextFileIndex.LINE_NUMBER),self.default)\n",
    "        self.tokenizer = tftext.BertTokenizer(self.table,split_unknown_characters=False)\n",
    "        self.built=True\n",
    "        \n",
    "    def call(self, word):\n",
    "        word_ids = tf.cast(self.tokenizer.tokenize(word),dtype=self.dtype)\n",
    "        return word_ids\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(BertTokenizerLayer, self).get_config()\n",
    "#         config.update({'filepath': self.filepath})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_text.python.ops.bert_tokenizer.BertTokenizer at 0x7f4bcdd481c0>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = '/space/engineering/tf_serve/models/dish_multilingual_bert/bert_multilingual_preprocessor/vocab.txt'\n",
    "unk_word_index = 100\n",
    "table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.TextFileInitializer(vocab_file,\n",
    "                                          key_dtype=tf.string,key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "                                     value_dtype=tf.int64,value_index=tf.lookup.TextFileIndex.LINE_NUMBER),unk_word_index)\n",
    "tokenizer = tftext.BertTokenizer(table,split_unknown_characters=False)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert_preprocessor_loaded.tokenize({\"sentences\":tf.constant(\"talk to an agent\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[31311], [10114], [18980]], [[33786]]]>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tf.constant([\"talk to agent\", \"representative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"bert_tokenizer_layer_3/Cast_1:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"bert_tokenizer_layer_3/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets/WordpieceTokenizeWithOffsets:1\", shape=(None,), dtype=int64)), row_splits=Tensor(\"bert_tokenizer_layer_3/RaggedFromRowSplits/control_dependency:0\", shape=(None,), dtype=int64))]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_layer = BertTokenizerLayer(vocab_file, unk_word_index)\n",
    "temp = [tokenize_layer(input_text)]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilingual_bert_for_saving(bert_config,num_labels,max_seq_length,\n",
    "                                     model_hub_url,preprocessor_path,\n",
    "                                     checkpoint_path,\n",
    "                                     default_label,\n",
    "                                    max_top_intents=2, unk_word_index=100):\n",
    "    bert_preprocessor_loaded = hub.load(preprocessor_path)\n",
    "    vocab_file = os.path.join(preprocessor_path,\"assets\",\"vocab.txt\")\n",
    "    \n",
    "    input_text = tf.keras.layers.Input(shape=(), dtype=tf.string,name='input_text')\n",
    "#     tokenize = hub.KerasLayer(bert_preprocessor_loaded.tokenize)\n",
    "    tokenize = BertTokenizerLayer(vocab_file, unk_word_index)\n",
    "    \n",
    "    tokenized_inputs = [tokenize(input_text)] # bert can handle 2 input_texts (segments)\n",
    "    \n",
    "    bert_pack_inputs = hub.KerasLayer(bert_preprocessor_loaded.bert_pack_inputs,arguments=dict(seq_length=max_seq_length))\n",
    "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "    encoder = hub.KerasLayer(model_hub_url,trainable=False)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "    sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n",
    "    initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config[\"initializer_range\"])\n",
    "    dense_output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(pooled_output)\n",
    "    \n",
    "    # calculating softmax over the output layer\n",
    "    probs = tf.nn.softmax(dense_output,axis=-1,name='scores')\n",
    "    # sorting & taking only max_top_intents\n",
    "    sorted_indexes = tf.cast(tf.argsort(probs,axis=-1,direction='DESCENDING'),tf.int64)[:,:max_top_intents]\n",
    "    sorted_scores1 = tf.sort(probs,axis=-1,direction='DESCENDING',name=\"scores1\")[:,:max_top_intents]\n",
    "    # this identity operation was only required to get the name correctly as in tf2.3 the sort object's name was coming differently\n",
    "    # https://github.com/tensorflow/tensorflow/issues/39398\n",
    "    # https://stackoverflow.com/questions/38626424/how-to-assign-new-name-or-rename-an-existing-tensor-in-tensorflow\n",
    "    sorted_scores = tf.identity(sorted_scores1,name='scores_sorted')\n",
    "\n",
    "    labels = LabelLookup(filepath=intent_file,default=default_label,name=\"classes\")(sorted_indexes)\n",
    "\n",
    "    # loaded_model.compile()\n",
    "    #     checkpoint = tf.train.Checkpoint(model=model)\n",
    "    #     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "    \n",
    "    model  = tf.keras.Model(inputs={'input_text':input_text},\n",
    "                         outputs={\"classes\":labels,\"scores\":sorted_scores})\n",
    "    # FIXME the following is a hack (not sure if it will create other issues)\n",
    "    model.output_names = ['classes', 'scores']\n",
    "\n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "    model.load_weights(checkpoint_path).assert_existing_objects_matched()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessor_path = '/space/engineering/tfhub_modules/7d11d5f8a107b5acd196d06446e8a878d630fe38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_preprocessor_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bce00cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bce00cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bcdf90310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bcdf90310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f4bcde8f160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f4bcfb9fcd0>).\n",
      "Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f4bcde8f160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f4bcfb9fcd0>).\n"
     ]
    }
   ],
   "source": [
    "classification_model_to_save = get_multilingual_bert_for_saving(bert_config=bert_config,\n",
    "                                                              num_labels=input_meta_data['num_labels'],\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               model_hub_url=bert_hub_url,\n",
    "                                                                preprocessor_path=preprocessor_path,\n",
    "                                                                checkpoint_path=tf.train.latest_checkpoint(output_folder),\n",
    "                                                                default_label=default_label, max_top_intents=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': array([[b'other-other', b'representative-request'],\n",
       "        [b'greet-hello', b'autopay-cancel'],\n",
       "        [b'representative-request', b'other-other'],\n",
       "        [b'remote-setup', b'remote-place_order']], dtype=object),\n",
       " 'scores': array([[0.10534582, 0.05661591],\n",
       "        [0.07370817, 0.02759776],\n",
       "        [0.33845136, 0.0372153 ],\n",
       "        [0.8056617 , 0.02082952]], dtype=float32)}"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = classification_model_to_save.predict(['','hello','talk to agent', 'remote not working'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_text (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        (None, None, None)   0           input_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      {'input_type_ids': ( 0           keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_2 (KerasLayer)      {'default': (None, 7 177853441   keras_layer_1[0][0]              \n",
      "                                                                 keras_layer_1[0][1]              \n",
      "                                                                 keras_layer_1[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 142)          109198      keras_layer_2[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_scores (TensorFlowO [(None, 142)]        0           output[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           tf_op_layer_scores[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(2,)]               0           tf_op_layer_scores[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2 (TensorFlowO [(None, None), (None 0           tf_op_layer_scores[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, None)]       0           tf_op_layer_TopKV2[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, None), (None 0           tf_op_layer_scores[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, None)]       0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, None)]       0           tf_op_layer_TopKV2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "classes (LabelLookup)           (None, None)         0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_scores_sorted (Tens [(None, None)]       0           tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 177,962,639\n",
      "Trainable params: 109,198\n",
      "Non-trainable params: 177,853,441\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model_to_save.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /space/engineering/tf_serve/models/dish_multilingual_bert/2/assets\n",
      "Assets written to: /space/engineering/tf_serve/models/dish_multilingual_bert/2/assets\n"
     ]
    }
   ],
   "source": [
    "# final_model_path=os.path.join(output_folder,'final_model')\n",
    "final_model_path='/space/engineering/tf_serve/models/dish_multilingual_bert'\n",
    "final_versioned_model_path = os.path.join(final_model_path,'2')\n",
    "classification_model_to_save.save(final_versioned_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the saved model with preprocessing & trying it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbacfe940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbacfe940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbad61280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbad61280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbacfeee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbacfeee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbad55c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bbad55c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "loaded_final_model = tf.saved_model.load(final_versioned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction signature_wrapper(input_text) at 0x7F4BBB34D700>"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default = loaded_final_model.signatures['serving_default']\n",
    "serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': <tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       " array([[0.10534582, 0.05661591],\n",
       "        [0.07370817, 0.02759776],\n",
       "        [0.33845136, 0.0372153 ],\n",
       "        [0.8056617 , 0.02082952]], dtype=float32)>,\n",
       " 'classes': <tf.Tensor: shape=(4, 2), dtype=string, numpy=\n",
       " array([[b'other-other', b'representative-request'],\n",
       "        [b'greet-hello', b'autopay-cancel'],\n",
       "        [b'representative-request', b'other-other'],\n",
       "        [b'remote-setup', b'remote-place_order']], dtype=object)>}"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default(tf.constant(['','hello','talk to agent', 'remote not working']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running against a held out test set\n",
    "ideally we need a held out test set, but using the validation set again just to have the testing code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>granular_intent</th>\n",
       "      <th>ru_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>a9cf6bee-3971-4516-459f-2243d9a606fd</td>\n",
       "      <td>I want to inform you that I don't have electri...</td>\n",
       "      <td>billing-issue</td>\n",
       "      <td>billing-issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>0f050cf9-88d7-44bd-23c8-5f26674f5b6a</td>\n",
       "      <td>What happen to my bill</td>\n",
       "      <td>billing-query</td>\n",
       "      <td>billing-query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>INT-sv1appis11-1503849377195-243917</td>\n",
       "      <td>I need to replace my remote control.</td>\n",
       "      <td>remote-place_order</td>\n",
       "      <td>remote-place_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>INT-sv1appis14-1504137880316-305603_1158</td>\n",
       "      <td>Reciever is saying not authorized on every cha...</td>\n",
       "      <td>receiver_issue-get_help</td>\n",
       "      <td>receiver_issue-get_help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>6e1842f4-63a1-4259-3999-6928033ce7eb</td>\n",
       "      <td>i need to update my credit card info</td>\n",
       "      <td>payment-get_help</td>\n",
       "      <td>payment-get_help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "20421      a9cf6bee-3971-4516-459f-2243d9a606fd   \n",
       "22946      0f050cf9-88d7-44bd-23c8-5f26674f5b6a   \n",
       "8207        INT-sv1appis11-1503849377195-243917   \n",
       "14144  INT-sv1appis14-1504137880316-305603_1158   \n",
       "8164       6e1842f4-63a1-4259-3999-6928033ce7eb   \n",
       "\n",
       "                                                    text  \\\n",
       "20421  I want to inform you that I don't have electri...   \n",
       "22946                             What happen to my bill   \n",
       "8207                I need to replace my remote control.   \n",
       "14144  Reciever is saying not authorized on every cha...   \n",
       "8164                i need to update my credit card info   \n",
       "\n",
       "               granular_intent                ru_intent  \n",
       "20421            billing-issue            billing-issue  \n",
       "22946            billing-query            billing-query  \n",
       "8207        remote-place_order       remote-place_order  \n",
       "14144  receiver_issue-get_help  receiver_issue-get_help  \n",
       "8164          payment-get_help         payment-get_help  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': array([[b'billing-issue', b'price-increase', b'billing-vague', ...,\n",
       "         b'app-query', b'dvr-query', b'receiver_upgrade-query'],\n",
       "        [b'billing-issue', b'billing-vague', b'billing-query', ...,\n",
       "         b'ppv-cancel', b'order-query', b'receiver_upgrade-query'],\n",
       "        [b'remote-place_order', b'remote-order_status',\n",
       "         b'remote-not_working', ..., b'get-help', b'billing-vague',\n",
       "         b'other-other'],\n",
       "        ...,\n",
       "        [b'channel_package-issue', b'streaming-issues',\n",
       "         b'comp_part_signal_loss-issue', ..., b'order-cancel',\n",
       "         b'internet-price_query', b'appointment-cancel'],\n",
       "        [b'price-increase', b'billing-issue',\n",
       "         b'account_cancel-promotion_seek', ..., b'online_account-setup',\n",
       "         b'dish_pause-cancel', b'billing-preferences'],\n",
       "        [b'greet-hello', b'yes-give', b'no-give', ..., b'promotion-query',\n",
       "         b'billing-preferences', b'account-address_change']], dtype=object),\n",
       " 'scores': array([[9.90572035e-01, 1.36903033e-03, 7.22032622e-04, ...,\n",
       "         4.48613173e-06, 3.90728383e-06, 3.59540400e-06],\n",
       "        [9.83889103e-01, 3.92688625e-03, 1.98980793e-03, ...,\n",
       "         5.12303404e-06, 5.08199355e-06, 4.91710898e-06],\n",
       "        [9.39636528e-01, 2.66878530e-02, 5.72897727e-03, ...,\n",
       "         1.40353868e-05, 1.27390758e-05, 1.08726945e-05],\n",
       "        ...,\n",
       "        [9.89189625e-01, 1.56994630e-03, 1.04121200e-03, ...,\n",
       "         3.62604578e-06, 2.82794531e-06, 1.43056025e-06],\n",
       "        [9.91882026e-01, 1.29181775e-03, 6.47934037e-04, ...,\n",
       "         5.17458193e-06, 4.91146602e-06, 4.39468567e-06],\n",
       "        [5.50903201e-01, 1.80327654e-01, 8.84241089e-02, ...,\n",
       "         1.65124256e-05, 1.24546677e-05, 9.99046279e-06]], dtype=float32)}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = classification_model_to_save.predict(df_val['text'].array[:20].to_numpy())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_intent_per_row(row, classification_model, text_column='text',out_of_domain_intent='none_none'):\n",
    "    text = row['text']\n",
    "    try:\n",
    "        output = classification_model.predict([text])\n",
    "        # 1st index is for batch & batch size is 1, 2nd is the list of intents, taking the top intent\n",
    "        row['predicted_intent'] = output['classes'][0][0]\n",
    "        row['score'] = output['scores'][0][0]\n",
    "    except Exception as e:\n",
    "        print(f'exception occured, text {text} classifying as out of domain intent error {e}')\n",
    "        row['predicted_intent']  = out_of_domain_intent\n",
    "        row['score'] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test data 2572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>granular_intent</th>\n",
       "      <th>ru_intent</th>\n",
       "      <th>predicted_intent</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>a9cf6bee-3971-4516-459f-2243d9a606fd</td>\n",
       "      <td>I want to inform you that I don't have electri...</td>\n",
       "      <td>billing-issue</td>\n",
       "      <td>billing-issue</td>\n",
       "      <td>b'billing-issue'</td>\n",
       "      <td>0.990572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>0f050cf9-88d7-44bd-23c8-5f26674f5b6a</td>\n",
       "      <td>What happen to my bill</td>\n",
       "      <td>billing-query</td>\n",
       "      <td>billing-query</td>\n",
       "      <td>b'billing-issue'</td>\n",
       "      <td>0.983889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>INT-sv1appis11-1503849377195-243917</td>\n",
       "      <td>I need to replace my remote control.</td>\n",
       "      <td>remote-place_order</td>\n",
       "      <td>remote-place_order</td>\n",
       "      <td>b'remote-place_order'</td>\n",
       "      <td>0.939638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>INT-sv1appis14-1504137880316-305603_1158</td>\n",
       "      <td>Reciever is saying not authorized on every cha...</td>\n",
       "      <td>receiver_issue-get_help</td>\n",
       "      <td>receiver_issue-get_help</td>\n",
       "      <td>b'receiver_issue-get_help'</td>\n",
       "      <td>0.598178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>6e1842f4-63a1-4259-3999-6928033ce7eb</td>\n",
       "      <td>i need to update my credit card info</td>\n",
       "      <td>payment-get_help</td>\n",
       "      <td>payment-get_help</td>\n",
       "      <td>b'payment-get_help'</td>\n",
       "      <td>0.947868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "20421      a9cf6bee-3971-4516-459f-2243d9a606fd   \n",
       "22946      0f050cf9-88d7-44bd-23c8-5f26674f5b6a   \n",
       "8207        INT-sv1appis11-1503849377195-243917   \n",
       "14144  INT-sv1appis14-1504137880316-305603_1158   \n",
       "8164       6e1842f4-63a1-4259-3999-6928033ce7eb   \n",
       "\n",
       "                                                    text  \\\n",
       "20421  I want to inform you that I don't have electri...   \n",
       "22946                             What happen to my bill   \n",
       "8207                I need to replace my remote control.   \n",
       "14144  Reciever is saying not authorized on every cha...   \n",
       "8164                i need to update my credit card info   \n",
       "\n",
       "               granular_intent                ru_intent  \\\n",
       "20421            billing-issue            billing-issue   \n",
       "22946            billing-query            billing-query   \n",
       "8207        remote-place_order       remote-place_order   \n",
       "14144  receiver_issue-get_help  receiver_issue-get_help   \n",
       "8164          payment-get_help         payment-get_help   \n",
       "\n",
       "                 predicted_intent     score  \n",
       "20421            b'billing-issue'  0.990572  \n",
       "22946            b'billing-issue'  0.983889  \n",
       "8207        b'remote-place_order'  0.939638  \n",
       "14144  b'receiver_issue-get_help'  0.598178  \n",
       "8164          b'payment-get_help'  0.947868  "
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'size of test data {len(df_test)}')\n",
    "df_test = df_test.apply(lambda row:get_predicted_intent_per_row(row,classification_model_to_save,text_column='text'),axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load_final_model_keras = tf.keras.models.load_model(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((),\n",
       " {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default.structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_lookup': TensorSpec(shape=(None,), dtype=tf.string, name='label_lookup')}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default.structured_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_lookup': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other-other'], dtype=object)>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default(tf.constant(['talk to an agent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original preprocessing logic \n",
    "Refer - https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/1    \n",
    "This had an issue while loading the model for serving. It was still pointing to original vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bd493df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bd493df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bd48585e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f4bd48585e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f4bd4838040> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f4be619fd60>).\n",
      "Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f4bd4838040> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f4be619fd60>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4be61a63a0>"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_hub_url = bert_preprocessor_url\n",
    "model_hub_url = bert_hub_url\n",
    "max_top_intents = 2\n",
    "checkpoint_path=tf.train.latest_checkpoint(output_folder)\n",
    "bert_preprocessor_loaded = hub.load(preprocessor_hub_url)\n",
    "input_text = tf.keras.layers.Input(shape=(), dtype=tf.string,name='input_text')\n",
    "tokenize = hub.KerasLayer(bert_preprocessor_loaded.tokenize)\n",
    "tokenized_inputs = [tokenize(input_text)] # bert can handle 2 input_texts (segments)\n",
    "\n",
    "bert_pack_inputs = hub.KerasLayer(bert_preprocessor_loaded.bert_pack_inputs,arguments=dict(seq_length=max_seq_length))\n",
    "encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "encoder = hub.KerasLayer(model_hub_url,trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n",
    "initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config[\"initializer_range\"])\n",
    "dense_output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(pooled_output)\n",
    "\n",
    "# calculating softmax over the output layer\n",
    "probs = tf.nn.softmax(dense_output,axis=-1,name='scores')\n",
    "# sorting & taking only max_top_intents\n",
    "sorted_indexes = tf.cast(tf.argsort(probs,axis=-1,direction='DESCENDING'),tf.int64)[:,:max_top_intents]\n",
    "sorted_scores1 = tf.sort(probs,axis=-1,direction='DESCENDING',name=\"scores1\")[:,:max_top_intents]\n",
    "# this identity operation was only required to get the name correctly as in tf2.3 the sort object's name was coming differently\n",
    "# https://github.com/tensorflow/tensorflow/issues/39398\n",
    "# https://stackoverflow.com/questions/38626424/how-to-assign-new-name-or-rename-an-existing-tensor-in-tensorflow\n",
    "sorted_scores = tf.identity(sorted_scores1,name='scores_sorted')\n",
    "\n",
    "labels = LabelLookup(filepath=intent_file,default=default_label,name=\"classes\")(sorted_indexes)\n",
    "\n",
    "# loaded_model.compile()\n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "\n",
    "model  = tf.keras.Model(inputs={'input_text':input_text},\n",
    "                     outputs={\"classes\":labels,\"scores\":sorted_scores})\n",
    "# FIXME the following is a hack (not sure if it will create other issues)\n",
    "# model.output_names = ['classes', 'scores']\n",
    "\n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "model.load_weights(checkpoint_path).assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"keras_layer/StatefulPartitionedCall:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"keras_layer/StatefulPartitionedCall:2\", shape=(None,), dtype=int64)), row_splits=Tensor(\"keras_layer/StatefulPartitionedCall:1\", shape=(None,), dtype=int64))]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%tensorboard --logdir /var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large/checkpoint/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate(eval_input_fn,model):\n",
    "    eval_iter = iter(strategy.experimental_distribute_datasets_from_function(eval_input_fn))\n",
    "    \n",
    "    def _test_step_fn(inputs,label):\n",
    "#         inputs,label = inputs\n",
    "        model_outputs = model(inputs,training=False)\n",
    "        metric.update_state(label,model_outputs)\n",
    "    strategy.experimental_run_v2(_test_step_fn,args=(next(eval_iter)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluate(eval_input_fn,trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - tensorflow 2.3 (tf2.3)",
   "language": "python",
   "name": "tf2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
