{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# import bert\n",
    "# from bert import BertModelLayer\n",
    "import functools\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "import tf_sentencepiece as tfs\n",
    "import tensorflow_text as tftext\n",
    "import sys\n",
    "sys.path.extend([\"/space/users/jgeorge/git/tensorflow_repos/models\"])\n",
    "\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# pylint: disable=g-import-not-at-top,redefined-outer-name,reimported\n",
    "from official.modeling import model_training_utils\n",
    "\n",
    "from official.nlp.modeling.models import bert_classifier, bert_pretrainer\n",
    "# from official.nlp.modeling.models.bert_classifier import BertClassifier\n",
    "# from official.nlp.modeling.models.bert_pretrainer import BertPretrainer\n",
    "# from official.nlp import bert_modeling as modeling\n",
    "# from official.nlp import bert_models\n",
    "from official.nlp import optimization\n",
    "from official.nlp.bert import common_flags\n",
    "from official.nlp.bert import input_pipeline\n",
    "from official.nlp.bert import model_saving_utils\n",
    "from official.utils.misc import distribution_utils\n",
    "from official.utils.misc import keras_utils\n",
    "from official.nlp.bert import tokenization\n",
    "\n",
    "from official.nlp.albert import configs as albert_configs\n",
    "from official.nlp.bert import run_classifier as run_classifier_bert\n",
    "\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.utils import tf_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.engine import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##restricting no of gpus\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "device_to_use = gpus[3]\n",
    "tf.config.experimental.set_memory_growth(device_to_use,True)\n",
    "tf.config.experimental.set_visible_devices(device_to_use, 'GPU')\n",
    "print(tf.config.experimental.get_visible_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##setting direcory for downloading tfhub modules\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = '/space/engineering/tfhub_modules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_data_path='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/dishDataJan17.txt'\n",
    "df = pd.read_csv(dish_data_path,sep='\\t',header=None,names=['filename','text','granular_intent','ru_intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>granular_intent</th>\n",
       "      <th>ru_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INT-sv1appis14-1504137880316-305603_4567</td>\n",
       "      <td>can you send my bill to my mail?</td>\n",
       "      <td>billing-preferences</td>\n",
       "      <td>billing-preferences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INT-va1appis15-1504373018548-41332</td>\n",
       "      <td>My Wally receiver has lost Satellite signal in...</td>\n",
       "      <td>comp_part_signal_loss-issue</td>\n",
       "      <td>comp_part_signal_loss-issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INT-sv1appis12-1503954587819-263368</td>\n",
       "      <td>I need a payment extension so i don't get my s...</td>\n",
       "      <td>payment_extension-request</td>\n",
       "      <td>payment_extension-request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ed8e9b1-10f5-438d-c409-e616c3ff9ede</td>\n",
       "      <td>how can i find my local channels. it seems i d...</td>\n",
       "      <td>channel_package-issue</td>\n",
       "      <td>channel_package-issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INT-sv1appis13-1504099917638-293735</td>\n",
       "      <td>Wanted to speak with someone about my bill</td>\n",
       "      <td>representative-request</td>\n",
       "      <td>representative-request</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  \\\n",
       "0  INT-sv1appis14-1504137880316-305603_4567   \n",
       "1        INT-va1appis15-1504373018548-41332   \n",
       "2       INT-sv1appis12-1503954587819-263368   \n",
       "3      8ed8e9b1-10f5-438d-c409-e616c3ff9ede   \n",
       "4       INT-sv1appis13-1504099917638-293735   \n",
       "\n",
       "                                                text  \\\n",
       "0                   can you send my bill to my mail?   \n",
       "1  My Wally receiver has lost Satellite signal in...   \n",
       "2  I need a payment extension so i don't get my s...   \n",
       "3  how can i find my local channels. it seems i d...   \n",
       "4         Wanted to speak with someone about my bill   \n",
       "\n",
       "               granular_intent                    ru_intent  \n",
       "0          billing-preferences          billing-preferences  \n",
       "1  comp_part_signal_loss-issue  comp_part_signal_loss-issue  \n",
       "2    payment_extension-request    payment_extension-request  \n",
       "3        channel_package-issue        channel_package-issue  \n",
       "4       representative-request       representative-request  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_val,y_train,y_val = train_test_split(df,df['granular_intent'],train_size=0.8,random_state=42,stratify=df['granular_intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_exp_folder = '/space/users/jgeorge/projects/k/tensorflow2-question-answering/input/dish/data/jan17_2020/'\n",
    "main_exp_folder = '/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_csv_file='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/train.txt'\n",
    "eval_csv_file='/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/val.txt'\n",
    "\n",
    "df_train.to_csv(train_csv_file,sep='\\t',header=False,index=False)\n",
    "df_val.to_csv(eval_csv_file,sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_file = '/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/intentlist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(intent_file,'w',encoding='utf-8') as out_f:\n",
    "    for intent in sorted(df_train['granular_intent'].unique()):\n",
    "        out_f.write(intent+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list = []\n",
    "with open(intent_file,'r') as inp_f:\n",
    "    for intent in inp_f:\n",
    "        intent_list.append(intent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meta_data = {\n",
    "    'max_seq_length':128,\n",
    "    'num_labels':len(intent_list),\n",
    "    'train_data_size':20574,\n",
    "    'eval_data_size':5144,\n",
    "    'default_label':'other-other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 128,\n",
       " 'num_labels': 142,\n",
       " 'train_data_size': 20574,\n",
       " 'eval_data_size': 5144,\n",
       " 'default_label': 'other-other'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meta_path = os.path.join(main_exp_folder,'input_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing metadata file\n",
    "with open(input_meta_path,'w',encoding='utf-8') as jf:\n",
    "    jf.write(json.dumps(input_meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading metadata file\n",
    "with open(input_meta_path,'r',encoding='utf-8') as jf:\n",
    "#     input_meta_data = json.loads(jf.read())\n",
    "    input_meta_data = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing & feeding into graph\n",
    "We will be reading the regular text file as input & encoding the text \n",
    "using sentence piece encoder provided along with albert & then\n",
    "writing it as tfrecord. Other than the sentencepiece encoder these models does not require any preprocessing like regex-replacement, lemmatization etc \n",
    "\n",
    "Writing as tfrecord is not necessary, but it is a more optimized file format for reading into \n",
    "tf.data api (you can even base your tf dataset on a textfile or even a python iterator)\n",
    "Also it's not necessary to use tf.data apis but this is much more optimized, like preloading data into gpu memory & optimization required if you are running across systems & all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence piece encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##albert hub url\n",
    "bert_hub_url='https://tfhub.dev/tensorflow/albert_en_large/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from link given in https://github.com/tensorflow/models/tree/master/official/nlp/albert\n",
    "# specifically https://storage.googleapis.com/cloud-tpu-checkpoints/albert/checkpoints/albert_v2_large.tar.gz\n",
    "# this is not required if we are just using tensorflow hub, since the hub module didn't have a detailed config, \n",
    "# will load the config from this folder for reference  \n",
    "bert_model_dir='/space/engineering/pretrained_models/albert/albert_large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the used sentence piece model from the hub module, \n",
    "it will be present in the assests folder of the downloaded albert model\n",
    "Since we are using hub here & not directly downloading it, the path can be fetched from hub layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_vocab_path = \"/space/engineering/pretrained_models/bert/multi_cased_L-12_H-768_A-12/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hub_loaded = hub.load(bert_hub_url)\n",
    "sentencepiece_path = bert_hub_loaded.sp_model_file.asset_path.numpy()\n",
    "\n",
    "# or if you are using hub.KeraLayer\n",
    "# bert_model = hub.KerasLayer(bert_hub_url,trainable=True)\n",
    "# sentencepiece_path = bert_model.resolved_object.sp_model_file.asset_path.numpy()\n",
    "\n",
    "##if you have directly downloaded the model you could do this\n",
    "# sentencepiece_path = os.path.join(model_dir, \"assets\", \"30k-clean.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading the sentence piece model into memory\n",
    "sp_model_proto = tf.io.gfile.GFile(sentencepiece_path, 'rb').read()\n",
    "\n",
    "# sp_model = sp_model_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sentence piece we can use either the       \n",
    "1) tf_sentencepiece (import as tfs here)     \n",
    "2) sentencepiece (imported as spm) package        \n",
    "3) sentencepiece from tensorflow_text    \n",
    "4) tokenization.FullSentencePieceTokenizer - a wrapper on top of 2) sentencepiece, code is available in models/official/nlp/bert/tokenization.py      \n",
    "\n",
    "We will eventually just use tf_sentencepiece as that's the one which is currently, available to export as a graph.      \n",
    "But for the 1st step of creating training data (in tf records format) either of them will do\n",
    "but i'll illustrate how to use others as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=int32, numpy=\n",
       "array([  590,    55,  7876,    20,  6557,  3284,  5477, 11969,   357,\n",
       "           8,  3099,     8,  1323,  1433,   159, 10114], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_text  SentencepieceEncodeDense(values=<tf.Tensor: shape=(1, 16), dtype=int32, numpy=\n",
      "array([[  590,    55,  7876,    20,  6557,  3284,  5477, 11969,   357,\n",
      "            8,  3099,     8,  1323,  1433,   159, 10114]], dtype=int32)>, sequence_length=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([16], dtype=int32)>) , decoded text  tf.Tensor([b'give me directions to nearest restaurant randomtext 15-08-2019 year 2019'], shape=(1,), dtype=string) \n",
      "\n",
      "encoded_text2  [590, 55, 7876, 20, 6557, 3284, 5477, 11969, 357, 8, 3099, 8, 1323, 1433, 159, 10114] , decoded text2  give me directions to nearest restaurant randomtext 15-08-2019 year 2019 \n",
      "\n",
      "encoded_text3  tf.Tensor(\n",
      "[  590    55  7876    20  6557  3284  5477 11969   357     8  3099     8\n",
      "  1323  1433   159 10114], shape=(16,), dtype=int32) , decoded text3  tf.Tensor(b'give me directions to nearest restaurant randomtext 15-08-2019 year 2019', shape=(), dtype=string) \n",
      "\n",
      "tokens4 ['▁give', '▁me', '▁directions', '▁to', '▁nearest', '▁restaurant', '▁random', 'text', '▁15', '-', '08', '-', '20', '19', '▁year', '▁2019'] \n",
      "ids4  [590, 55, 7876, 20, 6557, 3284, 5477, 11969, 357, 8, 3099, 8, 1323, 1433, 159, 10114]\n"
     ]
    }
   ],
   "source": [
    "actual_sentence = 'give me directions to nearest restaurant randomtext 15-08-2019 year 2019'\n",
    "#1st method\n",
    "encoded_text1 = tfs.encode([actual_sentence],model_proto=sp_model_proto)\n",
    "##This method return\n",
    "#   pieces: A dense 2D tensor representing the tokenized sentences. key = values\n",
    "#   sequence_length: A 1D tensor representing the length of pieces.\n",
    "\n",
    "encoded_value1 = encoded_text1.values.numpy()\n",
    "sequence_length=encoded_text1.sequence_length.numpy()[0]\n",
    "# sequence_length=len(encoded_value1[0])\n",
    "print('encoded_text ',encoded_text1, ', decoded text ',\n",
    "      tfs.decode(encoded_value1,sequence_length=[sequence_length],model_proto=sp_model_proto),'\\n')\n",
    "\n",
    "# 2nd method\n",
    "sp2 = spm.SentencePieceProcessor()\n",
    "sp2.load(model_proto=sp_model_proto)\n",
    "encoded_text2 = sp2.encode_as_ids(actual_sentence)\n",
    "print('encoded_text2 ',encoded_text2, ', decoded text2 ',\n",
    "      sp2.decode_ids(encoded_text2),'\\n')\n",
    "\n",
    "###3rd methond\n",
    "sp3 = tftext.SentencepieceTokenizer(model=sp_model_proto)\n",
    "encoded_text3 = sp3.tokenize(actual_sentence)\n",
    "print('encoded_text3 ',encoded_text3, ', decoded text3 ',sp3.detokenize(encoded_text3.numpy()),'\\n')\n",
    "\n",
    "\n",
    "#method 4\n",
    "#this is just another wrapper around sentencepiece\n",
    "sp4 = tokenization.FullSentencePieceTokenizer(sentencepiece_path)\n",
    "tokens4= sp4.tokenize(actual_sentence)\n",
    "ids4 = sp4.convert_tokens_to_ids(tokens4)\n",
    "print('tokens4',tokens4, '\\nids4 ',ids4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would have noticed that in method 1) tf_sentencepiece i have to pass sequence_length for decoding\n",
    "Printing output from couple of other functions in sentencepiece, just to get a better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentencepieceEncodeDense(values=<tf.Tensor: shape=(1, 16), dtype=int32, numpy=\n",
       "array([[  590,    55,  7876,    20,  6557,  3284,  5477, 11969,   357,\n",
       "            8,  3099,     8,  1323,  1433,   159, 10114]], dtype=int32)>, sequence_length=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([16], dtype=int32)>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentencepieceEncodeDense(values=<tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
       "array([[  590,    55,  7876,    20,  6557,  3284,  5477, 11969,   357,\n",
       "            8,  3099,     8,  1323,  1433,   159, 10114],\n",
       "       [ 5123,  1289,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)>, sequence_length=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([16,  2], dtype=int32)>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.encode([actual_sentence,'sentence test'],model_proto=sp_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[4148, 48, 25], [1289, 485]]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp3.tokenize(['hi this is','test run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me directions to nearest restaurant randomtext 15-08-2019 year 2019'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pieces1  ['▁give', '▁me', '▁directions', '▁to', '▁nearest', '▁restaurant', '▁random', 'text', '▁15', '-', '08', '-', '20', '19', '▁year', '▁2019'] \n",
      "ids1  [590, 55, 7876, 20, 6557, 3284, 5477, 11969, 357, 8, 3099, 8, 1323, 1433, 159, 10114] \n",
      "\n",
      "pieces2  ['▁give', '▁me', '▁directions', '▁to', '▁nearest', 'rest', 'au', 'rant'] \n",
      "ids2  [590, 55, 7876, 20, 6557, 11466, 1346, 7874] \n",
      "pieces2_2  ['▁give', '▁me', '▁directions', '▁to', '▁nearest', 'rest', 'au', 'rant'] \n",
      "decoded_piece  give me directions to nearestrestaurant\n"
     ]
    }
   ],
   "source": [
    "pieces1 = sp2.encode_as_pieces(actual_sentence)\n",
    "ids1 = sp2.piece_to_id(pieces1)\n",
    "print('pieces1 ', pieces1 , '\\nids1 ',ids1,'\\n')\n",
    "\n",
    "pieces2 = sp2.encode_as_pieces('give me directions to nearestrestaurant')\n",
    "ids2 = sp2.piece_to_id(pieces2)\n",
    "pieces2_2 = sp2.id_to_piece(ids2)\n",
    "decoded_piece = sp2.decode_pieces(pieces2)\n",
    "\n",
    "print('pieces2 ', pieces2, '\\nids2 ',ids2,'\\npieces2_2 ',pieces2_2, '\\ndecoded_piece ',decoded_piece )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', '[CLS]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2.id_to_piece([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <pad>\n",
      "1 <unk>\n",
      "2 [CLS]\n",
      "3 [SEP]\n",
      "4 [MASK]\n",
      "5 (\n",
      "6 )\n",
      "7 \"\n",
      "8 -\n",
      "9 .\n",
      "10 –\n",
      "11 £\n",
      "12 €\n",
      "13 ▁\n",
      "14 ▁the\n",
      "15 ,\n",
      "16 ▁of\n",
      "17 ▁and\n",
      "18 s\n",
      "19 ▁in\n",
      "20 ▁to\n",
      "21 ▁a\n",
      "22 '\n",
      "23 ▁was\n",
      "24 ▁he\n",
      "25 ▁is\n",
      "26 ▁for\n",
      "27 ▁on\n",
      "28 ▁as\n",
      "29 ▁with\n",
      "30 ▁that\n",
      "31 ▁i\n",
      "32 ▁it\n",
      "33 ▁his\n",
      "34 ▁by\n",
      "35 ▁at\n",
      "36 ▁her\n",
      "37 ▁from\n",
      "38 t\n",
      "39 ▁she\n",
      "40 ▁an\n",
      "41 ▁had\n",
      "42 ▁you\n",
      "43 d\n",
      "44 ▁be\n",
      "45 :\n",
      "46 ▁were\n",
      "47 ▁but\n",
      "48 ▁this\n",
      "49 i\n",
      "50 ▁are\n",
      "51 ▁my\n",
      "52 ▁not\n",
      "53 ▁one\n",
      "54 ▁or\n",
      "55 ▁me\n",
      "56 ▁which\n",
      "57 ▁have\n",
      "58 a\n",
      "59 ▁they\n",
      "60 ?\n",
      "61 ▁him\n",
      "62 e\n",
      "63 ▁has\n",
      "64 ▁first\n",
      "65 ▁all\n",
      "66 ▁their\n",
      "67 ▁also\n",
      "68 ing\n",
      "69 ed\n",
      "70 ▁out\n",
      "71 ▁up\n",
      "72 ▁who\n",
      "73 ;\n",
      "74 ▁been\n",
      "75 ▁after\n",
      "76 ▁when\n",
      "77 ▁into\n",
      "78 ▁new\n",
      "79 m\n",
      "80 ▁there\n",
      "81 ▁two\n",
      "82 ▁its\n",
      "83 ▁would\n",
      "84 ▁over\n",
      "85 ▁time\n",
      "86 ▁so\n",
      "87 ▁said\n",
      "88 ▁about\n",
      "89 ▁other\n",
      "90 ▁no\n",
      "91 ▁more\n",
      "92 ▁can\n",
      "93 y\n",
      "94 ▁then\n",
      "95 ▁we\n",
      "96 th\n",
      "97 ▁back\n",
      "98 ▁what\n",
      "99 re\n"
     ]
    }
   ],
   "source": [
    "#printing out 1st 100 tokens, just to get a feel of what all entries are present\n",
    "for index,token in enumerate (sp2.id_to_piece([*range(100)])):\n",
    "    print(index,token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into TFRecords\n",
    "For following functionalities refer the file  - models/official/nlp/data/classifier_data_lib.py       \n",
    "This includes even the sentence piece tokenization part\n",
    "#### Defining an object for the 1 row of text input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#in our case we are doing just classification so we only need 1 text value = text_a\n",
    "class InputExample(object):\n",
    "    def __init__(self,uuid,text_a,text_b=None,label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "          uuid: Unique id for the example.\n",
    "          text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "          text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "          label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining an object for the 1 row of input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in the official one there was something called is_real_example as feature, here i skipped it since it's \n",
    "#only classification\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,input_ids,input_mask,\n",
    "                segment_ids,label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions for converting values to train features so that it can be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    print(\"type constant \",type(tf.constant(0)))\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(values):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\n",
    "      #Note that the Feature requires a list as input\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path=os.path.join(main_exp_folder,'train.tfrecords')\n",
    "eval_data_path=os.path.join(main_exp_folder,'eval.tfrecords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS_ID  2 , SEP_ID  3\n"
     ]
    }
   ],
   "source": [
    "#special tokens\n",
    "[CLS_ID,SEP_ID]  = tfs.piece_to_id(['[CLS]','[SEP]'],model_proto=sp_model_proto).numpy()\n",
    "print('CLS_ID ', CLS_ID, ', SEP_ID ', SEP_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function which converts a single input to Features, one of the feature being the sentencepiece encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(ex_index, example, label_list, max_seq_length,sp_proto):\n",
    "    ## please refer to functionality in file models/official/nlp/data/classifier_data_lib.py \n",
    "    ##this function is based on an older version & slightly different as in it's taking care of only \n",
    "    # the classification part\n",
    "    \n",
    "    # The convention in BERT is:\n",
    "    # (a) For sequence pairs:\n",
    "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "    # (b) For single sequences:\n",
    "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "    #  type_ids: 0     0   0   0  0     0 0\n",
    "    #\n",
    "    # Where \"type_ids\" are used to indicate whether this is the first\n",
    "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "    # embedding vector (and position vector). This is not *strictly* necessary\n",
    "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "    # it easier for the model to learn the concept of sequences.\n",
    "    #\n",
    "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "    # used as the \"sentence vector\". Note that this only makes sense because\n",
    "    # the entire model is fine-tuned.\n",
    "    \n",
    "#     CLS_ID = 2\n",
    "#     SEP_ID = 3\n",
    "    [CLS_ID,SEP_ID]  = tfs.piece_to_id(['[CLS]','[SEP]'],model_proto=sp_proto).numpy()\n",
    "    # -2 for [CLS], [SEP] \n",
    "    # we need to add these tokens in addition to the sentence words is while keeping the max sequence length limit\n",
    "    # check Bert paper for this [CLS] is added at the beginning & [SEP] after 1st sentence (in our classificatin example \n",
    "    # we don't differentiate the sentences here, so [SEP] is at the end. For challenges like SQUAD 2 sentences is \n",
    "    # where i have seen people use 2 sentences , 1st question & 2nd answer )\n",
    "    \n",
    "    max_word_ids = max_seq_length -2\n",
    "    input_ids = []\n",
    "    segment_ids = []\n",
    "    input_mask = []\n",
    "    input_ids.append(CLS_ID)\n",
    "    \n",
    "    word_ids = tfs.encode([example.text_a],model_proto=sp_proto).values[0]\n",
    "    \n",
    "#     print('word ids ',word_ids)\n",
    "# trimming to the max size\n",
    "    word_ids = word_ids[:max_word_ids]\n",
    "    input_ids.extend(word_ids)\n",
    "#     print(\"input text \",example.text)\n",
    "    input_ids.append(SEP_ID)\n",
    "    segment_ids = [0]*len(input_ids)\n",
    "    input_mask = [1]*len(input_ids)\n",
    "    if len(input_ids)<max_seq_length:\n",
    "        diff = max_seq_length - len(input_ids)\n",
    "        input_ids.extend([0]*diff)\n",
    "        segment_ids.extend([0]*diff)\n",
    "        input_mask.extend([0]*diff)\n",
    "    assert(len(input_ids)==max_seq_length)\n",
    "    assert(len(segment_ids)==max_seq_length)\n",
    "    assert(len(input_mask)==max_seq_length)\n",
    "    label_map = {label:i for i,label in enumerate(label_list)}\n",
    "    label_id = label_map[example.label]\n",
    "    if ex_index < 5:\n",
    "        logging.info(\"*** Example ***\")\n",
    "        logging.info(\"uuid: %s\", (example.uuid))\n",
    "        logging.info(\"tokens: %s\",\n",
    "                     \" \".join([str(x) for x in tfs.id_to_piece(input_ids,model_proto=sp_proto).numpy()]))\n",
    "        logging.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
    "        logging.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
    "        logging.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
    "        logging.info(\"label: %s (id = %d)\", example.label, label_id)\n",
    "\n",
    "    feature = InputFeatures(input_ids,input_mask,segment_ids,label_id)\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config_dict = {\n",
    "#     \"hidden_dropout_prob\":0,\n",
    "#     'initializer_range': 0.02\n",
    "# }\n",
    "# bert_config = albert_configs.AlbertConfig.from_dict(bert_config_dict)\n",
    "\n",
    "# in some cases it might be inside assets folder\n",
    "bert_config_file = os.path.join(bert_model_dir,'albert_config.json')\n",
    "\n",
    "# bert_config = modeling.AlbertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "bert_config = albert_configs.AlbertConfig.from_json_file(bert_config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 30000,\n",
       " 'hidden_size': 1024,\n",
       " 'num_hidden_layers': 24,\n",
       " 'num_attention_heads': 16,\n",
       " 'hidden_act': 'gelu',\n",
       " 'intermediate_size': 4096,\n",
       " 'hidden_dropout_prob': 0,\n",
       " 'attention_probs_dropout_prob': 0,\n",
       " 'max_position_embeddings': 512,\n",
       " 'type_vocab_size': 2,\n",
       " 'initializer_range': 0.02,\n",
       " 'backward_compatible': True,\n",
       " 'embedding_size': 128,\n",
       " 'num_hidden_groups': 1,\n",
       " 'net_structure_type': 0,\n",
       " 'gap_size': 0,\n",
       " 'num_memory_blocks': 0,\n",
       " 'inner_group_num': 1,\n",
       " 'down_scale_factor': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this for the Dropout probability between bert layer & final Dense layer\n",
    "bert_config.hidden_dropout_prob=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_length = bert_config.max_position_embeddings\n",
    "# could even keep max_seq_length as 512, but limiting to 128 for this expt\n",
    "max_seq_length = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the code which reads data line by line converts & writes the data in tfrecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refer file_based_convert_examples_to_features function in models/official/nlp/data/classifier_data_lib.py\n",
    "def write_training_data(input_csv_file,output_file,sentencepiece_path=None,sp_proto=None,delimiter='\\t',max_seq_length=128):\n",
    "    ##loading the sentence piece model into memory\n",
    "    if sp_proto ==None:\n",
    "        sp_proto = tf.io.gfile.GFile(sentencepiece_path, 'rb').read()\n",
    "   \n",
    "    with open(input_csv_file,'r',encoding='utf-8') as csv_file, tf.io.TFRecordWriter(output_file) as tf_record_writer:\n",
    "        #tried using binary format for bytes_list, but csv_reader requires text format\n",
    "#     with open(input_csv_file,'rb') as csv_file, tf.io.TFRecordWriter(output_file) as tf_record_writer:\n",
    "        csv_reader = csv.reader(csv_file,delimiter=delimiter,quotechar='\"')\n",
    "        for i,cols in enumerate(csv_reader):\n",
    "            ##skipping filename & granular tag (granular tag & final tag are the same here)\n",
    "#             yield cols[1:-1]\n",
    "            features = collections.OrderedDict()\n",
    "            \n",
    "            uuid = cols[0]\n",
    "            text = cols[1]\n",
    "            if(len(cols)<4):\n",
    "                print('uuid ',uuid)\n",
    "            intent = cols[2]\n",
    "            input_example = InputExample(uuid,text,label=intent)\n",
    "            #this will encode the text,label into ids \n",
    "            feature = convert_single_example(ex_index=i,example=input_example,label_list=intent_list,\n",
    "                                             max_seq_length=max_seq_length,sp_proto=sp_proto)\n",
    "            features[\"input_ids\"] = _int64_feature(feature.input_ids)\n",
    "            features[\"input_mask\"] = _int64_feature(feature.input_mask)\n",
    "            features[\"segment_ids\"] = _int64_feature(feature.segment_ids)\n",
    "            #Note making it as a list & passing it\n",
    "            features[\"label_id\"] = _int64_feature([feature.label_id])\n",
    "#             features[\"is_real_example\"]\n",
    "            tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "            tf_record_writer.write(tf_example.SerializeToString())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_training_data(train_csv_file,train_data_path,sp_proto=sp_model_proto,max_seq_length=max_seq_length)\n",
    "write_training_data(eval_csv_file,eval_data_path,sp_proto=sp_model_proto,max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data from tfrecord to provide to training graph\n",
    "Before we write the actual code to read it let's just explore some of the functions in tf.data api & on how to decode the tfrecord data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = tf.data.TFRecordDataset(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_data(record):\n",
    "    features = {\n",
    "        \"input_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"input_mask\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"segment_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"label_id\":tf.io.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    "#     features = {\n",
    "#         'uuid':tf.io.FixedLenFeature([],tf.string),\n",
    "#         'text':tf.io.VarLenFeature(tf.int64),\n",
    "#         'intent':tf.io.FixedLenFeature([],tf.string)\n",
    "#     }    \n",
    "    return tf.io.parse_single_example(record,features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map function processes line by line, similar to spark,scala map or pandas apply fucntion\n",
    "processed_data = raw_ds.map(_decode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([    2,   483,   144,    51,  1071,  1839,    34, 14737,    37,\n",
      "         236,   818,  1071,    60,     3,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0])>, 'input_mask': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'label_id': <tf.Tensor: shape=(), dtype=int64, numpy=103>, 'segment_ids': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>}\n",
      "{'input_ids': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([   2,   13,    1,  259,   20, 3547,   14, 1889, 2440, 3607,    3,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0])>, 'input_mask': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'label_id': <tf.Tensor: shape=(), dtype=int64, numpy=34>, 'segment_ids': <tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>}\n"
     ]
    }
   ],
   "source": [
    "## taking only 2 rows & iterating & viewing output\n",
    "for line in processed_data.take(2):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for reading & creating a dataset object from tfrecord\n",
    "putting the same code above into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_dataset(input_file,seq_length,batch_size,is_training=True):\n",
    "# this is a simplified version & slightly less optimized version of what is used in official bert training\n",
    "# refer to function create_classifier_dataset in models/official/nlp/data/create_finetuning_data.py\n",
    "\n",
    "\n",
    "    # create a tf_data set out of the tfrecords file\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    name_to_features = {\n",
    "        \"input_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"input_mask\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"segment_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"label_id\":tf.io.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    "    ## map function processes line by line, similar to spark,scala map or pandas apply fucntion\n",
    "    dataset = dataset.map(lambda record: tf.io.parse_single_example(record, name_to_features))\n",
    "#     or could even do this\n",
    "#     dataset = dataset.map(_decode_data)\n",
    "    \n",
    "#     now separating out the features & label\n",
    "    def _select_data_from_record(record):\n",
    "#         x contains the features\n",
    "#         y is your prediction\n",
    "# This dataset will be passed to keras's model.fit refer to it's documentation for further details\n",
    "# a short snippet from that documentation\n",
    "\n",
    "# A `tf.data` dataset. Should return a tuple\n",
    "#         of either `(inputs, targets)` or\n",
    "#         `(inputs, targets, sample_weights)`.\n",
    "\n",
    "# Even a tuple of values for x works, but list doesn't work\n",
    "#         x = (\n",
    "#             record['input_ids'],\n",
    "#             record['input_mask'],\n",
    "#             record['segment_ids']\n",
    "#         )\n",
    "\n",
    "        x = {\n",
    "            'input_ids': record['input_ids'],\n",
    "            'input_mask': record['input_mask'],\n",
    "            'segment_ids': record['segment_ids']\n",
    "        }\n",
    "\n",
    "        y = record['label_id']\n",
    "        # our dataset is returning a tuple (x,y) - x are the features\n",
    "        return (x, y)\n",
    "    \n",
    "    dataset = dataset.map(_select_data_from_record)\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(100)\n",
    "        dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(5)\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n"
     ]
    }
   ],
   "source": [
    "steps_per_loop = 1\n",
    "learning_rate=1e-5\n",
    "epochs=10\n",
    "\n",
    "train_batch_size=16\n",
    "eval_batch_size=16\n",
    "\n",
    "train_data_size = input_meta_data['train_data_size']\n",
    "steps_per_epoch = int(train_data_size / train_batch_size)\n",
    "print(steps_per_epoch)\n",
    "\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / train_batch_size)\n",
    "eval_steps = int(math.ceil(input_meta_data['eval_data_size'] / eval_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = get_classifier_dataset(train_data_path,max_seq_length,train_batch_size,is_training=True)\n",
    "evaluation_dataset = get_classifier_dataset(eval_data_path,max_seq_length,eval_batch_size,is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[  2,  13,   1, ...,   0,   0,   0],\n",
      "       [  2, 420,  21, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  2, 483, 144, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
      "array([ 29, 128,  34, 103,  88,  97, 103,  42,  30, 128,  97,  87,  30,\n",
      "       103,  53,  36])>)\n",
      "({'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[ 2, 25, 51, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 2, 25, 80, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=\n",
      "array([ 39,  30,  63, 128,  91,  40,   5,  26,  34,   2,   1, 133, 128,\n",
      "        30,  30,  32])>)\n"
     ]
    }
   ],
   "source": [
    "## taking only 2 rows & iterating & viewing output\n",
    "for line in training_dataset.take(2):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model code, graph creation\n",
    "This section is the core logic of the model, here we are using tensorflow hub url for albert model. Using hub simplifies the code a lot      \n",
    "It's a slightly simplied version of official bert code, that code have functionality to load a non hub model. \n",
    "#### refer to models/official/nlp/bert/run_classifier.py\n",
    "Since in this notebook we are only using one gpu, we can even ignore the strategy part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = distribution_utils.get_distribution_strategy('mirrored',num_gpus=1)\n",
    "\n",
    "# strategy = tf.distribute.OneDeviceStrategy(\"device:GPU:2\")\n",
    "#since devices to use is set to 2 already, only 1 device is visible which is 0\n",
    "strategy = tf.distribute.OneDeviceStrategy(\"device:GPU:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary tryouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_keras_layer = hub.KerasLayer(bert_hub_url,trainable=True,tags=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_loaded = hub.load(bert_hub_url,tags=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'keras_layer',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'handle': 'https://tfhub.dev/tensorflow/albert_en_large/1'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_keras_layer.get_config()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert_keras_layer.resolved_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load._WrapperFunction at 0x7fad48196e10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = bert_loaded.signatures['serving_default']\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'/space/engineering/tfhub_modules/d0ceaf43f67b8744561ebeeaea4c7c188a6e6f78/assets/30k-clean.model'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_hub_loaded.sp_model_file.asset_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.utils.register_keras_serializable()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###custom code from saved model folder (not hub url)\n",
    "# How does it differentiate between the bert vs albert - models/official/nlp/bert/bert_models.py\n",
    "  if isinstance(bert_config, albert_configs.AlbertConfig):  \n",
    "        kwargs['embedding_width'] = bert_config.embedding_size\n",
    "    return networks.AlbertTransformerEncoder(**kwargs)                                                                                                                 else:\n",
    "    assert isinstance(bert_config, configs.BertConfig)                                                                                                                   return networks.TransformerEncoder(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the graph\n",
    "It's just this function & your graph definition is done :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albert_model(bert_config,num_labels,max_seq_length,hub_url):\n",
    "    \"\"\"This function return our classification model based on bert + original bert model\"\"\"\n",
    "#     https://www.tensorflow.org/hub/reusable_saved_models\n",
    "    ## Note that name parameter specified here is the same as the feature name keys in the dictionary (x) in tf.data dataset  \n",
    "    # Apparantely the code even works even if the name of the input specified here & as the key value to inputs dictionary of tf.keras.Model\n",
    "    # are different from the tf.data.Dataset input. But let's not rely on that, that seems like a potential bug\n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='segment_ids')\n",
    "    \n",
    "    bert_model = hub.KerasLayer(hub_url,trainable=True,tags=None)\n",
    "    ### pooled_output will give the representation for [CLS]\n",
    "    ### sequence_output will give representations for all tokens\n",
    "    ##since it's classification task we will just use pooled_output\n",
    "    pooled_output, sequence_output = bert_model([input_ids, input_mask, segment_ids])\n",
    "    bert_output = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(pooled_output) \n",
    "    \n",
    "    initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "    output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(bert_output)\n",
    "    \n",
    "    return tf.keras.Model(inputs={'input_ids':input_ids,\n",
    "                                 'input_mask':input_mask,\n",
    "                                 'segment_ids':segment_ids},\n",
    "                         outputs=output),bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the classification model description/summary\n",
    "We are calling get_albert_model here just to print out model summary, otherwise we call it internally\n",
    "in another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_model,core_bert_model = get_albert_model(bert_config=bert_config,\n",
    "                                                              num_labels=input_meta_data['num_labels'],\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               hub_url=bert_hub_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 17683968    input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 142)          145550      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,829,518\n",
      "Trainable params: 17,829,518\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 128),\n",
       "    'dtype': 'int32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_ids'},\n",
       "   'name': 'input_ids',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 128),\n",
       "    'dtype': 'int32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_mask'},\n",
       "   'name': 'input_mask',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 128),\n",
       "    'dtype': 'int32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'segment_ids'},\n",
       "   'name': 'segment_ids',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'KerasLayer',\n",
       "   'config': {'name': 'keras_layer',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'handle': 'https://tfhub.dev/tensorflow/albert_en_large/1'},\n",
       "   'name': 'keras_layer',\n",
       "   'inbound_nodes': [[['input_ids', 0, 0, {}],\n",
       "     ['input_mask', 0, 0, {}],\n",
       "     ['segment_ids', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.2,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'name': 'dropout',\n",
       "   'inbound_nodes': [[['keras_layer', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'output',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 142,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'TruncatedNormal',\n",
       "     'config': {'mean': 0.0, 'stddev': 0.02, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'output',\n",
       "   'inbound_nodes': [[['dropout', 0, 0, {}]]]}],\n",
       " 'input_layers': {'input_ids': ['input_ids', 0, 0],\n",
       "  'input_mask': ['input_mask', 0, 0],\n",
       "  'segment_ids': ['segment_ids', 0, 0]},\n",
       " 'output_layers': [['output', 0, 0]]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'keras_layer',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'handle': 'https://tfhub.dev/tensorflow/albert_en_large/1'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_bert_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss function,  metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_fn(num_classes, loss_factor=1.0):\n",
    "    \"\"\"Gets the classification loss function.\"\"\"\n",
    "\n",
    "    def classification_loss_fn(labels, logits):\n",
    "        \"\"\"Classification loss.\"\"\"\n",
    "        labels = tf.squeeze(labels)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        one_hot_labels = tf.one_hot(\n",
    "            tf.cast(labels, dtype=tf.int32), depth=num_classes, dtype=tf.float32)\n",
    "        per_example_loss = -tf.reduce_sum(\n",
    "            tf.cast(one_hot_labels, dtype=tf.float32) * log_probs, axis=-1)\n",
    "        #batch loss\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        loss *= loss_factor\n",
    "        return loss\n",
    "    return classification_loss_fn  \n",
    "\n",
    "\n",
    "def metric_fn():\n",
    "    return tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy',dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for running training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_keras_compile_fit(model_dir,\n",
    "                          strategy,\n",
    "                          model_fn,\n",
    "                          training_dataset,\n",
    "                          evaluation_dataset,\n",
    "                          loss_fn,\n",
    "                          metric_fn,\n",
    "                          init_checkpoint,\n",
    "                          epochs,\n",
    "                          steps_per_epoch,\n",
    "                          steps_per_loop,\n",
    "                          eval_steps,\n",
    "                          custom_callbacks=None):\n",
    "    \"\"\"Runs BERT classifier model using Keras compile/fit API.\"\"\"\n",
    "    ###slightly simplied version of official bert code \n",
    "    # refer to models/official/nlp/bert/run_classifier.py -   function run_keras_compile_fit\n",
    "    # if you running on a single gpu or on just cpu this strategy is not necessary\n",
    "    with strategy.scope():\n",
    "        #sub_model is the original bert\n",
    "        classification_model, sub_model = model_fn()\n",
    "        optimizer = classification_model.optimizer\n",
    "        \n",
    "        # this is not required for the hub version of the model, this restore method is trying to restor values,\n",
    "        # from a saved bert model (since we have only provided the sub_model to checkpoint)\n",
    "        # Let's saying we stopped training at some point & want to continue from that point next time,\n",
    "        # here we can instead load our classification_model & init_checkpoint can be our previous saved checkpoint file\n",
    "        if init_checkpoint:\n",
    "            checkpoint = tf.train.Checkpoint(model=sub_model)\n",
    "            checkpoint.restore(init_checkpoint).assert_existing_objects_matched()\n",
    "\n",
    "        classification_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=[metric_fn()])\n",
    "    #     ,experimental_steps_per_execution=steps_per_loop)\n",
    "\n",
    "        summary_dir = os.path.join(model_dir, 'summaries')\n",
    "        summary_callback = tf.keras.callbacks.TensorBoard(summary_dir)\n",
    "        checkpoint_path = os.path.join(model_dir, 'checkpoint')\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_path, save_weights_only=True)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "\n",
    "        if custom_callbacks is not None:\n",
    "            custom_callbacks += [summary_callback, checkpoint_callback, early_stopping]\n",
    "        else:\n",
    "            custom_callbacks = [summary_callback, checkpoint_callback, early_stopping]\n",
    "#       Note that we are only passing x & not y in fit function\n",
    "#       Refer to keras model.fit documentation for further details\n",
    "\n",
    "#       If `x` is a dataset, generator,\n",
    "#       or `keras.utils.Sequence` instance, `y` should\n",
    "#       not be specified (since targets will be obtained from `x`).\n",
    "        model_history = classification_model.fit(\n",
    "            x=training_dataset,\n",
    "            validation_data=evaluation_dataset,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "            validation_steps=eval_steps,\n",
    "            callbacks=custom_callbacks)\n",
    "\n",
    "        return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clearing the existing graphs\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1285/1285 [==============================] - 967s 752ms/step - loss: 4.1694 - test_accuracy: 0.1472 - val_loss: 2.9912 - val_test_accuracy: 0.4090\n",
      "Epoch 2/20\n",
      "1285/1285 [==============================] - 969s 754ms/step - loss: 2.3306 - test_accuracy: 0.5118 - val_loss: 1.8371 - val_test_accuracy: 0.6059\n",
      "Epoch 3/20\n",
      "1285/1285 [==============================] - 970s 755ms/step - loss: 1.5524 - test_accuracy: 0.6758 - val_loss: 1.4411 - val_test_accuracy: 0.6897\n",
      "Epoch 4/20\n",
      "1285/1285 [==============================] - 971s 756ms/step - loss: 1.1426 - test_accuracy: 0.7578 - val_loss: 1.2217 - val_test_accuracy: 0.7329\n",
      "Epoch 5/20\n",
      "1285/1285 [==============================] - 972s 757ms/step - loss: 0.8821 - test_accuracy: 0.8107 - val_loss: 1.1210 - val_test_accuracy: 0.7496\n",
      "Epoch 6/20\n",
      "1285/1285 [==============================] - 973s 757ms/step - loss: 0.7038 - test_accuracy: 0.8472 - val_loss: 1.0250 - val_test_accuracy: 0.7747\n",
      "Epoch 7/20\n",
      "1285/1285 [==============================] - 974s 758ms/step - loss: 0.5796 - test_accuracy: 0.8722 - val_loss: 1.0059 - val_test_accuracy: 0.7795\n",
      "Epoch 8/20\n",
      "1285/1285 [==============================] - 973s 757ms/step - loss: 0.4617 - test_accuracy: 0.9007 - val_loss: 0.9761 - val_test_accuracy: 0.7842\n",
      "Epoch 9/20\n",
      "1285/1285 [==============================] - 973s 757ms/step - loss: 0.3737 - test_accuracy: 0.9228 - val_loss: 0.9731 - val_test_accuracy: 0.7873\n",
      "Epoch 10/20\n",
      "1285/1285 [==============================] - 973s 757ms/step - loss: 0.3064 - test_accuracy: 0.9394 - val_loss: 0.9455 - val_test_accuracy: 0.7926\n",
      "Epoch 11/20\n",
      "1285/1285 [==============================] - 974s 758ms/step - loss: 0.2548 - test_accuracy: 0.9526 - val_loss: 0.9469 - val_test_accuracy: 0.8002\n"
     ]
    }
   ],
   "source": [
    "loss_multiplier = 1\n",
    "max_seq_length = input_meta_data['max_seq_length']\n",
    "num_classes = input_meta_data['num_labels']\n",
    "loss_fn = get_loss_fn(num_classes,loss_multiplier)\n",
    "epochs=20\n",
    "initial_lr = learning_rate\n",
    "def _get_classifier_model():\n",
    "    classifier_model,core_model = get_albert_model(bert_config=bert_config,\n",
    "                                                              num_labels=num_classes,\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               hub_url=bert_hub_url)\n",
    "    ##This is basically Adam optimizer with weight decay after set no of warm up steps & \n",
    "    # before that an increasing learning rate from 0 to initial_lr\n",
    "    # refer to models/official/nlp/optimization.py for more details\n",
    "    classifier_model.optimizer = optimization.create_optimizer(init_lr=initial_lr,\n",
    "                                                               num_train_steps=steps_per_epoch*epochs,\n",
    "                                                               num_warmup_steps=warmup_steps)\n",
    "    return classifier_model,core_model\n",
    "\n",
    "trained_model = run_keras_compile_fit(model_dir=output_folder,strategy=strategy,model_fn=_get_classifier_model,\n",
    "                                     training_dataset=training_dataset,evaluation_dataset=evaluation_dataset,\n",
    "                                      loss_fn=loss_fn,metric_fn=metric_fn,\n",
    "                                     init_checkpoint=None,\n",
    "                                      epochs=epochs,\n",
    "                                      steps_per_epoch=steps_per_epoch,\n",
    "                                      steps_per_loop=steps_per_loop,\n",
    "                                      eval_steps=eval_steps\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "The model that we trained right now takes the sentence piece encoded list as input, along with input_mask list, segment_ids list\n",
    "When we are deploying we want to give a text as input & get the text label as output.   \n",
    "So what we are going to do is to have a graph with sentence piece encoding within the graph itself & create input_mask, segment_ids also as part of the graph for input   \n",
    "For the output have a softmax & a table lookup to on labels to return the label name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence piece tokenizaton\n",
    "I'll walk through details of this Layer after we are done saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.keras.utils.register_keras_serializable(package=\"Text\")\n",
    "\n",
    "class SentencepieceTokenization(tf.keras.layers.Layer):\n",
    "    def __init__(self,model_path,max_seq_length):\n",
    "        super(SentencepieceTokenization, self).__init__(trainable=False,dtype=tf.int32)\n",
    "        self.model_path = model_path\n",
    "        # TODO keep a tf.constant else tracing issues \n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.model_proto = tf.io.gfile.GFile(self.model_path, 'rb').read()\n",
    "        ## pad_id is usually 0 \n",
    "        [self.CLS_ID,self.SEP_ID,self.PAD_ID]  = tfs.piece_to_id(['[CLS]','[SEP]','<pad>'],model_file=self.model_path)\n",
    "        self.built=True\n",
    "        \n",
    "#     @tf.function    \n",
    "    def call(self, input_text):\n",
    "        ##tensorflow sentence piece works while exporting to graph while, tf_text sentencepiece doesn't\n",
    "        encoded_text = self.get_encoded_text(input_text,max_sequence_length=self.max_seq_length)\n",
    "        return encoded_text\n",
    "\n",
    "#     @tf.function\n",
    "    def get_encoded_text(self,input_text_batch,max_sequence_length):\n",
    "        def process_invidual_line_encoding(x):\n",
    "#             tf sentencepiece requires a list as input, while the individual value that we get here\n",
    "#             is a single sentence, so adding one more dimension (i.e adding batch dimension = 1)\n",
    "            list_x = tf.expand_dims(x,axis=0)\n",
    "            sp_encoded = tfs.encode(list_x,model_proto=self.model_proto)\n",
    "    #         removing the batch dim with size=1 (which we added in the previous step)\n",
    "            values = tf.squeeze(sp_encoded.values,name='squeezed_values')\n",
    "            sequence_length = tf.squeeze(sp_encoded.sequence_length)\n",
    "    #         trimming to max_length-2 (-2 to incorporate [CLS], [SEP])\n",
    "            trimmed_max_length = max_sequence_length-2\n",
    "            values_trimmed = tf.cond(tf.greater(sequence_length,trimmed_max_length), \n",
    "                                    lambda : tf.slice(values,begin=[0],size=[trimmed_max_length],name='trimmed_out'),lambda : values)\n",
    "            concat = tf.concat([[self.CLS_ID],values_trimmed,[self.SEP_ID]],axis=0,name='concat_out')\n",
    "            # tf.shape gives dynamic shape &\n",
    "            # tenorflow_variable.shape gives static shape with dynamic entries = None\n",
    "            actual_token_length = tf.shape(concat)[-1]\n",
    "            # need not prepend anything so 0 for 1st entry in padding, \n",
    "            # & next value for padding is how many dimensions required at the end of tensor\n",
    "            padded = tf.pad(concat,paddings=[[0,max_sequence_length-actual_token_length]],name='input_ids')\n",
    "    #         segment_ids = tf.zeros(shape=tf.shape(padded),dtype=tf.int32)\n",
    "    #         or\n",
    "            # This will create zeros with similar shape as padded tensor\n",
    "            segment_ids = tf.zeros_like(padded,dtype=tf.int32,name='segment_ids')\n",
    "            \n",
    "            # This tensor is zero initialized & will update 0th index till actual_token_length with 1\n",
    "            input_mask = tf.scatter_nd(indices=tf.expand_dims(tf.range(0,actual_token_length),axis=1),\n",
    "                                       updates=tf.ones(shape=[actual_token_length],dtype=tf.int32),\n",
    "                                       shape=[max_sequence_length],name='input_mask')\n",
    "            return (padded,segment_ids,input_mask)\n",
    "    #     Issue running map_fn on gpu https://github.com/tensorflow/tensorflow/issues/28007 \n",
    "    #     https://www.tensorflow.org/api_docs/python/tf/device\n",
    "        with tf.device('/device:CPU:0'):\n",
    "            encoded = tf.map_fn(lambda x: process_invidual_line_encoding(x),input_text_batch,dtype=(tf.int32,tf.int32,tf.int32))\n",
    "            return encoded\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SentencepieceTokenization, self).get_config()\n",
    "        config.update({'model_path': self.model_path})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelLookup(tf.keras.layers.Layer):\n",
    "#     def __init__(self,model_proto):\n",
    "    def __init__(self,filepath,default):\n",
    "        \"\"\" \n",
    "        filepath - path to the text file with 1 label per line\n",
    "        \"\"\"\n",
    "        super(LabelLookup, self).__init__(trainable=False,dtype=tf.int32)\n",
    "        self.filepath = filepath\n",
    "        self.default=default\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        # need to convert label index to label name. So keeping line no as key & whole text line as label\n",
    "        # issue with using table lookup (both file based & key value tensorbased) in tf2.2 (tf2.x) - https://github.com/tensorflow/tensorflow/issues/38305\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.TextFileInitializer(self.filepath,\n",
    "                                          key_dtype=tf.int64,key_index=tf.lookup.TextFileIndex.LINE_NUMBER,\n",
    "                                     value_dtype=tf.string,value_index=tf.lookup.TextFileIndex.WHOLE_LINE),self.default)\n",
    "        self.built=True\n",
    "        \n",
    "    def call(self, input_text):\n",
    "        word_ids = self.table.lookup(input_text)\n",
    "        return word_ids\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(LabelLookup, self).get_config()\n",
    "#         config.update({'filepath': self.filepath})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow_hub.keras_layer.KerasLayer object at 0x7fad24620dd0> and <tensorflow.python.keras.layers.core.Dense object at 0x7facac64c3d0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow_hub.keras_layer.KerasLayer object at 0x7fad24620dd0> and <tensorflow.python.keras.layers.core.Dense object at 0x7facac64c3d0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7facac64c3d0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fabd81a50d0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7facac64c3d0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fabd81a50d0>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fabd81a3bd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = input_meta_data['max_seq_length']\n",
    "num_labels = input_meta_data['num_labels']\n",
    "initial_lr = learning_rate\n",
    "default_label_index = 1\n",
    "default_label='other-other'\n",
    "checkpoint_path=tf.train.latest_checkpoint(output_folder)\n",
    "\n",
    "input_text = tf.keras.Input(shape=(),dtype=tf.string,name='input_text')\n",
    "sentence_piece_layer = SentencepieceTokenization(model_path=sentencepiece_path,max_seq_length=tf.constant(max_seq_length))\n",
    "input_ids_processed,segment_ids_processed,input_mask_processed = sentence_piece_layer(input_text)\n",
    "\n",
    "\n",
    "bert_model = hub.KerasLayer(bert_hub_url,trainable=True,tags=None)\n",
    "### pooled_output will give the representation for [CLS]\n",
    "### sequence_output will give representations for all tokens\n",
    "## since it's classification task we will just use pooled_output\n",
    "pooled_output, sequence_output = bert_model([input_ids_processed, input_mask_processed, segment_ids_processed])\n",
    "#     bert_output = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(pooled_output) \n",
    "\n",
    "# This doesn't really matter as we will be loading the weights from saved checkpoint\n",
    "initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "#     output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(bert_output)\n",
    "# dense_output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32,activation='softmax')(pooled_output)\n",
    "dense_output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(pooled_output)\n",
    "# log_probs = tf.nn.softmax()\n",
    "log_probs = tf.nn.log_softmax(dense_output, axis=-1)\n",
    "label_id = tf.argmax(log_probs,axis=-1)\n",
    "\n",
    "label = LabelLookup(filepath=intent_file,default=default_label)(label_id)\n",
    "\n",
    "loaded_model  = tf.keras.Model(inputs={'input_text':input_text},\n",
    "                     outputs=label)\n",
    "# loaded_model.compile()\n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "loaded_model.load_weights(checkpoint_path).assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'representative-request'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(['talk to agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sentencepiece_tokenization_2/Identity:0' shape=(None, None) dtype=int32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {i:label for i,label in enumerate(intent_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'representative-request'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map.get(131)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put the loading model part into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albert_model_saving(bert_config,input_meta_data,hub_url,checkpoint_path,sentencepiece_path,label_file):\n",
    "    \"\"\"This function return our classification model based on bert + updated bert part of model \"\"\"\n",
    "\n",
    "    max_seq_length = input_meta_data['max_seq_length']\n",
    "    num_labels = input_meta_data['num_labels']\n",
    "    default_label = tf.constant(input_meta_data['default_label'])\n",
    "    #alternative way of giving input by specifying the entire text & do the preprocessing in the graph\n",
    "    input_text = tf.keras.Input(shape=(),dtype=tf.string,name='input_text')\n",
    "    sentence_piece_layer = SentencepieceTokenization(model_path=sentencepiece_path,max_seq_length=tf.constant(max_seq_length))\n",
    "    input_ids_processed,segment_ids_processed,input_mask_processed = sentence_piece_layer(input_text)\n",
    "    \n",
    "    \n",
    "    bert_model = hub.KerasLayer(hub_url,trainable=True,tags=None)\n",
    "    ### pooled_output will give the representation for [CLS]\n",
    "    ### sequence_output will give representations for all tokens\n",
    "    ##since it's classification task we will just use pooled_output\n",
    "    pooled_output, sequence_output = bert_model([input_ids_processed, input_mask_processed, segment_ids_processed])\n",
    "    \n",
    "    # This doesn't really matter as we will be loading the weights from saved checkpoint\n",
    "    initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "    # we don't want dropout for the model we are going to serve so skipping that\n",
    "    dense_output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(pooled_output)\n",
    "    # log_probs = tf.nn.softmax()\n",
    "    log_probs = tf.nn.log_softmax(dense_output, axis=-1)\n",
    "    label_id = tf.argmax(log_probs,axis=-1)\n",
    "\n",
    "    label = LabelLookup(filepath=label_file,default=default_label)(label_id)\n",
    "\n",
    "    model  = tf.keras.Model(inputs={'input_text':input_text},\n",
    "                         outputs={'label':label,'score':log_probs[label_id]})\n",
    "    \n",
    "#     checkpoint = tf.train.Checkpoint(model=model)\n",
    "#     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "    model.load_weights(checkpoint_path).assert_existing_objects_matched()\n",
    "    return model,bert_model, input_text,label,log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tf.constant([1.0,2.0])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(temp,[1],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.piece_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/space/engineering/tfhub_modules/d0ceaf43f67b8744561ebeeaea4c7c188a6e6f78/assets/30k-clean.model'\n",
      "/space/engineering/tfhub_modules/d0ceaf43f67b8744561ebeeaea4c7c188a6e6f78/assets/30k-clean.model\n"
     ]
    }
   ],
   "source": [
    "print(sentencepiece_path)\n",
    "sentencepiece_path = sentencepiece_path.decode('utf-8')\n",
    "print(sentencepiece_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = intent_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor 'ArgMax:0' shape=(None,) dtype=int64>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e38be208ffef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                      \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                     \u001b[0msentencepiece_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentencepiece_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                                      \u001b[0mlabel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                                     )\n",
      "\u001b[0;32m<ipython-input-94-b3302f7521a0>\u001b[0m in \u001b[0;36mget_albert_model_saving\u001b[0;34m(bert_config, input_meta_data, hub_url, checkpoint_path, sentencepiece_path, label_file)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     model  = tf.keras.Model(inputs={'input_text':input_text},\n\u001b[0;32m---> 30\u001b[0;31m                          outputs={'label':label,'score':log_probs[label_id]})\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     checkpoint = tf.train.Checkpoint(model=model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m       \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor 'ArgMax:0' shape=(None,) dtype=int64>"
     ]
    }
   ],
   "source": [
    "classification_model_to_save, bert_updated,input_text,label,log_probs = get_albert_model_saving(bert_config,\n",
    "                                                                     input_meta_data,\n",
    "                                                                     bert_hub_url,\n",
    "                                                                     checkpoint_path=tf.train.latest_checkpoint(output_folder),\n",
    "                                                                    sentencepiece_path=sentencepiece_path,\n",
    "                                                                     label_file=label_file\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.word_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.position_embedding/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.type_embeddings/embeddings:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings/layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embedding_projection/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/query/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/key/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention/value/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/self_attention_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/intermediate/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/gamma:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.transformer/output_layer_norm/beta:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.pooler_transform/bias:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /space/engineering/tf_serve/models/tryout_jithin_3/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /space/engineering/tf_serve/models/tryout_jithin_3/1/assets\n"
     ]
    }
   ],
   "source": [
    "# final_model_path=os.path.join(output_folder,'final_model')\n",
    "final_model_path3='/space/engineering/tf_serve/models/tryout_jithin_3'\n",
    "classification_model_to_save.save(os.path.join(final_model_path3,'1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_text (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sentencepiece_tokenization (Sen ((None, None), (None 0           input_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 17683968    sentencepiece_tokenization[0][0] \n",
      "                                                                 sentencepiece_tokenization[0][2] \n",
      "                                                                 sentencepiece_tokenization[0][1] \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 142)          145550      keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogSoftmax (TensorF [(None, 142)]        0           output[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ArgMax (TensorFlowO [(None,)]            0           tf_op_layer_LogSoftmax[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "label_lookup (LabelLookup)      (None,)              0           tf_op_layer_ArgMax[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 17,829,518\n",
      "Trainable params: 17,829,518\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model_to_save.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 128,\n",
       " 'num_labels': 142,\n",
       " 'train_data_size': 20574,\n",
       " 'eval_data_size': 5144,\n",
       " 'default_label': 'other-other'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'position_embedding/embeddings:0' shape=(512, 128) dtype=float32, numpy=\narray([[ 0.04171413, -0.05951454,  0.00528023, ..., -0.00547502,\n        -0.00608543,  0.01891393],\n       [ 0.01842086, -0.00854636,  0.01457946, ..., -0.2188653 ,\n        -0.02077591,  0.05037078],\n       [-0.02886076, -0.01502202,  0.02091144, ..., -0.16695945,\n        -0.0303349 ,  0.06738311],\n       ...,\n       [ 0.05315233,  0.00108237,  0.01054862, ..., -0.11003321,\n         0.00282854, -0.01345602],\n       [ 0.02562682, -0.06601355, -0.01717755, ..., -0.13026832,\n        -0.00394623,  0.04304561],\n       [ 0.02484268, -0.03633654, -0.03465453, ..., -0.08623783,\n        -0.00122317,  0.00660813]], dtype=float32)>, <tf.Variable 'transformer/self_attention/query/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[ 2.45376015e+00,  4.76708263e-02, -1.26744613e-01, ...,\n        -3.46782118e-01, -2.13123128e-01,  1.15038261e-01],\n       [ 9.12567750e-02,  1.93411217e-03,  2.07950562e-01, ...,\n        -1.40724576e+00,  8.51527974e-03, -8.34104978e-03],\n       [ 5.74417651e-01,  5.32591999e-01, -1.39200494e-01, ...,\n         1.49228200e-01, -1.09081835e-01,  5.10540567e-02],\n       ...,\n       [ 1.98225096e-01,  1.18390076e-01, -1.38897151e-02, ...,\n         2.18401536e-01, -1.01841846e-02, -2.01080218e-01],\n       [ 1.70461401e-01, -4.32333685e-02,  6.05556890e-02, ...,\n        -2.54708380e-01, -4.64531891e-02, -2.82951653e-01],\n       [ 2.12428659e-01,  3.77846628e-01,  3.82576555e-01, ...,\n        -4.46735799e-01, -2.10399985e-01,  3.62275302e-01]], dtype=float32)>, <tf.Variable 'embedding_projection/kernel:0' shape=(128, 1024) dtype=float32, numpy=\narray([[-0.03311966, -0.01145261, -0.01302266, ...,  0.03378126,\n         0.03187594, -0.07032862],\n       [-0.01979856, -0.01833594, -0.00088798, ...,  0.00279429,\n         0.01289404, -0.05421524],\n       [-0.00527666, -0.00531581,  0.00867427, ..., -0.00036586,\n         0.0088558 , -0.00422233],\n       ...,\n       [ 0.03803551,  0.01312911,  0.03702177, ...,  0.04629155,\n        -0.02312718, -0.0257398 ],\n       [ 0.05053426,  0.04734649, -0.02995732, ...,  0.03516439,\n        -0.00742496, -0.01042338],\n       [ 0.01236061, -0.01599358,  0.00260928, ..., -0.02889969,\n        -0.00557954, -0.00491254]], dtype=float32)>, <tf.Variable 'transformer/self_attention_layer_norm/gamma:0' shape=(1024,) dtype=float32, numpy=\narray([0.47873768, 0.56642795, 0.479606  , ..., 0.48143235, 0.4791084 ,\n       0.50819606], dtype=float32)>, <tf.Variable 'embedding_projection/bias:0' shape=(1024,) dtype=float32, numpy=\narray([ 0.01374829,  0.08602794,  0.07090328, ..., -0.04428381,\n        0.01013557,  0.02760786], dtype=float32)>, <tf.Variable 'transformer/self_attention/value/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[-0.00583021,  0.01898559, -0.07813249, ...,  0.01470194,\n        -0.04617868,  0.05991031],\n       [ 0.01118729, -0.01664848,  0.02290742, ...,  0.05128998,\n         0.0488997 , -0.01383384],\n       [-0.03382362,  0.02397531,  0.04477526, ...,  0.02746537,\n         0.00654325, -0.02739377],\n       ...,\n       [-0.00801583, -0.0073606 ,  0.01663694, ...,  0.03749947,\n        -0.0279592 ,  0.02456144],\n       [-0.10955632, -0.05614718, -0.0373836 , ..., -0.02047898,\n        -0.02281027, -0.06386512],\n       [-0.05746127, -0.06979866,  0.03344131, ...,  0.05559727,\n         0.04984279,  0.10994195]], dtype=float32)>, <tf.Variable 'transformer/self_attention/query/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[-0.01377837,  0.07357438, -0.04527948, ..., -0.05842502,\n         -0.03491806, -0.01472285],\n        [ 0.0782255 , -0.01223121, -0.0201827 , ..., -0.02918999,\n         -0.03506214,  0.09720387],\n        [-0.06090837,  0.01052236, -0.08871312, ...,  0.04718109,\n         -0.08264613, -0.02211992],\n        ...,\n        [-0.02211656, -0.07450034, -0.09105378, ..., -0.02353879,\n         -0.00186193, -0.02624659],\n        [-0.06466416,  0.05104137,  0.06214633, ..., -0.00882597,\n          0.01384698, -0.00641415],\n        [ 0.00728806, -0.00661764,  0.01004463, ..., -0.07231323,\n         -0.01745309,  0.07953671]],\n\n       [[-0.08094801, -0.0444716 , -0.01454574, ..., -0.12114487,\n          0.04690602, -0.02417438],\n        [-0.0312053 , -0.00134854, -0.01033786, ...,  0.00974481,\n          0.05574513,  0.00051812],\n        [-0.02444011,  0.03559694, -0.02237239, ...,  0.06787734,\n          0.04717512,  0.00415475],\n        ...,\n        [-0.04579082, -0.01079442, -0.06424504, ..., -0.001316  ,\n         -0.02370661, -0.01075424],\n        [-0.04026837,  0.03273043, -0.02467076, ..., -0.00966896,\n          0.1009945 ,  0.02552257],\n        [-0.00929556,  0.02242032, -0.01502303, ...,  0.019133  ,\n         -0.01543612,  0.0423996 ]],\n\n       [[-0.03561778, -0.03511388,  0.07547905, ...,  0.11983824,\n          0.016311  ,  0.00299589],\n        [-0.00864482, -0.03277572,  0.04324057, ...,  0.05288047,\n          0.02432082,  0.01934007],\n        [-0.01116764,  0.06070578,  0.01920597, ..., -0.0345761 ,\n         -0.12884846,  0.00155059],\n        ...,\n        [-0.04399838,  0.04378324, -0.06521463, ...,  0.00727548,\n          0.01195491, -0.11238346],\n        [-0.08165981, -0.04063996, -0.0250167 , ...,  0.04088634,\n          0.02011568, -0.01322642],\n        [-0.02424259,  0.06421451, -0.02915962, ..., -0.05856399,\n         -0.05201594,  0.00169805]],\n\n       ...,\n\n       [[-0.03239403, -0.07309454, -0.05284168, ..., -0.02018154,\n         -0.09058899, -0.10210551],\n        [ 0.0506363 ,  0.02141806, -0.03836602, ..., -0.00504499,\n         -0.05645337,  0.13195612],\n        [-0.03446314, -0.03101292, -0.01456441, ...,  0.0270409 ,\n         -0.05220241,  0.03553066],\n        ...,\n        [ 0.0692331 ,  0.00466796, -0.0829353 , ..., -0.03670895,\n         -0.00238922, -0.02170164],\n        [ 0.02525684,  0.02580033, -0.07306258, ...,  0.04904684,\n          0.02424773, -0.00820468],\n        [ 0.02405336, -0.06676543, -0.02742696, ..., -0.00666523,\n         -0.02353144, -0.00806599]],\n\n       [[ 0.02209821, -0.11545915, -0.00533447, ...,  0.06857974,\n          0.00115309,  0.03564795],\n        [-0.02203719, -0.01723689, -0.04801384, ...,  0.04606811,\n          0.02226988,  0.02057405],\n        [-0.03286405,  0.03829096,  0.00884398, ...,  0.00273205,\n          0.01895589, -0.08520883],\n        ...,\n        [ 0.04428779, -0.05511183,  0.18416893, ..., -0.06693763,\n          0.00239552, -0.00967456],\n        [ 0.03811575, -0.00498529, -0.00786001, ..., -0.06144257,\n         -0.02605344,  0.01187585],\n        [-0.03807084, -0.01023659,  0.02927524, ...,  0.02512911,\n         -0.04879359,  0.0123428 ]],\n\n       [[ 0.01876527,  0.02102618, -0.0693239 , ...,  0.06529572,\n          0.00221279,  0.03376883],\n        [-0.07404101, -0.01753376,  0.02830493, ..., -0.03738623,\n         -0.02309295,  0.05911645],\n        [ 0.01543296,  0.00256317,  0.03950445, ...,  0.11955313,\n         -0.05716116,  0.01603354],\n        ...,\n        [-0.0256962 ,  0.03320227,  0.05090382, ..., -0.04775341,\n          0.05963584,  0.000934  ],\n        [-0.09600199,  0.04555895,  0.02650656, ..., -0.11290168,\n         -0.10418572,  0.04207915],\n        [ 0.03619373, -0.05530521,  0.02797042, ..., -0.01123728,\n         -0.00518207,  0.0060749 ]]], dtype=float32)>, <tf.Variable 'transformer/output/bias:0' shape=(1024,) dtype=float32, numpy=\narray([-0.24647339, -0.00776859, -0.04411339, ..., -0.08313917,\n        0.0983099 , -0.04420137], dtype=float32)>, <tf.Variable 'transformer/self_attention/value/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[ 0.08797709,  0.0020717 , -0.02988835, ...,  0.00414013,\n          0.07484715,  0.03971449],\n        [ 0.01181907,  0.01673844,  0.00993257, ...,  0.04269501,\n          0.07497684,  0.05441765],\n        [-0.04123079, -0.0125709 ,  0.07505488, ..., -0.01293301,\n          0.01663662, -0.00806466],\n        ...,\n        [-0.03976909, -0.04241847,  0.04778959, ..., -0.05560155,\n          0.034874  , -0.07447197],\n        [-0.00133578, -0.00624564,  0.04871361, ..., -0.03820138,\n         -0.02092554, -0.03139704],\n        [-0.06732795,  0.0424525 , -0.01663647, ..., -0.04881165,\n         -0.02787822, -0.00515961]],\n\n       [[ 0.07280349, -0.07364671, -0.08526693, ..., -0.06247063,\n          0.00236623, -0.00911083],\n        [-0.03756052,  0.01553301, -0.00284038, ..., -0.06488091,\n         -0.01434528, -0.03161497],\n        [-0.02179443, -0.0646414 , -0.04048219, ...,  0.02184545,\n         -0.0211122 ,  0.01740629],\n        ...,\n        [-0.02763911,  0.00523491,  0.00303702, ...,  0.00910007,\n          0.00787244, -0.05087136],\n        [-0.01797713, -0.04068588,  0.02618967, ..., -0.0096323 ,\n         -0.06151869,  0.02406118],\n        [-0.02478819,  0.04828609, -0.00703087, ..., -0.03620443,\n          0.04607834,  0.03005329]],\n\n       [[ 0.01337238, -0.03798615,  0.02630081, ...,  0.01285004,\n          0.08671611,  0.06131849],\n        [ 0.07498433, -0.0858638 , -0.02551636, ..., -0.00508317,\n          0.00318569,  0.06502707],\n        [ 0.02094145, -0.00057176,  0.00539172, ..., -0.01223748,\n         -0.00193865,  0.00151399],\n        ...,\n        [ 0.02882743, -0.05991769,  0.04019088, ...,  0.06426458,\n          0.01378288, -0.07480925],\n        [ 0.03058263,  0.04395986,  0.01187258, ..., -0.00552897,\n          0.0382335 , -0.02911536],\n        [-0.06633037,  0.00577369,  0.01846346, ..., -0.02890185,\n          0.01893614,  0.00294089]],\n\n       ...,\n\n       [[ 0.03748734, -0.07109033, -0.00454385, ..., -0.00556623,\n         -0.07197092,  0.00822964],\n        [ 0.00029132, -0.03028077, -0.00639235, ..., -0.05224453,\n          0.07962234,  0.01018672],\n        [-0.04369333, -0.05030391,  0.01688178, ...,  0.0066217 ,\n          0.01812653,  0.00703911],\n        ...,\n        [-0.10768004,  0.05172554,  0.0182227 , ...,  0.05067201,\n          0.01246925,  0.0401826 ],\n        [-0.04991208, -0.01331158, -0.01212245, ..., -0.04266884,\n          0.04379959,  0.01865999],\n        [-0.05395498, -0.03194196, -0.001778  , ..., -0.03485607,\n          0.03047973,  0.03649557]],\n\n       [[ 0.04807007, -0.03686615,  0.01512305, ...,  0.01602007,\n          0.11524873,  0.01916426],\n        [ 0.0012002 , -0.04894599, -0.04309888, ...,  0.07189992,\n          0.15859145, -0.06280167],\n        [ 0.08538401, -0.03809969,  0.04182295, ..., -0.02923686,\n          0.0003086 ,  0.03860561],\n        ...,\n        [-0.01383685, -0.01391714, -0.01385395, ...,  0.00126929,\n          0.0860488 ,  0.02731048],\n        [ 0.03810836,  0.05952343,  0.01847435, ...,  0.04779863,\n          0.0012848 , -0.09237032],\n        [-0.05638543,  0.024988  , -0.04909164, ...,  0.06645802,\n          0.11695842,  0.04548807]],\n\n       [[ 0.00357805, -0.01972263, -0.020643  , ..., -0.02112963,\n          0.04822826,  0.01768974],\n        [ 0.05982173,  0.00412898,  0.02767219, ..., -0.04594505,\n          0.02497969, -0.011791  ],\n        [ 0.06478981, -0.02329071,  0.00180043, ..., -0.02658423,\n          0.00817082, -0.01976474],\n        ...,\n        [ 0.01835014, -0.01268417, -0.07389341, ...,  0.05695285,\n          0.00050769, -0.01934631],\n        [-0.00798785,  0.0209216 , -0.01295373, ...,  0.07503591,\n         -0.05892896, -0.0335428 ],\n        [ 0.02507908,  0.00504514,  0.01544049, ..., -0.00188708,\n         -0.01404955,  0.05319757]]], dtype=float32)>, <tf.Variable 'transformer/output_layer_norm/gamma:0' shape=(1024,) dtype=float32, numpy=\narray([0.8545426 , 0.8777306 , 0.8767569 , ..., 0.8640456 , 0.8231375 ,\n       0.85486865], dtype=float32)>, <tf.Variable 'embeddings/layer_norm/beta:0' shape=(128,) dtype=float32, numpy=\narray([-0.5842526 ,  0.24272971, -0.12445377,  0.07139821, -0.34981656,\n        0.16594781, -0.30217123,  0.6490534 , -0.30634406, -0.36531183,\n        0.16858287, -0.43766633,  0.12411823,  0.33471942,  0.01254949,\n       -0.2908569 , -1.139494  ,  0.11709121,  0.2582868 ,  0.28464222,\n        0.03860448,  0.46567854, -0.3528685 ,  0.3549207 ,  0.8635659 ,\n       -0.16202736,  0.11273721,  0.0516649 ,  0.21996643,  0.07899692,\n        0.5350719 , -0.03773566,  0.5482328 ,  0.34826764,  0.28899294,\n        0.06849271,  0.16730666, -0.21323828,  0.07566579,  0.03076132,\n       -1.4614726 , -0.41675633,  0.28203508,  0.19634478,  0.47250408,\n        0.21584797, -0.18325771, -0.50363094,  0.39384124,  0.35548446,\n       -0.14043917,  0.04353445,  0.04234899,  0.04064114,  0.26725945,\n        0.06668285,  0.21382625,  0.38483828, -0.04219316,  0.04379422,\n        0.5362364 ,  0.00848074, -0.08906814, -0.13959515, -0.0108059 ,\n       -0.150432  ,  0.02988789,  0.1244619 , -0.23843955,  0.2598754 ,\n        0.06482524, -0.34236938,  0.12493712, -0.31151992, -0.05674663,\n        0.32138032,  0.32952127,  0.2600991 ,  1.2608591 , -0.00433848,\n        0.53402925, -0.06318664, -0.05468542, -0.52521217,  0.10494697,\n       -0.2463326 ,  0.17766938, -0.2147248 , -0.04897923,  0.19409223,\n       -0.00354851, -0.03950975,  0.29356265,  0.08504426, -0.03914158,\n       -0.12665841,  0.04963979,  0.14758857, -0.05302747, -0.5430127 ,\n        0.24101722, -0.263537  , -0.8372029 , -0.05900194, -0.03526299,\n        0.03415408,  0.46867988, -0.312193  ,  0.2922889 ,  0.2073657 ,\n        0.02637885, -0.07367035, -0.23456465,  0.36595738,  0.59381425,\n        0.39802575,  0.11532904, -1.1621219 , -0.13976075, -0.11088204,\n       -0.08006179,  0.5729334 ,  0.03168112,  0.24488862, -0.72558   ,\n       -0.3117142 ,  0.3622865 , -0.02723189], dtype=float32)>, <tf.Variable 'transformer/output_layer_norm/beta:0' shape=(1024,) dtype=float32, numpy=\narray([-0.07938902, -0.05059273, -0.00045664, ...,  0.01891402,\n        0.03678424,  0.12761983], dtype=float32)>, <tf.Variable 'transformer/intermediate/kernel:0' shape=(1024, 4096) dtype=float32, numpy=\narray([[ 0.02624489,  0.01479701,  0.02738292, ..., -0.01135132,\n         0.0117222 , -0.01887776],\n       [ 0.01027278,  0.02836631,  0.00807532, ...,  0.00307549,\n        -0.07374579, -0.05794734],\n       [ 0.07240843, -0.11266635, -0.0465501 , ..., -0.01003353,\n         0.01962401, -0.03882667],\n       ...,\n       [-0.03021646, -0.01252673, -0.01728925, ...,  0.11241266,\n         0.06752944, -0.0189009 ],\n       [-0.01871368,  0.04275062,  0.02974374, ..., -0.10041117,\n        -0.00401674, -0.02922116],\n       [ 0.07769395, -0.00169165,  0.06005793, ...,  0.03372611,\n         0.09345875, -0.00471404]], dtype=float32)>, <tf.Variable 'pooler_transform/bias:0' shape=(1024,) dtype=float32, numpy=\narray([-0.04656763, -0.26320603, -0.07046566, ...,  0.26848638,\n       -0.301408  , -0.05583415], dtype=float32)>, <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(128,) dtype=float32, numpy=\narray([1.7839581 , 1.8909203 , 1.8902636 , 1.9057839 , 1.865123  ,\n       1.8633173 , 1.7874655 , 1.8197732 , 1.8653047 , 1.265877  ,\n       1.9067185 , 1.3949844 , 1.8377118 , 1.8029649 , 1.943066  ,\n       1.7839162 , 1.2115556 , 1.8840996 , 1.7027538 , 1.9194046 ,\n       1.7909882 , 2.0551376 , 1.7422584 , 1.8138171 , 1.9750853 ,\n       1.9896872 , 1.8258024 , 1.8482335 , 1.7632504 , 1.8764453 ,\n       1.7474222 , 1.932738  , 1.7700673 , 1.7354928 , 1.3469992 ,\n       0.78094333, 1.8966844 , 1.7008317 , 1.5683017 , 1.70847   ,\n       1.1830852 , 1.6319302 , 1.9137667 , 1.8161463 , 1.660736  ,\n       1.8398185 , 1.8505971 , 1.8121346 , 1.9098474 , 1.8154311 ,\n       1.8577214 , 1.8624518 , 1.8422674 , 1.810782  , 1.9760392 ,\n       1.71011   , 1.823686  , 1.2051458 , 1.7132999 , 2.0394435 ,\n       1.9106469 , 1.7092353 , 1.73497   , 1.6923317 , 1.8144536 ,\n       1.8161547 , 1.8892204 , 1.8127007 , 1.7109252 , 1.8944374 ,\n       1.7437671 , 1.4700319 , 1.6981688 , 1.5983671 , 1.8760558 ,\n       1.9136702 , 1.7502984 , 1.9094018 , 1.0197016 , 1.8225905 ,\n       1.2226652 , 1.9014813 , 1.8830897 , 1.2154391 , 1.9332271 ,\n       1.9730096 , 1.7327032 , 1.8965244 , 1.8862689 , 1.465993  ,\n       1.6774863 , 1.7258805 , 1.7486068 , 1.7492235 , 1.9269828 ,\n       1.8115519 , 1.9743698 , 1.852579  , 1.4711702 , 1.8735343 ,\n       1.8826352 , 1.3469298 , 1.2056285 , 1.7344472 , 1.2986183 ,\n       1.2588569 , 1.9949453 , 1.8725826 , 1.8003536 , 1.3359643 ,\n       1.7860365 , 1.8115499 , 1.8104943 , 1.8090411 , 1.7031308 ,\n       1.8164089 , 1.8747627 , 1.1072854 , 1.9315572 , 1.7622515 ,\n       1.758978  , 1.7557343 , 1.7713057 , 1.8013195 , 1.1476954 ,\n       1.1441917 , 1.8329461 , 1.7555294 ], dtype=float32)>, <tf.Variable 'transformer/self_attention_output/bias:0' shape=(1024,) dtype=float32, numpy=\narray([ 0.09856169, -0.09544315,  0.06416708, ...,  0.03073069,\n       -0.06195455,  0.08915669], dtype=float32)>, <tf.Variable 'transformer/intermediate/bias:0' shape=(4096,) dtype=float32, numpy=\narray([-0.66687495, -0.23961528, -0.80109847, ..., -0.66950315,\n       -0.23912948, -0.38637745], dtype=float32)>, <tf.Variable 'transformer/output/kernel:0' shape=(4096, 1024) dtype=float32, numpy=\narray([[ 0.06272804, -0.0991563 , -0.00634015, ..., -0.05167221,\n        -0.04058805,  0.11515144],\n       [ 0.06619747, -0.0604772 , -0.00470938, ...,  0.0054595 ,\n         0.04805936,  0.08183908],\n       [ 0.00053815,  0.03986236, -0.0038653 , ..., -0.05934481,\n         0.06247399,  0.05197472],\n       ...,\n       [-0.01945007, -0.02923877,  0.02015522, ...,  0.05845422,\n        -0.01744714,  0.07759047],\n       [-0.07426859,  0.0134705 , -0.05658459, ..., -0.00631556,\n         0.04343706, -0.09226128],\n       [-0.02510573, -0.05316114, -0.05383938, ...,  0.07250074,\n        -0.07358983,  0.08247995]], dtype=float32)>, <tf.Variable 'transformer/self_attention_layer_norm/beta:0' shape=(1024,) dtype=float32, numpy=\narray([-0.11128127,  0.09175195, -0.0451484 , ...,  0.00629278,\n        0.02116437, -0.02543932], dtype=float32)>, <tf.Variable 'transformer/self_attention/key/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[ 2.4713101e-02, -8.4732929e-03,  9.4683498e-02, ...,\n          7.9031169e-02, -1.2722029e-02,  1.8242197e-02],\n        [ 7.3173251e-03, -2.0339107e-02,  2.1190507e-02, ...,\n         -1.5573609e-02, -4.5128711e-03,  1.1003817e-02],\n        [ 7.0165731e-02,  8.8932505e-04, -5.5978518e-02, ...,\n         -4.4360928e-02,  1.2549350e-02,  1.2195073e-02],\n        ...,\n        [ 3.9751898e-02, -7.8894429e-02,  3.5209768e-02, ...,\n          6.1872490e-02, -6.4032704e-02, -1.8050693e-02],\n        [-3.0467499e-02,  3.5991903e-02,  7.0526212e-02, ...,\n         -1.2557115e-01,  3.5162043e-02,  1.0676601e-02],\n        [-7.5061998e-04,  7.2652623e-02, -2.3527259e-02, ...,\n         -3.8151357e-02,  1.7010717e-02,  1.9637674e-02]],\n\n       [[ 2.0027144e-02, -9.4912341e-03, -5.9485622e-02, ...,\n         -4.4538103e-02,  1.1637376e-03, -3.0620754e-02],\n        [ 1.9961732e-02,  2.3787232e-02,  3.3009835e-02, ...,\n          3.4633353e-02, -3.0900784e-02,  4.3894886e-03],\n        [-4.5316410e-03,  7.1450822e-02, -4.0445078e-02, ...,\n         -9.1760159e-02, -5.5172995e-02, -1.6513530e-02],\n        ...,\n        [ 1.4449713e-02,  2.2924665e-02, -1.2238196e-02, ...,\n          7.7013850e-02, -7.7437714e-02, -9.1232777e-02],\n        [-8.5429750e-02,  2.6168317e-02, -9.1173857e-02, ...,\n         -6.3306525e-02,  4.4367980e-02,  3.1533514e-03],\n        [-1.4282439e-02, -1.8458495e-02, -1.6364652e-04, ...,\n          2.8204570e-02, -3.3194371e-02,  1.2041159e-02]],\n\n       [[-1.3470611e-02, -6.6131316e-03,  1.0277274e-02, ...,\n         -2.6586000e-02, -2.7954231e-03,  7.4636444e-02],\n        [ 3.8047303e-02, -7.0768811e-02,  2.7904188e-02, ...,\n          6.4772409e-03,  8.6533353e-03, -5.7381988e-03],\n        [-6.1659995e-02, -1.9641824e-02,  4.5295339e-03, ...,\n         -7.9011984e-02, -8.8489905e-02, -6.3039489e-02],\n        ...,\n        [ 1.7574983e-02, -1.6585337e-02,  6.5038404e-03, ...,\n         -9.8161653e-02,  1.6528068e-02, -4.9473003e-02],\n        [-4.7106016e-02, -1.4097092e-02, -3.6388967e-02, ...,\n         -4.9359822e-03,  1.5996471e-02,  2.7868472e-02],\n        [ 4.2999599e-02,  5.0639473e-02,  1.4499824e-02, ...,\n         -5.7727244e-02, -8.1605487e-02,  2.0229815e-02]],\n\n       ...,\n\n       [[ 6.1360657e-02, -1.4103043e-02,  2.1941089e-03, ...,\n          7.4588634e-02,  4.0464137e-02, -6.5672502e-04],\n        [ 3.8772956e-02,  1.7533615e-02, -3.8802300e-02, ...,\n          2.1978794e-03,  3.0107835e-02,  4.9107172e-02],\n        [ 8.9048423e-02, -4.8273843e-02, -1.1750394e-02, ...,\n          5.0601628e-02,  5.5317212e-02, -6.8827339e-02],\n        ...,\n        [ 3.9119568e-02,  2.8708689e-02, -4.8825359e-03, ...,\n         -4.1826796e-02,  7.7156126e-02, -8.6068429e-02],\n        [-1.0914610e-03,  7.4436881e-02, -9.1448031e-02, ...,\n         -1.2533712e-02, -1.7853940e-02, -1.3294272e-02],\n        [ 2.4324105e-05, -1.8835047e-02, -4.6823423e-02, ...,\n         -3.0126328e-02, -5.2027958e-03,  5.1746584e-02]],\n\n       [[-1.9124746e-02, -3.9369494e-02, -1.9944701e-02, ...,\n          1.0756750e-01, -5.4115411e-02,  2.4449121e-02],\n        [-9.4848692e-02,  1.0229457e-02, -6.5941885e-02, ...,\n          3.5749212e-02,  7.0381328e-02, -2.0526096e-02],\n        [ 5.1128607e-02, -3.6088333e-02,  5.5570420e-02, ...,\n         -1.5034926e-02,  4.7761545e-02,  9.9037580e-02],\n        ...,\n        [ 3.0040503e-02, -3.7970971e-02,  1.0421912e-02, ...,\n         -5.8147941e-02,  1.1260663e-02, -3.3532418e-05],\n        [ 5.4495495e-02, -7.5122397e-03,  3.8050596e-02, ...,\n         -3.3011734e-02,  4.2246524e-03, -8.3926702e-03],\n        [ 4.6221283e-03, -5.3813014e-02,  1.6895467e-02, ...,\n          1.9936441e-02, -6.3096374e-02,  1.3950768e-02]],\n\n       [[ 1.6954603e-02,  5.7040595e-02,  1.5734315e-02, ...,\n          3.6513884e-02, -1.2498280e-02, -3.2489341e-02],\n        [-7.3507376e-02, -4.7027759e-04,  4.6819609e-02, ...,\n          8.7657543e-03, -3.3977064e-03,  3.0739758e-02],\n        [-1.5084445e-02,  4.5815274e-02, -2.8523199e-02, ...,\n          2.1990506e-02, -2.8816486e-02, -2.4439283e-02],\n        ...,\n        [-5.8590394e-02, -2.2878752e-04,  8.9097640e-04, ...,\n         -6.1450910e-02, -5.5946052e-02, -2.5287621e-02],\n        [-3.9880879e-02, -4.3279279e-02, -1.0391799e-02, ...,\n         -1.1459351e-01, -5.8107884e-03,  5.1980626e-02],\n        [ 3.7124943e-02, -3.0228711e-04,  1.4431281e-02, ...,\n         -2.4514509e-02, -2.7502658e-02,  9.5150033e-03]]], dtype=float32)>, <tf.Variable 'transformer/self_attention_output/kernel:0' shape=(16, 64, 1024) dtype=float32, numpy=\narray([[[-0.12087623, -0.00131766,  0.0059417 , ..., -0.01276294,\n         -0.01676265, -0.10364094],\n        [-0.11030291,  0.03917245,  0.08902217, ..., -0.00991671,\n         -0.03903826, -0.04283248],\n        [-0.08456261,  0.05295455, -0.05333614, ...,  0.04496399,\n         -0.02267177,  0.03789821],\n        ...,\n        [-0.01463968,  0.00105729, -0.03952024, ..., -0.00622237,\n          0.02773172,  0.04143756],\n        [ 0.02726533, -0.04562404, -0.01092314, ...,  0.07876874,\n         -0.10231116, -0.08164937],\n        [-0.03413047,  0.04504857, -0.07175126, ..., -0.07401045,\n         -0.01263101,  0.04526484]],\n\n       [[ 0.04133579,  0.00715958,  0.07387298, ..., -0.02295391,\n          0.01748894,  0.04781013],\n        [-0.07751813, -0.02407866,  0.04599382, ..., -0.16222243,\n         -0.10661072,  0.00727186],\n        [-0.06002577,  0.02527035,  0.04255925, ..., -0.0862935 ,\n         -0.04250443, -0.03319255],\n        ...,\n        [ 0.04278314,  0.03787831,  0.00446601, ...,  0.05054899,\n         -0.08515636,  0.05557117],\n        [-0.02215524,  0.00050115,  0.08688294, ..., -0.09411283,\n         -0.01767358, -0.00129942],\n        [-0.04210161,  0.02384934,  0.08061824, ...,  0.124822  ,\n          0.03908351, -0.0484701 ]],\n\n       [[-0.09888351, -0.0051013 ,  0.03721306, ..., -0.03904448,\n          0.02210518,  0.06002177],\n        [-0.00963472, -0.0220372 ,  0.05162675, ..., -0.03965967,\n          0.01706901,  0.06558199],\n        [ 0.08189272,  0.06789871,  0.05701382, ..., -0.01269164,\n          0.03169342,  0.00836909],\n        ...,\n        [-0.02334395,  0.01568061,  0.05703887, ...,  0.0273691 ,\n         -0.01814027, -0.01872451],\n        [ 0.06504452, -0.03338562, -0.0703576 , ..., -0.05403217,\n          0.07934742,  0.07556178],\n        [-0.00310893, -0.04448323, -0.05647891, ...,  0.00665758,\n          0.00152404, -0.00411649]],\n\n       ...,\n\n       [[ 0.04162116, -0.03725463, -0.04037993, ..., -0.05948862,\n         -0.03199046, -0.06347068],\n        [ 0.01424028, -0.01043441, -0.01848511, ...,  0.03906364,\n          0.10528692, -0.01073527],\n        [ 0.01106103, -0.0317982 , -0.08034817, ..., -0.00695507,\n         -0.03181245, -0.03582251],\n        ...,\n        [ 0.05527718,  0.00725207, -0.03463059, ...,  0.02542693,\n         -0.00925153,  0.00595798],\n        [-0.00356322,  0.10247871,  0.04952729, ..., -0.01858452,\n         -0.00868734, -0.05647591],\n        [-0.04316147, -0.00417736,  0.04818535, ..., -0.03246309,\n          0.05976842, -0.00438782]],\n\n       [[ 0.0248446 , -0.01758825, -0.04737019, ...,  0.04280659,\n         -0.02860698,  0.02186623],\n        [-0.05687475,  0.02948832, -0.04468279, ..., -0.0093023 ,\n          0.0226582 ,  0.08020571],\n        [ 0.02384427, -0.02303015,  0.0617718 , ..., -0.03017887,\n         -0.0407806 ,  0.04612486],\n        ...,\n        [-0.07820291, -0.03813744, -0.0063624 , ...,  0.00369967,\n          0.03497613,  0.00212011],\n        [-0.06974534, -0.01040694, -0.00887159, ...,  0.04638416,\n          0.04365183,  0.03806246],\n        [ 0.01768665,  0.05274608,  0.07386105, ...,  0.0053088 ,\n         -0.02989793,  0.0253226 ]],\n\n       [[ 0.0321832 , -0.0242134 ,  0.0163552 , ...,  0.05967472,\n          0.03027917, -0.03767041],\n        [-0.0836022 , -0.0253592 ,  0.04704583, ...,  0.05642388,\n         -0.04858131, -0.01046145],\n        [ 0.05051516, -0.00169722, -0.02403292, ...,  0.01683992,\n          0.02337351,  0.00433411],\n        ...,\n        [-0.01164332,  0.03490139,  0.00623156, ...,  0.04541679,\n         -0.03625841,  0.02501275],\n        [ 0.01010661, -0.02505532,  0.00512691, ..., -0.01287222,\n         -0.02916379,  0.01367385],\n        [-0.00354523,  0.03046549,  0.02393773, ...,  0.05403419,\n         -0.02108731, -0.00417873]]], dtype=float32)>, <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 128) dtype=float32, numpy=\narray([[ 2.98617668e-02,  4.58420767e-03,  9.50067490e-03,\n         1.75369158e-02,  2.27376875e-02,  4.29183478e-03,\n        -2.27738265e-03, -3.18773687e-02, -5.63001540e-03,\n         1.66752022e-02, -1.20887235e-02,  2.89540719e-02,\n         1.93531048e-02, -3.11399251e-03, -9.68094263e-03,\n         3.08668386e-04,  7.51848668e-02, -1.16000529e-02,\n        -5.12433704e-03,  5.25925029e-03, -1.38946734e-02,\n         4.76975273e-03,  4.62501822e-03, -6.50442598e-05,\n         3.29455268e-03, -1.21591957e-02,  5.38068730e-03,\n        -5.98245393e-03,  1.09438878e-02, -4.52870177e-03,\n        -2.04672646e-02, -1.66713949e-02, -1.18922638e-02,\n        -4.03177040e-03,  2.68683936e-02, -9.11266655e-02,\n        -1.54091446e-02, -1.04631260e-02, -5.78899076e-03,\n         1.03390468e-02,  6.26485571e-02, -4.99828369e-04,\n         4.90542548e-03, -1.14343350e-03, -6.82649016e-03,\n        -6.46636821e-03, -2.14987788e-02,  5.80138573e-03,\n        -1.58117935e-02, -1.06885741e-02, -2.43090885e-03,\n         2.31577959e-02,  1.02502853e-02, -2.44546775e-03,\n        -4.73010400e-03,  2.49942183e-03, -4.50519752e-03,\n        -4.47330670e-03, -7.95519073e-03,  1.66786332e-02,\n        -3.83057236e-03,  1.03940750e-02,  9.91822407e-03,\n        -8.73943418e-03, -8.47806409e-03,  1.48456031e-02,\n        -5.68873063e-03, -1.08904056e-02, -6.08319824e-04,\n         1.80337823e-03, -7.87300430e-03,  8.92674830e-03,\n        -1.73187945e-02,  2.09515984e-03,  9.51454858e-04,\n        -4.76388540e-03, -6.71155564e-03, -2.73680547e-04,\n        -4.81038205e-02, -1.03519205e-02, -4.91856225e-02,\n        -5.66279888e-03,  6.91874698e-03,  1.69854257e-02,\n         5.39499195e-03,  1.53280245e-02, -1.12297228e-02,\n        -3.91890714e-03,  1.98564236e-03,  1.28436293e-02,\n        -1.87377427e-02,  1.86861132e-03, -1.15595544e-02,\n        -6.88303588e-03, -3.81718599e-03,  6.70217117e-03,\n        -1.81409102e-02, -1.42892322e-03,  9.69388336e-03,\n         3.38096693e-02, -1.23233367e-02,  2.05204450e-02,\n         3.89646031e-02, -3.02533736e-03, -2.15234347e-02,\n        -6.32723561e-03,  1.17032044e-02, -7.54641183e-03,\n         3.60583392e-04,  1.73142459e-02,  2.28945562e-03,\n         1.89215306e-03, -1.35893542e-02, -6.38993399e-04,\n        -1.21622784e-02, -1.43322041e-02, -7.85413571e-03,\n         6.35343790e-02,  1.09696239e-02, -4.97072469e-03,\n        -1.25197712e-02, -3.98948044e-03,  1.28613831e-02,\n        -1.80547517e-02,  5.86996675e-02,  4.84309130e-04,\n        -1.03661912e-02, -4.17545671e-03],\n       [ 9.51315742e-03,  2.64111790e-03,  5.81751531e-03,\n         4.10360843e-03,  1.55416913e-02,  1.55874644e-03,\n        -5.31348353e-03, -4.87021580e-02,  1.00112511e-02,\n         2.75518820e-02, -1.85683072e-02,  2.73402948e-02,\n        -1.22063803e-02, -4.09271149e-03, -1.37833096e-02,\n         2.41741035e-02,  4.24481854e-02, -4.00120532e-03,\n        -3.35831493e-02, -1.33783203e-02,  2.09027017e-03,\n         8.39193538e-03,  1.90373324e-02, -1.89809110e-02,\n        -1.05222119e-02, -2.92985654e-03, -4.83474694e-03,\n        -3.20151169e-03,  7.30225863e-03,  9.39310808e-03,\n        -1.22383051e-02, -8.78334511e-03, -3.00480910e-02,\n         2.01238692e-03, -2.83827409e-02,  8.82106274e-02,\n        -1.94496717e-02, -3.62360314e-03, -5.34485793e-03,\n         4.65337234e-03,  3.76006775e-02,  2.69234143e-02,\n        -1.06045017e-02, -1.79957170e-02, -4.03852109e-03,\n         2.52132537e-03, -1.05875516e-02,  8.53512343e-03,\n        -2.45905947e-02, -1.00720078e-02, -1.32326074e-02,\n         2.51564309e-02,  2.14203354e-03, -2.51882207e-02,\n         1.15820989e-02,  2.51928228e-03,  6.23461697e-03,\n        -7.63629982e-03, -2.04616474e-04,  2.41278857e-02,\n        -1.79238878e-02, -1.55131910e-02,  4.07387875e-03,\n         8.40316899e-03,  1.20135089e-02,  2.82466188e-02,\n         1.81839261e-02, -9.39134136e-03,  1.00992816e-02,\n        -2.92194262e-03, -9.00639873e-03,  2.28380989e-02,\n        -1.50002800e-02,  1.30763149e-03, -6.63995510e-03,\n         3.84626235e-03, -1.98405497e-02,  2.38769618e-03,\n        -9.61042866e-02, -7.00418372e-03, -4.75384183e-02,\n        -7.61770876e-03,  5.07009681e-03,  3.13257128e-02,\n         1.43967173e-03,  2.42153052e-02, -6.58777030e-03,\n         7.36570219e-03, -4.23991401e-03, -5.32793056e-04,\n         1.39645627e-02, -1.48792369e-02, -1.02066770e-02,\n        -2.86848191e-03,  3.51263513e-03, -1.29089076e-02,\n        -1.11678587e-02, -4.60836251e-04, -5.57290018e-03,\n         2.38979999e-02, -1.34584466e-02,  2.72901040e-02,\n         3.52007523e-02,  5.37421845e-04,  5.08337431e-02,\n        -1.19858270e-03,  3.09318351e-03, -8.45669943e-04,\n        -1.43428221e-02, -2.99898349e-02, -2.00865697e-02,\n         1.51976733e-03, -8.06429703e-03, -1.30432064e-03,\n        -7.50076445e-03, -2.58349683e-02, -1.28204534e-02,\n         6.31427392e-02,  4.21355572e-03,  1.35499082e-04,\n        -1.17550660e-02, -2.00037528e-02, -5.88530907e-03,\n        -5.21364575e-03,  1.01053575e-02,  2.43842863e-02,\n        -2.61453558e-02,  1.84759460e-02]], dtype=float32)>, <tf.Variable 'pooler_transform/kernel:0' shape=(1024, 1024) dtype=float32, numpy=\narray([[-0.00052518, -0.0253877 , -0.01490941, ...,  0.01312183,\n        -0.0278377 , -0.04181223],\n       [ 0.01424094,  0.01080372,  0.05730467, ..., -0.02480907,\n         0.03609122,  0.04318529],\n       [ 0.05742806,  0.01663461, -0.0205514 , ..., -0.00812335,\n        -0.0091945 ,  0.00107263],\n       ...,\n       [-0.01611846, -0.0331498 , -0.03367683, ...,  0.0242574 ,\n        -0.01729438, -0.01731833],\n       [ 0.02241669,  0.02788646,  0.01500472, ..., -0.01016136,\n        -0.00482643,  0.02016787],\n       [-0.02179764,  0.0102333 , -0.02675315, ..., -0.03132581,\n         0.0061183 ,  0.00078582]], dtype=float32)>, <tf.Variable 'transformer/self_attention/key/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[-0.19564319,  0.11978531, -0.41439384, ...,  0.08712698,\n        -0.08149096, -0.1953145 ],\n       [ 0.6122577 , -0.02963953, -0.16226979, ..., -0.47796267,\n        -0.06287912, -0.06575805],\n       [ 0.6078491 , -0.40588948,  0.15858388, ..., -0.40763453,\n        -0.26575118, -0.01651137],\n       ...,\n       [-0.09129642, -0.19593433,  0.586245  , ...,  0.6237123 ,\n        -0.66800666, -0.12655008],\n       [ 0.07444556, -0.4216305 , -0.71830815, ..., -0.73751533,\n         0.46753627,  0.2613811 ],\n       [-0.02628985,  0.48830336, -0.36769304, ..., -0.0338308 ,\n        -0.00832799,  0.16880564]], dtype=float32)>, <tf.Variable 'word_embeddings/embeddings:0' shape=(30000, 128) dtype=float32, numpy=\narray([[ 0.05185268,  0.02554895,  0.07820596, ...,  0.13243212,\n        -0.11136495, -0.0815003 ],\n       [-0.02186797,  0.08194945, -0.03814889, ..., -0.0105723 ,\n         0.08643766,  0.07545596],\n       [ 0.03902123, -0.04490783,  0.02247689, ...,  0.0101957 ,\n        -0.01016969,  0.01507433],\n       ...,\n       [-0.05190184,  0.05257452, -0.06086375, ...,  0.02349056,\n        -0.03793135,  0.11683138],\n       [-0.08752286,  0.01797947,  0.0432927 , ..., -0.02513511,\n        -0.02745636, -0.05742462],\n       [-0.00042062,  0.01001474, -0.10400026, ...,  0.02441972,\n        -0.13680935, -0.02415917]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6e411e0775ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_meta_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_hub_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mcustom_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;31m# streaming restore for any variables created in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0mtrackable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_nontrivial_match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m              \u001b[0;34m\"Typically this means that the checkpoint does not match the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m              \u001b[0;34m\"Python program. The following objects have no matching \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m              \"checkpointed value: %s\") % (list(unused_python_objects),))\n\u001b[0m\u001b[1;32m    802\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'position_embedding/embeddings:0' shape=(512, 128) dtype=float32, numpy=\narray([[ 0.04171413, -0.05951454,  0.00528023, ..., -0.00547502,\n        -0.00608543,  0.01891393],\n       [ 0.01842086, -0.00854636,  0.01457946, ..., -0.2188653 ,\n        -0.02077591,  0.05037078],\n       [-0.02886076, -0.01502202,  0.02091144, ..., -0.16695945,\n        -0.0303349 ,  0.06738311],\n       ...,\n       [ 0.05315233,  0.00108237,  0.01054862, ..., -0.11003321,\n         0.00282854, -0.01345602],\n       [ 0.02562682, -0.06601355, -0.01717755, ..., -0.13026832,\n        -0.00394623,  0.04304561],\n       [ 0.02484268, -0.03633654, -0.03465453, ..., -0.08623783,\n        -0.00122317,  0.00660813]], dtype=float32)>, <tf.Variable 'transformer/self_attention/query/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[ 2.45376015e+00,  4.76708263e-02, -1.26744613e-01, ...,\n        -3.46782118e-01, -2.13123128e-01,  1.15038261e-01],\n       [ 9.12567750e-02,  1.93411217e-03,  2.07950562e-01, ...,\n        -1.40724576e+00,  8.51527974e-03, -8.34104978e-03],\n       [ 5.74417651e-01,  5.32591999e-01, -1.39200494e-01, ...,\n         1.49228200e-01, -1.09081835e-01,  5.10540567e-02],\n       ...,\n       [ 1.98225096e-01,  1.18390076e-01, -1.38897151e-02, ...,\n         2.18401536e-01, -1.01841846e-02, -2.01080218e-01],\n       [ 1.70461401e-01, -4.32333685e-02,  6.05556890e-02, ...,\n        -2.54708380e-01, -4.64531891e-02, -2.82951653e-01],\n       [ 2.12428659e-01,  3.77846628e-01,  3.82576555e-01, ...,\n        -4.46735799e-01, -2.10399985e-01,  3.62275302e-01]], dtype=float32)>, <tf.Variable 'embedding_projection/kernel:0' shape=(128, 1024) dtype=float32, numpy=\narray([[-0.03311966, -0.01145261, -0.01302266, ...,  0.03378126,\n         0.03187594, -0.07032862],\n       [-0.01979856, -0.01833594, -0.00088798, ...,  0.00279429,\n         0.01289404, -0.05421524],\n       [-0.00527666, -0.00531581,  0.00867427, ..., -0.00036586,\n         0.0088558 , -0.00422233],\n       ...,\n       [ 0.03803551,  0.01312911,  0.03702177, ...,  0.04629155,\n        -0.02312718, -0.0257398 ],\n       [ 0.05053426,  0.04734649, -0.02995732, ...,  0.03516439,\n        -0.00742496, -0.01042338],\n       [ 0.01236061, -0.01599358,  0.00260928, ..., -0.02889969,\n        -0.00557954, -0.00491254]], dtype=float32)>, <tf.Variable 'transformer/self_attention_layer_norm/gamma:0' shape=(1024,) dtype=float32, numpy=\narray([0.47873768, 0.56642795, 0.479606  , ..., 0.48143235, 0.4791084 ,\n       0.50819606], dtype=float32)>, <tf.Variable 'embedding_projection/bias:0' shape=(1024,) dtype=float32, numpy=\narray([ 0.01374829,  0.08602794,  0.07090328, ..., -0.04428381,\n        0.01013557,  0.02760786], dtype=float32)>, <tf.Variable 'transformer/self_attention/value/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[-0.00583021,  0.01898559, -0.07813249, ...,  0.01470194,\n        -0.04617868,  0.05991031],\n       [ 0.01118729, -0.01664848,  0.02290742, ...,  0.05128998,\n         0.0488997 , -0.01383384],\n       [-0.03382362,  0.02397531,  0.04477526, ...,  0.02746537,\n         0.00654325, -0.02739377],\n       ...,\n       [-0.00801583, -0.0073606 ,  0.01663694, ...,  0.03749947,\n        -0.0279592 ,  0.02456144],\n       [-0.10955632, -0.05614718, -0.0373836 , ..., -0.02047898,\n        -0.02281027, -0.06386512],\n       [-0.05746127, -0.06979866,  0.03344131, ...,  0.05559727,\n         0.04984279,  0.10994195]], dtype=float32)>, <tf.Variable 'transformer/self_attention/query/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[-0.01377837,  0.07357438, -0.04527948, ..., -0.05842502,\n         -0.03491806, -0.01472285],\n        [ 0.0782255 , -0.01223121, -0.0201827 , ..., -0.02918999,\n         -0.03506214,  0.09720387],\n        [-0.06090837,  0.01052236, -0.08871312, ...,  0.04718109,\n         -0.08264613, -0.02211992],\n        ...,\n        [-0.02211656, -0.07450034, -0.09105378, ..., -0.02353879,\n         -0.00186193, -0.02624659],\n        [-0.06466416,  0.05104137,  0.06214633, ..., -0.00882597,\n          0.01384698, -0.00641415],\n        [ 0.00728806, -0.00661764,  0.01004463, ..., -0.07231323,\n         -0.01745309,  0.07953671]],\n\n       [[-0.08094801, -0.0444716 , -0.01454574, ..., -0.12114487,\n          0.04690602, -0.02417438],\n        [-0.0312053 , -0.00134854, -0.01033786, ...,  0.00974481,\n          0.05574513,  0.00051812],\n        [-0.02444011,  0.03559694, -0.02237239, ...,  0.06787734,\n          0.04717512,  0.00415475],\n        ...,\n        [-0.04579082, -0.01079442, -0.06424504, ..., -0.001316  ,\n         -0.02370661, -0.01075424],\n        [-0.04026837,  0.03273043, -0.02467076, ..., -0.00966896,\n          0.1009945 ,  0.02552257],\n        [-0.00929556,  0.02242032, -0.01502303, ...,  0.019133  ,\n         -0.01543612,  0.0423996 ]],\n\n       [[-0.03561778, -0.03511388,  0.07547905, ...,  0.11983824,\n          0.016311  ,  0.00299589],\n        [-0.00864482, -0.03277572,  0.04324057, ...,  0.05288047,\n          0.02432082,  0.01934007],\n        [-0.01116764,  0.06070578,  0.01920597, ..., -0.0345761 ,\n         -0.12884846,  0.00155059],\n        ...,\n        [-0.04399838,  0.04378324, -0.06521463, ...,  0.00727548,\n          0.01195491, -0.11238346],\n        [-0.08165981, -0.04063996, -0.0250167 , ...,  0.04088634,\n          0.02011568, -0.01322642],\n        [-0.02424259,  0.06421451, -0.02915962, ..., -0.05856399,\n         -0.05201594,  0.00169805]],\n\n       ...,\n\n       [[-0.03239403, -0.07309454, -0.05284168, ..., -0.02018154,\n         -0.09058899, -0.10210551],\n        [ 0.0506363 ,  0.02141806, -0.03836602, ..., -0.00504499,\n         -0.05645337,  0.13195612],\n        [-0.03446314, -0.03101292, -0.01456441, ...,  0.0270409 ,\n         -0.05220241,  0.03553066],\n        ...,\n        [ 0.0692331 ,  0.00466796, -0.0829353 , ..., -0.03670895,\n         -0.00238922, -0.02170164],\n        [ 0.02525684,  0.02580033, -0.07306258, ...,  0.04904684,\n          0.02424773, -0.00820468],\n        [ 0.02405336, -0.06676543, -0.02742696, ..., -0.00666523,\n         -0.02353144, -0.00806599]],\n\n       [[ 0.02209821, -0.11545915, -0.00533447, ...,  0.06857974,\n          0.00115309,  0.03564795],\n        [-0.02203719, -0.01723689, -0.04801384, ...,  0.04606811,\n          0.02226988,  0.02057405],\n        [-0.03286405,  0.03829096,  0.00884398, ...,  0.00273205,\n          0.01895589, -0.08520883],\n        ...,\n        [ 0.04428779, -0.05511183,  0.18416893, ..., -0.06693763,\n          0.00239552, -0.00967456],\n        [ 0.03811575, -0.00498529, -0.00786001, ..., -0.06144257,\n         -0.02605344,  0.01187585],\n        [-0.03807084, -0.01023659,  0.02927524, ...,  0.02512911,\n         -0.04879359,  0.0123428 ]],\n\n       [[ 0.01876527,  0.02102618, -0.0693239 , ...,  0.06529572,\n          0.00221279,  0.03376883],\n        [-0.07404101, -0.01753376,  0.02830493, ..., -0.03738623,\n         -0.02309295,  0.05911645],\n        [ 0.01543296,  0.00256317,  0.03950445, ...,  0.11955313,\n         -0.05716116,  0.01603354],\n        ...,\n        [-0.0256962 ,  0.03320227,  0.05090382, ..., -0.04775341,\n          0.05963584,  0.000934  ],\n        [-0.09600199,  0.04555895,  0.02650656, ..., -0.11290168,\n         -0.10418572,  0.04207915],\n        [ 0.03619373, -0.05530521,  0.02797042, ..., -0.01123728,\n         -0.00518207,  0.0060749 ]]], dtype=float32)>, <tf.Variable 'transformer/output/bias:0' shape=(1024,) dtype=float32, numpy=\narray([-0.24647339, -0.00776859, -0.04411339, ..., -0.08313917,\n        0.0983099 , -0.04420137], dtype=float32)>, <tf.Variable 'transformer/self_attention/value/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[ 0.08797709,  0.0020717 , -0.02988835, ...,  0.00414013,\n          0.07484715,  0.03971449],\n        [ 0.01181907,  0.01673844,  0.00993257, ...,  0.04269501,\n          0.07497684,  0.05441765],\n        [-0.04123079, -0.0125709 ,  0.07505488, ..., -0.01293301,\n          0.01663662, -0.00806466],\n        ...,\n        [-0.03976909, -0.04241847,  0.04778959, ..., -0.05560155,\n          0.034874  , -0.07447197],\n        [-0.00133578, -0.00624564,  0.04871361, ..., -0.03820138,\n         -0.02092554, -0.03139704],\n        [-0.06732795,  0.0424525 , -0.01663647, ..., -0.04881165,\n         -0.02787822, -0.00515961]],\n\n       [[ 0.07280349, -0.07364671, -0.08526693, ..., -0.06247063,\n          0.00236623, -0.00911083],\n        [-0.03756052,  0.01553301, -0.00284038, ..., -0.06488091,\n         -0.01434528, -0.03161497],\n        [-0.02179443, -0.0646414 , -0.04048219, ...,  0.02184545,\n         -0.0211122 ,  0.01740629],\n        ...,\n        [-0.02763911,  0.00523491,  0.00303702, ...,  0.00910007,\n          0.00787244, -0.05087136],\n        [-0.01797713, -0.04068588,  0.02618967, ..., -0.0096323 ,\n         -0.06151869,  0.02406118],\n        [-0.02478819,  0.04828609, -0.00703087, ..., -0.03620443,\n          0.04607834,  0.03005329]],\n\n       [[ 0.01337238, -0.03798615,  0.02630081, ...,  0.01285004,\n          0.08671611,  0.06131849],\n        [ 0.07498433, -0.0858638 , -0.02551636, ..., -0.00508317,\n          0.00318569,  0.06502707],\n        [ 0.02094145, -0.00057176,  0.00539172, ..., -0.01223748,\n         -0.00193865,  0.00151399],\n        ...,\n        [ 0.02882743, -0.05991769,  0.04019088, ...,  0.06426458,\n          0.01378288, -0.07480925],\n        [ 0.03058263,  0.04395986,  0.01187258, ..., -0.00552897,\n          0.0382335 , -0.02911536],\n        [-0.06633037,  0.00577369,  0.01846346, ..., -0.02890185,\n          0.01893614,  0.00294089]],\n\n       ...,\n\n       [[ 0.03748734, -0.07109033, -0.00454385, ..., -0.00556623,\n         -0.07197092,  0.00822964],\n        [ 0.00029132, -0.03028077, -0.00639235, ..., -0.05224453,\n          0.07962234,  0.01018672],\n        [-0.04369333, -0.05030391,  0.01688178, ...,  0.0066217 ,\n          0.01812653,  0.00703911],\n        ...,\n        [-0.10768004,  0.05172554,  0.0182227 , ...,  0.05067201,\n          0.01246925,  0.0401826 ],\n        [-0.04991208, -0.01331158, -0.01212245, ..., -0.04266884,\n          0.04379959,  0.01865999],\n        [-0.05395498, -0.03194196, -0.001778  , ..., -0.03485607,\n          0.03047973,  0.03649557]],\n\n       [[ 0.04807007, -0.03686615,  0.01512305, ...,  0.01602007,\n          0.11524873,  0.01916426],\n        [ 0.0012002 , -0.04894599, -0.04309888, ...,  0.07189992,\n          0.15859145, -0.06280167],\n        [ 0.08538401, -0.03809969,  0.04182295, ..., -0.02923686,\n          0.0003086 ,  0.03860561],\n        ...,\n        [-0.01383685, -0.01391714, -0.01385395, ...,  0.00126929,\n          0.0860488 ,  0.02731048],\n        [ 0.03810836,  0.05952343,  0.01847435, ...,  0.04779863,\n          0.0012848 , -0.09237032],\n        [-0.05638543,  0.024988  , -0.04909164, ...,  0.06645802,\n          0.11695842,  0.04548807]],\n\n       [[ 0.00357805, -0.01972263, -0.020643  , ..., -0.02112963,\n          0.04822826,  0.01768974],\n        [ 0.05982173,  0.00412898,  0.02767219, ..., -0.04594505,\n          0.02497969, -0.011791  ],\n        [ 0.06478981, -0.02329071,  0.00180043, ..., -0.02658423,\n          0.00817082, -0.01976474],\n        ...,\n        [ 0.01835014, -0.01268417, -0.07389341, ...,  0.05695285,\n          0.00050769, -0.01934631],\n        [-0.00798785,  0.0209216 , -0.01295373, ...,  0.07503591,\n         -0.05892896, -0.0335428 ],\n        [ 0.02507908,  0.00504514,  0.01544049, ..., -0.00188708,\n         -0.01404955,  0.05319757]]], dtype=float32)>, <tf.Variable 'transformer/output_layer_norm/gamma:0' shape=(1024,) dtype=float32, numpy=\narray([0.8545426 , 0.8777306 , 0.8767569 , ..., 0.8640456 , 0.8231375 ,\n       0.85486865], dtype=float32)>, <tf.Variable 'embeddings/layer_norm/beta:0' shape=(128,) dtype=float32, numpy=\narray([-0.5842526 ,  0.24272971, -0.12445377,  0.07139821, -0.34981656,\n        0.16594781, -0.30217123,  0.6490534 , -0.30634406, -0.36531183,\n        0.16858287, -0.43766633,  0.12411823,  0.33471942,  0.01254949,\n       -0.2908569 , -1.139494  ,  0.11709121,  0.2582868 ,  0.28464222,\n        0.03860448,  0.46567854, -0.3528685 ,  0.3549207 ,  0.8635659 ,\n       -0.16202736,  0.11273721,  0.0516649 ,  0.21996643,  0.07899692,\n        0.5350719 , -0.03773566,  0.5482328 ,  0.34826764,  0.28899294,\n        0.06849271,  0.16730666, -0.21323828,  0.07566579,  0.03076132,\n       -1.4614726 , -0.41675633,  0.28203508,  0.19634478,  0.47250408,\n        0.21584797, -0.18325771, -0.50363094,  0.39384124,  0.35548446,\n       -0.14043917,  0.04353445,  0.04234899,  0.04064114,  0.26725945,\n        0.06668285,  0.21382625,  0.38483828, -0.04219316,  0.04379422,\n        0.5362364 ,  0.00848074, -0.08906814, -0.13959515, -0.0108059 ,\n       -0.150432  ,  0.02988789,  0.1244619 , -0.23843955,  0.2598754 ,\n        0.06482524, -0.34236938,  0.12493712, -0.31151992, -0.05674663,\n        0.32138032,  0.32952127,  0.2600991 ,  1.2608591 , -0.00433848,\n        0.53402925, -0.06318664, -0.05468542, -0.52521217,  0.10494697,\n       -0.2463326 ,  0.17766938, -0.2147248 , -0.04897923,  0.19409223,\n       -0.00354851, -0.03950975,  0.29356265,  0.08504426, -0.03914158,\n       -0.12665841,  0.04963979,  0.14758857, -0.05302747, -0.5430127 ,\n        0.24101722, -0.263537  , -0.8372029 , -0.05900194, -0.03526299,\n        0.03415408,  0.46867988, -0.312193  ,  0.2922889 ,  0.2073657 ,\n        0.02637885, -0.07367035, -0.23456465,  0.36595738,  0.59381425,\n        0.39802575,  0.11532904, -1.1621219 , -0.13976075, -0.11088204,\n       -0.08006179,  0.5729334 ,  0.03168112,  0.24488862, -0.72558   ,\n       -0.3117142 ,  0.3622865 , -0.02723189], dtype=float32)>, <tf.Variable 'transformer/output_layer_norm/beta:0' shape=(1024,) dtype=float32, numpy=\narray([-0.07938902, -0.05059273, -0.00045664, ...,  0.01891402,\n        0.03678424,  0.12761983], dtype=float32)>, <tf.Variable 'transformer/intermediate/kernel:0' shape=(1024, 4096) dtype=float32, numpy=\narray([[ 0.02624489,  0.01479701,  0.02738292, ..., -0.01135132,\n         0.0117222 , -0.01887776],\n       [ 0.01027278,  0.02836631,  0.00807532, ...,  0.00307549,\n        -0.07374579, -0.05794734],\n       [ 0.07240843, -0.11266635, -0.0465501 , ..., -0.01003353,\n         0.01962401, -0.03882667],\n       ...,\n       [-0.03021646, -0.01252673, -0.01728925, ...,  0.11241266,\n         0.06752944, -0.0189009 ],\n       [-0.01871368,  0.04275062,  0.02974374, ..., -0.10041117,\n        -0.00401674, -0.02922116],\n       [ 0.07769395, -0.00169165,  0.06005793, ...,  0.03372611,\n         0.09345875, -0.00471404]], dtype=float32)>, <tf.Variable 'pooler_transform/bias:0' shape=(1024,) dtype=float32, numpy=\narray([-0.04656763, -0.26320603, -0.07046566, ...,  0.26848638,\n       -0.301408  , -0.05583415], dtype=float32)>, <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(128,) dtype=float32, numpy=\narray([1.7839581 , 1.8909203 , 1.8902636 , 1.9057839 , 1.865123  ,\n       1.8633173 , 1.7874655 , 1.8197732 , 1.8653047 , 1.265877  ,\n       1.9067185 , 1.3949844 , 1.8377118 , 1.8029649 , 1.943066  ,\n       1.7839162 , 1.2115556 , 1.8840996 , 1.7027538 , 1.9194046 ,\n       1.7909882 , 2.0551376 , 1.7422584 , 1.8138171 , 1.9750853 ,\n       1.9896872 , 1.8258024 , 1.8482335 , 1.7632504 , 1.8764453 ,\n       1.7474222 , 1.932738  , 1.7700673 , 1.7354928 , 1.3469992 ,\n       0.78094333, 1.8966844 , 1.7008317 , 1.5683017 , 1.70847   ,\n       1.1830852 , 1.6319302 , 1.9137667 , 1.8161463 , 1.660736  ,\n       1.8398185 , 1.8505971 , 1.8121346 , 1.9098474 , 1.8154311 ,\n       1.8577214 , 1.8624518 , 1.8422674 , 1.810782  , 1.9760392 ,\n       1.71011   , 1.823686  , 1.2051458 , 1.7132999 , 2.0394435 ,\n       1.9106469 , 1.7092353 , 1.73497   , 1.6923317 , 1.8144536 ,\n       1.8161547 , 1.8892204 , 1.8127007 , 1.7109252 , 1.8944374 ,\n       1.7437671 , 1.4700319 , 1.6981688 , 1.5983671 , 1.8760558 ,\n       1.9136702 , 1.7502984 , 1.9094018 , 1.0197016 , 1.8225905 ,\n       1.2226652 , 1.9014813 , 1.8830897 , 1.2154391 , 1.9332271 ,\n       1.9730096 , 1.7327032 , 1.8965244 , 1.8862689 , 1.465993  ,\n       1.6774863 , 1.7258805 , 1.7486068 , 1.7492235 , 1.9269828 ,\n       1.8115519 , 1.9743698 , 1.852579  , 1.4711702 , 1.8735343 ,\n       1.8826352 , 1.3469298 , 1.2056285 , 1.7344472 , 1.2986183 ,\n       1.2588569 , 1.9949453 , 1.8725826 , 1.8003536 , 1.3359643 ,\n       1.7860365 , 1.8115499 , 1.8104943 , 1.8090411 , 1.7031308 ,\n       1.8164089 , 1.8747627 , 1.1072854 , 1.9315572 , 1.7622515 ,\n       1.758978  , 1.7557343 , 1.7713057 , 1.8013195 , 1.1476954 ,\n       1.1441917 , 1.8329461 , 1.7555294 ], dtype=float32)>, <tf.Variable 'transformer/self_attention_output/bias:0' shape=(1024,) dtype=float32, numpy=\narray([ 0.09856169, -0.09544315,  0.06416708, ...,  0.03073069,\n       -0.06195455,  0.08915669], dtype=float32)>, <tf.Variable 'transformer/intermediate/bias:0' shape=(4096,) dtype=float32, numpy=\narray([-0.66687495, -0.23961528, -0.80109847, ..., -0.66950315,\n       -0.23912948, -0.38637745], dtype=float32)>, <tf.Variable 'transformer/output/kernel:0' shape=(4096, 1024) dtype=float32, numpy=\narray([[ 0.06272804, -0.0991563 , -0.00634015, ..., -0.05167221,\n        -0.04058805,  0.11515144],\n       [ 0.06619747, -0.0604772 , -0.00470938, ...,  0.0054595 ,\n         0.04805936,  0.08183908],\n       [ 0.00053815,  0.03986236, -0.0038653 , ..., -0.05934481,\n         0.06247399,  0.05197472],\n       ...,\n       [-0.01945007, -0.02923877,  0.02015522, ...,  0.05845422,\n        -0.01744714,  0.07759047],\n       [-0.07426859,  0.0134705 , -0.05658459, ..., -0.00631556,\n         0.04343706, -0.09226128],\n       [-0.02510573, -0.05316114, -0.05383938, ...,  0.07250074,\n        -0.07358983,  0.08247995]], dtype=float32)>, <tf.Variable 'transformer/self_attention_layer_norm/beta:0' shape=(1024,) dtype=float32, numpy=\narray([-0.11128127,  0.09175195, -0.0451484 , ...,  0.00629278,\n        0.02116437, -0.02543932], dtype=float32)>, <tf.Variable 'transformer/self_attention/key/kernel:0' shape=(1024, 16, 64) dtype=float32, numpy=\narray([[[ 2.4713101e-02, -8.4732929e-03,  9.4683498e-02, ...,\n          7.9031169e-02, -1.2722029e-02,  1.8242197e-02],\n        [ 7.3173251e-03, -2.0339107e-02,  2.1190507e-02, ...,\n         -1.5573609e-02, -4.5128711e-03,  1.1003817e-02],\n        [ 7.0165731e-02,  8.8932505e-04, -5.5978518e-02, ...,\n         -4.4360928e-02,  1.2549350e-02,  1.2195073e-02],\n        ...,\n        [ 3.9751898e-02, -7.8894429e-02,  3.5209768e-02, ...,\n          6.1872490e-02, -6.4032704e-02, -1.8050693e-02],\n        [-3.0467499e-02,  3.5991903e-02,  7.0526212e-02, ...,\n         -1.2557115e-01,  3.5162043e-02,  1.0676601e-02],\n        [-7.5061998e-04,  7.2652623e-02, -2.3527259e-02, ...,\n         -3.8151357e-02,  1.7010717e-02,  1.9637674e-02]],\n\n       [[ 2.0027144e-02, -9.4912341e-03, -5.9485622e-02, ...,\n         -4.4538103e-02,  1.1637376e-03, -3.0620754e-02],\n        [ 1.9961732e-02,  2.3787232e-02,  3.3009835e-02, ...,\n          3.4633353e-02, -3.0900784e-02,  4.3894886e-03],\n        [-4.5316410e-03,  7.1450822e-02, -4.0445078e-02, ...,\n         -9.1760159e-02, -5.5172995e-02, -1.6513530e-02],\n        ...,\n        [ 1.4449713e-02,  2.2924665e-02, -1.2238196e-02, ...,\n          7.7013850e-02, -7.7437714e-02, -9.1232777e-02],\n        [-8.5429750e-02,  2.6168317e-02, -9.1173857e-02, ...,\n         -6.3306525e-02,  4.4367980e-02,  3.1533514e-03],\n        [-1.4282439e-02, -1.8458495e-02, -1.6364652e-04, ...,\n          2.8204570e-02, -3.3194371e-02,  1.2041159e-02]],\n\n       [[-1.3470611e-02, -6.6131316e-03,  1.0277274e-02, ...,\n         -2.6586000e-02, -2.7954231e-03,  7.4636444e-02],\n        [ 3.8047303e-02, -7.0768811e-02,  2.7904188e-02, ...,\n          6.4772409e-03,  8.6533353e-03, -5.7381988e-03],\n        [-6.1659995e-02, -1.9641824e-02,  4.5295339e-03, ...,\n         -7.9011984e-02, -8.8489905e-02, -6.3039489e-02],\n        ...,\n        [ 1.7574983e-02, -1.6585337e-02,  6.5038404e-03, ...,\n         -9.8161653e-02,  1.6528068e-02, -4.9473003e-02],\n        [-4.7106016e-02, -1.4097092e-02, -3.6388967e-02, ...,\n         -4.9359822e-03,  1.5996471e-02,  2.7868472e-02],\n        [ 4.2999599e-02,  5.0639473e-02,  1.4499824e-02, ...,\n         -5.7727244e-02, -8.1605487e-02,  2.0229815e-02]],\n\n       ...,\n\n       [[ 6.1360657e-02, -1.4103043e-02,  2.1941089e-03, ...,\n          7.4588634e-02,  4.0464137e-02, -6.5672502e-04],\n        [ 3.8772956e-02,  1.7533615e-02, -3.8802300e-02, ...,\n          2.1978794e-03,  3.0107835e-02,  4.9107172e-02],\n        [ 8.9048423e-02, -4.8273843e-02, -1.1750394e-02, ...,\n          5.0601628e-02,  5.5317212e-02, -6.8827339e-02],\n        ...,\n        [ 3.9119568e-02,  2.8708689e-02, -4.8825359e-03, ...,\n         -4.1826796e-02,  7.7156126e-02, -8.6068429e-02],\n        [-1.0914610e-03,  7.4436881e-02, -9.1448031e-02, ...,\n         -1.2533712e-02, -1.7853940e-02, -1.3294272e-02],\n        [ 2.4324105e-05, -1.8835047e-02, -4.6823423e-02, ...,\n         -3.0126328e-02, -5.2027958e-03,  5.1746584e-02]],\n\n       [[-1.9124746e-02, -3.9369494e-02, -1.9944701e-02, ...,\n          1.0756750e-01, -5.4115411e-02,  2.4449121e-02],\n        [-9.4848692e-02,  1.0229457e-02, -6.5941885e-02, ...,\n          3.5749212e-02,  7.0381328e-02, -2.0526096e-02],\n        [ 5.1128607e-02, -3.6088333e-02,  5.5570420e-02, ...,\n         -1.5034926e-02,  4.7761545e-02,  9.9037580e-02],\n        ...,\n        [ 3.0040503e-02, -3.7970971e-02,  1.0421912e-02, ...,\n         -5.8147941e-02,  1.1260663e-02, -3.3532418e-05],\n        [ 5.4495495e-02, -7.5122397e-03,  3.8050596e-02, ...,\n         -3.3011734e-02,  4.2246524e-03, -8.3926702e-03],\n        [ 4.6221283e-03, -5.3813014e-02,  1.6895467e-02, ...,\n          1.9936441e-02, -6.3096374e-02,  1.3950768e-02]],\n\n       [[ 1.6954603e-02,  5.7040595e-02,  1.5734315e-02, ...,\n          3.6513884e-02, -1.2498280e-02, -3.2489341e-02],\n        [-7.3507376e-02, -4.7027759e-04,  4.6819609e-02, ...,\n          8.7657543e-03, -3.3977064e-03,  3.0739758e-02],\n        [-1.5084445e-02,  4.5815274e-02, -2.8523199e-02, ...,\n          2.1990506e-02, -2.8816486e-02, -2.4439283e-02],\n        ...,\n        [-5.8590394e-02, -2.2878752e-04,  8.9097640e-04, ...,\n         -6.1450910e-02, -5.5946052e-02, -2.5287621e-02],\n        [-3.9880879e-02, -4.3279279e-02, -1.0391799e-02, ...,\n         -1.1459351e-01, -5.8107884e-03,  5.1980626e-02],\n        [ 3.7124943e-02, -3.0228711e-04,  1.4431281e-02, ...,\n         -2.4514509e-02, -2.7502658e-02,  9.5150033e-03]]], dtype=float32)>, <tf.Variable 'transformer/self_attention_output/kernel:0' shape=(16, 64, 1024) dtype=float32, numpy=\narray([[[-0.12087623, -0.00131766,  0.0059417 , ..., -0.01276294,\n         -0.01676265, -0.10364094],\n        [-0.11030291,  0.03917245,  0.08902217, ..., -0.00991671,\n         -0.03903826, -0.04283248],\n        [-0.08456261,  0.05295455, -0.05333614, ...,  0.04496399,\n         -0.02267177,  0.03789821],\n        ...,\n        [-0.01463968,  0.00105729, -0.03952024, ..., -0.00622237,\n          0.02773172,  0.04143756],\n        [ 0.02726533, -0.04562404, -0.01092314, ...,  0.07876874,\n         -0.10231116, -0.08164937],\n        [-0.03413047,  0.04504857, -0.07175126, ..., -0.07401045,\n         -0.01263101,  0.04526484]],\n\n       [[ 0.04133579,  0.00715958,  0.07387298, ..., -0.02295391,\n          0.01748894,  0.04781013],\n        [-0.07751813, -0.02407866,  0.04599382, ..., -0.16222243,\n         -0.10661072,  0.00727186],\n        [-0.06002577,  0.02527035,  0.04255925, ..., -0.0862935 ,\n         -0.04250443, -0.03319255],\n        ...,\n        [ 0.04278314,  0.03787831,  0.00446601, ...,  0.05054899,\n         -0.08515636,  0.05557117],\n        [-0.02215524,  0.00050115,  0.08688294, ..., -0.09411283,\n         -0.01767358, -0.00129942],\n        [-0.04210161,  0.02384934,  0.08061824, ...,  0.124822  ,\n          0.03908351, -0.0484701 ]],\n\n       [[-0.09888351, -0.0051013 ,  0.03721306, ..., -0.03904448,\n          0.02210518,  0.06002177],\n        [-0.00963472, -0.0220372 ,  0.05162675, ..., -0.03965967,\n          0.01706901,  0.06558199],\n        [ 0.08189272,  0.06789871,  0.05701382, ..., -0.01269164,\n          0.03169342,  0.00836909],\n        ...,\n        [-0.02334395,  0.01568061,  0.05703887, ...,  0.0273691 ,\n         -0.01814027, -0.01872451],\n        [ 0.06504452, -0.03338562, -0.0703576 , ..., -0.05403217,\n          0.07934742,  0.07556178],\n        [-0.00310893, -0.04448323, -0.05647891, ...,  0.00665758,\n          0.00152404, -0.00411649]],\n\n       ...,\n\n       [[ 0.04162116, -0.03725463, -0.04037993, ..., -0.05948862,\n         -0.03199046, -0.06347068],\n        [ 0.01424028, -0.01043441, -0.01848511, ...,  0.03906364,\n          0.10528692, -0.01073527],\n        [ 0.01106103, -0.0317982 , -0.08034817, ..., -0.00695507,\n         -0.03181245, -0.03582251],\n        ...,\n        [ 0.05527718,  0.00725207, -0.03463059, ...,  0.02542693,\n         -0.00925153,  0.00595798],\n        [-0.00356322,  0.10247871,  0.04952729, ..., -0.01858452,\n         -0.00868734, -0.05647591],\n        [-0.04316147, -0.00417736,  0.04818535, ..., -0.03246309,\n          0.05976842, -0.00438782]],\n\n       [[ 0.0248446 , -0.01758825, -0.04737019, ...,  0.04280659,\n         -0.02860698,  0.02186623],\n        [-0.05687475,  0.02948832, -0.04468279, ..., -0.0093023 ,\n          0.0226582 ,  0.08020571],\n        [ 0.02384427, -0.02303015,  0.0617718 , ..., -0.03017887,\n         -0.0407806 ,  0.04612486],\n        ...,\n        [-0.07820291, -0.03813744, -0.0063624 , ...,  0.00369967,\n          0.03497613,  0.00212011],\n        [-0.06974534, -0.01040694, -0.00887159, ...,  0.04638416,\n          0.04365183,  0.03806246],\n        [ 0.01768665,  0.05274608,  0.07386105, ...,  0.0053088 ,\n         -0.02989793,  0.0253226 ]],\n\n       [[ 0.0321832 , -0.0242134 ,  0.0163552 , ...,  0.05967472,\n          0.03027917, -0.03767041],\n        [-0.0836022 , -0.0253592 ,  0.04704583, ...,  0.05642388,\n         -0.04858131, -0.01046145],\n        [ 0.05051516, -0.00169722, -0.02403292, ...,  0.01683992,\n          0.02337351,  0.00433411],\n        ...,\n        [-0.01164332,  0.03490139,  0.00623156, ...,  0.04541679,\n         -0.03625841,  0.02501275],\n        [ 0.01010661, -0.02505532,  0.00512691, ..., -0.01287222,\n         -0.02916379,  0.01367385],\n        [-0.00354523,  0.03046549,  0.02393773, ...,  0.05403419,\n         -0.02108731, -0.00417873]]], dtype=float32)>, <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 128) dtype=float32, numpy=\narray([[ 2.98617668e-02,  4.58420767e-03,  9.50067490e-03,\n         1.75369158e-02,  2.27376875e-02,  4.29183478e-03,\n        -2.27738265e-03, -3.18773687e-02, -5.63001540e-03,\n         1.66752022e-02, -1.20887235e-02,  2.89540719e-02,\n         1.93531048e-02, -3.11399251e-03, -9.68094263e-03,\n         3.08668386e-04,  7.51848668e-02, -1.16000529e-02,\n        -5.12433704e-03,  5.25925029e-03, -1.38946734e-02,\n         4.76975273e-03,  4.62501822e-03, -6.50442598e-05,\n         3.29455268e-03, -1.21591957e-02,  5.38068730e-03,\n        -5.98245393e-03,  1.09438878e-02, -4.52870177e-03,\n        -2.04672646e-02, -1.66713949e-02, -1.18922638e-02,\n        -4.03177040e-03,  2.68683936e-02, -9.11266655e-02,\n        -1.54091446e-02, -1.04631260e-02, -5.78899076e-03,\n         1.03390468e-02,  6.26485571e-02, -4.99828369e-04,\n         4.90542548e-03, -1.14343350e-03, -6.82649016e-03,\n        -6.46636821e-03, -2.14987788e-02,  5.80138573e-03,\n        -1.58117935e-02, -1.06885741e-02, -2.43090885e-03,\n         2.31577959e-02,  1.02502853e-02, -2.44546775e-03,\n        -4.73010400e-03,  2.49942183e-03, -4.50519752e-03,\n        -4.47330670e-03, -7.95519073e-03,  1.66786332e-02,\n        -3.83057236e-03,  1.03940750e-02,  9.91822407e-03,\n        -8.73943418e-03, -8.47806409e-03,  1.48456031e-02,\n        -5.68873063e-03, -1.08904056e-02, -6.08319824e-04,\n         1.80337823e-03, -7.87300430e-03,  8.92674830e-03,\n        -1.73187945e-02,  2.09515984e-03,  9.51454858e-04,\n        -4.76388540e-03, -6.71155564e-03, -2.73680547e-04,\n        -4.81038205e-02, -1.03519205e-02, -4.91856225e-02,\n        -5.66279888e-03,  6.91874698e-03,  1.69854257e-02,\n         5.39499195e-03,  1.53280245e-02, -1.12297228e-02,\n        -3.91890714e-03,  1.98564236e-03,  1.28436293e-02,\n        -1.87377427e-02,  1.86861132e-03, -1.15595544e-02,\n        -6.88303588e-03, -3.81718599e-03,  6.70217117e-03,\n        -1.81409102e-02, -1.42892322e-03,  9.69388336e-03,\n         3.38096693e-02, -1.23233367e-02,  2.05204450e-02,\n         3.89646031e-02, -3.02533736e-03, -2.15234347e-02,\n        -6.32723561e-03,  1.17032044e-02, -7.54641183e-03,\n         3.60583392e-04,  1.73142459e-02,  2.28945562e-03,\n         1.89215306e-03, -1.35893542e-02, -6.38993399e-04,\n        -1.21622784e-02, -1.43322041e-02, -7.85413571e-03,\n         6.35343790e-02,  1.09696239e-02, -4.97072469e-03,\n        -1.25197712e-02, -3.98948044e-03,  1.28613831e-02,\n        -1.80547517e-02,  5.86996675e-02,  4.84309130e-04,\n        -1.03661912e-02, -4.17545671e-03],\n       [ 9.51315742e-03,  2.64111790e-03,  5.81751531e-03,\n         4.10360843e-03,  1.55416913e-02,  1.55874644e-03,\n        -5.31348353e-03, -4.87021580e-02,  1.00112511e-02,\n         2.75518820e-02, -1.85683072e-02,  2.73402948e-02,\n        -1.22063803e-02, -4.09271149e-03, -1.37833096e-02,\n         2.41741035e-02,  4.24481854e-02, -4.00120532e-03,\n        -3.35831493e-02, -1.33783203e-02,  2.09027017e-03,\n         8.39193538e-03,  1.90373324e-02, -1.89809110e-02,\n        -1.05222119e-02, -2.92985654e-03, -4.83474694e-03,\n        -3.20151169e-03,  7.30225863e-03,  9.39310808e-03,\n        -1.22383051e-02, -8.78334511e-03, -3.00480910e-02,\n         2.01238692e-03, -2.83827409e-02,  8.82106274e-02,\n        -1.94496717e-02, -3.62360314e-03, -5.34485793e-03,\n         4.65337234e-03,  3.76006775e-02,  2.69234143e-02,\n        -1.06045017e-02, -1.79957170e-02, -4.03852109e-03,\n         2.52132537e-03, -1.05875516e-02,  8.53512343e-03,\n        -2.45905947e-02, -1.00720078e-02, -1.32326074e-02,\n         2.51564309e-02,  2.14203354e-03, -2.51882207e-02,\n         1.15820989e-02,  2.51928228e-03,  6.23461697e-03,\n        -7.63629982e-03, -2.04616474e-04,  2.41278857e-02,\n        -1.79238878e-02, -1.55131910e-02,  4.07387875e-03,\n         8.40316899e-03,  1.20135089e-02,  2.82466188e-02,\n         1.81839261e-02, -9.39134136e-03,  1.00992816e-02,\n        -2.92194262e-03, -9.00639873e-03,  2.28380989e-02,\n        -1.50002800e-02,  1.30763149e-03, -6.63995510e-03,\n         3.84626235e-03, -1.98405497e-02,  2.38769618e-03,\n        -9.61042866e-02, -7.00418372e-03, -4.75384183e-02,\n        -7.61770876e-03,  5.07009681e-03,  3.13257128e-02,\n         1.43967173e-03,  2.42153052e-02, -6.58777030e-03,\n         7.36570219e-03, -4.23991401e-03, -5.32793056e-04,\n         1.39645627e-02, -1.48792369e-02, -1.02066770e-02,\n        -2.86848191e-03,  3.51263513e-03, -1.29089076e-02,\n        -1.11678587e-02, -4.60836251e-04, -5.57290018e-03,\n         2.38979999e-02, -1.34584466e-02,  2.72901040e-02,\n         3.52007523e-02,  5.37421845e-04,  5.08337431e-02,\n        -1.19858270e-03,  3.09318351e-03, -8.45669943e-04,\n        -1.43428221e-02, -2.99898349e-02, -2.00865697e-02,\n         1.51976733e-03, -8.06429703e-03, -1.30432064e-03,\n        -7.50076445e-03, -2.58349683e-02, -1.28204534e-02,\n         6.31427392e-02,  4.21355572e-03,  1.35499082e-04,\n        -1.17550660e-02, -2.00037528e-02, -5.88530907e-03,\n        -5.21364575e-03,  1.01053575e-02,  2.43842863e-02,\n        -2.61453558e-02,  1.84759460e-02]], dtype=float32)>, <tf.Variable 'pooler_transform/kernel:0' shape=(1024, 1024) dtype=float32, numpy=\narray([[-0.00052518, -0.0253877 , -0.01490941, ...,  0.01312183,\n        -0.0278377 , -0.04181223],\n       [ 0.01424094,  0.01080372,  0.05730467, ..., -0.02480907,\n         0.03609122,  0.04318529],\n       [ 0.05742806,  0.01663461, -0.0205514 , ..., -0.00812335,\n        -0.0091945 ,  0.00107263],\n       ...,\n       [-0.01611846, -0.0331498 , -0.03367683, ...,  0.0242574 ,\n        -0.01729438, -0.01731833],\n       [ 0.02241669,  0.02788646,  0.01500472, ..., -0.01016136,\n        -0.00482643,  0.02016787],\n       [-0.02179764,  0.0102333 , -0.02675315, ..., -0.03132581,\n         0.0061183 ,  0.00078582]], dtype=float32)>, <tf.Variable 'transformer/self_attention/key/bias:0' shape=(16, 64) dtype=float32, numpy=\narray([[-0.19564319,  0.11978531, -0.41439384, ...,  0.08712698,\n        -0.08149096, -0.1953145 ],\n       [ 0.6122577 , -0.02963953, -0.16226979, ..., -0.47796267,\n        -0.06287912, -0.06575805],\n       [ 0.6078491 , -0.40588948,  0.15858388, ..., -0.40763453,\n        -0.26575118, -0.01651137],\n       ...,\n       [-0.09129642, -0.19593433,  0.586245  , ...,  0.6237123 ,\n        -0.66800666, -0.12655008],\n       [ 0.07444556, -0.4216305 , -0.71830815, ..., -0.73751533,\n         0.46753627,  0.2613811 ],\n       [-0.02628985,  0.48830336, -0.36769304, ..., -0.0338308 ,\n        -0.00832799,  0.16880564]], dtype=float32)>, <tf.Variable 'word_embeddings/embeddings:0' shape=(30000, 128) dtype=float32, numpy=\narray([[ 0.05185268,  0.02554895,  0.07820596, ...,  0.13243212,\n        -0.11136495, -0.0815003 ],\n       [-0.02186797,  0.08194945, -0.03814889, ..., -0.0105723 ,\n         0.08643766,  0.07545596],\n       [ 0.03902123, -0.04490783,  0.02247689, ...,  0.0101957 ,\n        -0.01016969,  0.01507433],\n       ...,\n       [-0.05190184,  0.05257452, -0.06086375, ...,  0.02349056,\n        -0.03793135,  0.11683138],\n       [-0.08752286,  0.01797947,  0.0432927 , ..., -0.02513511,\n        -0.02745636, -0.05742462],\n       [-0.00042062,  0.01001474, -0.10400026, ...,  0.02441972,\n        -0.13680935, -0.02415917]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,input_meta_data,hub_url):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.max_seq_length = input_meta_data['max_seq_length']\n",
    "        self.num_labels = input_meta_data['num_labels']\n",
    "        self.default_label = tf.constant(input_meta_data['default_label'])\n",
    "        self.sentence_piece_layer = SentencepieceTokenization(model_path=sentencepiece_path,max_seq_length=tf.constant(max_seq_length))\n",
    "        self.bert_model = hub.KerasLayer(hub_url,trainable=True,tags=None)\n",
    "        # This doesn't really matter as we will be loading the weights from saved checkpoint\n",
    "        self.initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "        # we don't want dropout for the model we are going to serve so skipping that\n",
    "        self.dense_final = tf.keras.layers.Dense(num_labels,kernel_initializer=self.initializer,name='output',dtype=tf.float32)\n",
    "        self.label_lookup = LabelLookup(filepath=label_file,default=default_label)\n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=None,dtype=tf.string)])\n",
    "    def call(input_text):\n",
    "        return get_classified_output(input_text)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=None,dtype=tf.string)])\n",
    "    def get_bert_embedding(input_text):\n",
    "        input_ids_processed,segment_ids_processed,input_mask_processed = self.sentence_piece_layer(input_text)\n",
    "        \n",
    "        ### pooled_output will give the representation for [CLS]\n",
    "        ### sequence_output will give representations for all tokens\n",
    "        ##since it's classification task we will just use pooled_output\n",
    "        pooled_output, sequence_output = self.bert_model([input_ids_processed, input_mask_processed, segment_ids_processed])\n",
    "\n",
    "        return {'pooled_output':pooled_output}\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=None,dtype=tf.string)])\n",
    "    def get_classified_output(input_text):\n",
    "        pooled_dict = get_bert_embedding(input_text)\n",
    "        pooled_output = pooled_dict['pooled_output']\n",
    "\n",
    "        # log_probs = tf.nn.softmax()\n",
    "        dense_output= self.dense_final(pooled_output)\n",
    "        log_probs = tf.nn.log_softmax(dense_output, axis=-1)\n",
    "        label_id = tf.argmax(log_probs,axis=-1)\n",
    "\n",
    "        label = self.label_lookup(label_id)\n",
    "\n",
    "    #     model  = tf.keras.Model(inputs={'input_text':input_text},\n",
    "    #                          outputs=label)\n",
    "\n",
    "    #     checkpoint = tf.train.Checkpoint(model=model)\n",
    "    #     checkpoint.restore(checkpoint_path).assert_existing_objects_matched()\n",
    "    #     model.load_weights(checkpoint_path).assert_existing_objects_matched()\n",
    "        return label\n",
    "tf.keras.backend.clear_session()\n",
    "input_text = tf.keras.Input(shape=(),dtype=tf.string,name='input_text')\n",
    "custom_model=CustomModel(input_meta_data,bert_hub_url)\n",
    "checkpoint_path=tf.train.latest_checkpoint(output_folder)\n",
    "custom_model.load_weights(checkpoint_path).assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_final_model_keras = tf.keras.models.load_model(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_final_model = tf.saved_model.load(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load._WrapperFunction at 0x7fab6ae73310>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default = loaded_final_model.signatures['serving_default']\n",
    "serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((),\n",
       " {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default.structured_input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_lookup': TensorSpec(shape=(None,), dtype=tf.string, name='label_lookup')}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default.structured_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_lookup': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'other-other'], dtype=object)>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_default(tf.constant(['talk to an agent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model_to_save, bert_updated,input_text,label,log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "build_tensor_info is not supported in Eager mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-2c3a1b56d23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.compat.v1.saved_model.predict_signature_def(inputs={'input_text':input_text},\n\u001b[0;32m----> 2\u001b[0;31m                                                            outputs={'output_label':label})\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py\u001b[0m in \u001b[0;36mpredict_signature_def\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m   signature_inputs = {key: utils.build_tensor_info(tensor)\n\u001b[0;32m--> 201\u001b[0;31m                       for key, tensor in inputs.items()}\n\u001b[0m\u001b[1;32m    202\u001b[0m   signature_outputs = {key: utils.build_tensor_info(tensor)\n\u001b[1;32m    203\u001b[0m                        for key, tensor in outputs.items()}\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m   signature_inputs = {key: utils.build_tensor_info(tensor)\n\u001b[0;32m--> 201\u001b[0;31m                       for key, tensor in inputs.items()}\n\u001b[0m\u001b[1;32m    202\u001b[0m   signature_outputs = {key: utils.build_tensor_info(tensor)\n\u001b[1;32m    203\u001b[0m                        for key, tensor in outputs.items()}\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mbuild_tensor_info\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \"\"\"\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"build_tensor_info is not supported in Eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tensor_info_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: build_tensor_info is not supported in Eager mode."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.saved_model.predict_signature_def(inputs={'input_text':input_text},\n",
    "                                                           outputs={'output_label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model_to_save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(shape=(None,), dtype=tf.string)])\n",
    "  def add(self, ):\n",
    "    return x + x + 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
    "  def add(self, x):\n",
    "    return x + x + 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'serve'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_with_signature_path=os.path.join(output_folder,'final_model_with_signature')\n",
    "classification_model_to_save.save(final_model_with_signature_path,signatures=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_final_model.signatures['serving_default'](['talk to an agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * ['talk to agent', 'talk to agent', 'talk to agent', 'talk to agent']\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='inputs/input_text')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='inputs/input_text')}\n    * True\n    * None\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-7c34273b9258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_final_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'talk to agent'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'talk to agent'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'talk to agent'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'talk to agent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         .format(_pretty_format_positional(args), kwargs,\n\u001b[1;32m    260\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \"\\n\\n\".join(signature_descriptions)))\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0mconcrete_function_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * ['talk to agent', 'talk to agent', 'talk to agent', 'talk to agent']\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='inputs/input_text')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='input_text')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_text': TensorSpec(shape=(None,), dtype=tf.string, name='inputs/input_text')}\n    * True\n    * None\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "loaded_final_model(['talk to agent','talk to agent','talk to agent','talk to agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensorflow.python.ops.lookup_ops.StaticHashTable,\n",
       " tensorflow.python.ops.lookup_ops.InitializableLookupTableBase,\n",
       " tensorflow.python.ops.lookup_ops.LookupInterface,\n",
       " tensorflow.python.training.tracking.tracking.TrackableResource,\n",
       " tensorflow.python.training.tracking.tracking.CapturableResource,\n",
       " tensorflow.python.training.tracking.base.Trackable,\n",
       " object]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.lookup.StaticHashTable.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%tensorboard --logdir /var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large/checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_predict(row):\n",
    "    text  = row['text']\n",
    "    d = {}\n",
    "    t = []\n",
    "    t.append(2)\n",
    "    temp= tfs.encode([text],model_proto=sp_model).values.numpy()[0]\n",
    "    t.extend(temp)\n",
    "    t.append(3)\n",
    "    \n",
    "#     d['input_ids'] = [t]\n",
    "#     d['input_mask'] = [[1]*len(t)]\n",
    "#     d['segment_ids'] = [[0]*len(t)]\n",
    "    \n",
    "    d['input_ids'] = tf.convert_to_tensor([t],dtype=tf.int32)\n",
    "    d['input_mask'] = tf.convert_to_tensor([[1]*len(t)],dtype=tf.int32)\n",
    "    d['segment_ids'] = tf.convert_to_tensor([[0]*len(t)],dtype=tf.int32)\n",
    "#     return pd.Series(d)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n",
       "1    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n",
       "2    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n",
       "3    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n",
       "4    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n",
       "dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test = df.head()\n",
    "temp_test = temp_test.apply(lambda x: get_input_predict(x),axis=1)\n",
    "temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=\n",
       " array([[   2,   92,   42, 2660,   51, 1071,   20,   51, 4216,   60,    3]],\n",
       "       dtype=int32)>,\n",
       " 'input_mask': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       " 'segment_ids': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type dict).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    465\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 466\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for 0    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n1    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n2    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n3    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\n4    {'input_ids': ((tf.Tensor(2, shape=(), dtype=i...\ndtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-476b973fbae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     ))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2837\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2838\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2839\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2840\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type dict)."
     ]
    }
   ],
   "source": [
    "trained_model.predict(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2, 92, 42, 2660, 51, 1071, 20, 51, 4216, 60, 3]),\n",
       "       list([2, 13, 1, 93, 13, 1, 1326, 6264, 63, 529, 13, 1, 58, 4213, 2119, 2800, 19, 51, 634, 337, 9, 13, 1, 438, 3320, 6264, 63, 2800, 9, 3]),\n",
       "       list([2, 13, 1, 376, 21, 7582, 3896, 86, 31, 221, 22, 38, 164, 51, 365, 2830, 576, 1427, 3]),\n",
       "       list([2, 184, 92, 31, 477, 51, 375, 6328, 9, 32, 2206, 31, 1049, 57, 186, 3]),\n",
       "       list([2, 13, 1, 1830, 69, 20, 1960, 29, 737, 88, 51, 1071, 3])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test['input_ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = [temp_test['input_ids'].values,temp_test['input_mask'].values,temp_test['segment_ids'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 92, 42, 2660, 51, 1071, 20, 51, 4216, 60, 3],\n",
       "  [2,\n",
       "   13,\n",
       "   1,\n",
       "   93,\n",
       "   13,\n",
       "   1,\n",
       "   1326,\n",
       "   6264,\n",
       "   63,\n",
       "   529,\n",
       "   13,\n",
       "   1,\n",
       "   58,\n",
       "   4213,\n",
       "   2119,\n",
       "   2800,\n",
       "   19,\n",
       "   51,\n",
       "   634,\n",
       "   337,\n",
       "   9,\n",
       "   13,\n",
       "   1,\n",
       "   438,\n",
       "   3320,\n",
       "   6264,\n",
       "   63,\n",
       "   2800,\n",
       "   9,\n",
       "   3],\n",
       "  [2,\n",
       "   13,\n",
       "   1,\n",
       "   376,\n",
       "   21,\n",
       "   7582,\n",
       "   3896,\n",
       "   86,\n",
       "   31,\n",
       "   221,\n",
       "   22,\n",
       "   38,\n",
       "   164,\n",
       "   51,\n",
       "   365,\n",
       "   2830,\n",
       "   576,\n",
       "   1427,\n",
       "   3],\n",
       "  [2, 184, 92, 31, 477, 51, 375, 6328, 9, 32, 2206, 31, 1049, 57, 186, 3],\n",
       "  [2, 13, 1, 1830, 69, 20, 1960, 29, 737, 88, 51, 1071, 3]],\n",
       " 'input_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'segment_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predict_dataset(input_file,seq_length,batch_size,is_training=True):\n",
    "# this is a simplified version & slightly less optimized version of what is used in official bert training\n",
    "# refer to function create_classifier_dataset in models/official/nlp/data/create_finetuning_data.py\n",
    "\n",
    "\n",
    "    # create a tf_data set out of the tfrecords file\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    name_to_features = {\n",
    "        \"input_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"input_mask\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"segment_ids\":tf.io.FixedLenFeature([max_seq_length],tf.int64),\n",
    "        \"label_id\":tf.io.FixedLenFeature([],tf.int64)\n",
    "        }\n",
    "    ## map function processes line by line, similar to spark,scala map or pandas apply fucntion\n",
    "    dataset = dataset.map(lambda record: tf.io.parse_single_example(record, name_to_features))\n",
    "#     now separating out the features & label\n",
    "    def _select_data_from_record(record):\n",
    "#         x contains the features\n",
    "#         y is your prediction\n",
    "#This dataset will be passed to keras's model.fit refer to it's documentation for further details\n",
    "# a short snippet from that documentation\n",
    "\n",
    "# A `tf.data` dataset. Should return a tuple\n",
    "#         of either `(inputs, targets)` or\n",
    "#         `(inputs, targets, sample_weights)`.\n",
    "\n",
    "\n",
    "        x = {\n",
    "            'input_ids': record['input_ids'],\n",
    "            'input_mask': record['input_mask'],\n",
    "            'segment_ids': record['segment_ids']\n",
    "        }\n",
    "        y = record['label_id']\n",
    "        return x\n",
    "    \n",
    "    dataset = dataset.map(_select_data_from_record)\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(100)\n",
    "        dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1024)\n",
    "    return dataset\n",
    "prediction_dataset = get_predict_dataset(eval_data_path,max_seq_length,eval_batch_size,is_training=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[   2,  184,  107, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0],\n",
      "       [   2,  184,  107, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2, 5388, 2697, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0],\n",
      "       [   2,   31,   41, ...,    0,    0,    0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n",
      "{'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[ 2, 92, 13, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0],\n",
      "       [ 2, 13,  1, ...,  0,  0,  0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n",
      "{'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[  2,  13,   1, ...,   0,   0,   0],\n",
      "       [  2,  51, 236, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  2,  13,   1, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0],\n",
      "       [  2,  13,   1, ...,   0,   0,   0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n",
      "{'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[   2, 8827, 2196, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   2,  376,  448, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0],\n",
      "       [   2,   13,    1, ...,    0,    0,    0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n",
      "{'input_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[    2,    13,     1, ...,     0,     0,     0],\n",
      "       [    2,    21,    57, ...,     0,     0,     0],\n",
      "       [    2,    13,     1, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    2,    13,     1, ...,     0,     0,     0],\n",
      "       [    2, 24339,     3, ...,     0,     0,     0],\n",
      "       [    2,    13,     1, ...,     0,     0,     0]])>, 'input_mask': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'segment_ids': <tf.Tensor: shape=(16, 128), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n"
     ]
    }
   ],
   "source": [
    "for line in prediction_dataset.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9895891 ,  0.38930255, -0.2897632 , ...,  1.347748  ,\n",
       "        -0.7115326 ,  0.43504658],\n",
       "       [-0.5799464 , -0.69323003,  0.49325743, ...,  1.1278716 ,\n",
       "        -0.97258717, -0.09923831],\n",
       "       [-0.9445586 , -1.2251675 , -0.37769505, ..., -0.8239982 ,\n",
       "        -0.5968072 , -0.9161253 ],\n",
       "       ...,\n",
       "       [-1.640143  , -0.58176893, -1.2308036 , ..., -0.83895874,\n",
       "        -0.7102679 , -1.271832  ],\n",
       "       [ 0.96426886, -0.1527807 , -0.3959958 , ...,  2.149941  ,\n",
       "        -0.50963145,  0.30589893],\n",
       "       [ 1.1327688 ,  1.637278  , -1.304856  , ...,  3.4651942 ,\n",
       "        -0.15032795,  0.1539227 ]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.predict(prediction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model,core_model = get_albert_model(bert_config=bert_config,\n",
    "                                                               float_type=tf.float32,\n",
    "                                                              num_labels=num_classes,\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               hub_module_url=bert_hub_url)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @tf.function\n",
    "def get_model_part1(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer=None,hub_module_url=None):\n",
    "#     if final_layer_initializer is not None:  \n",
    "#         initializer = final_layer_initializer\n",
    "#     else:\n",
    "#         initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "\n",
    "    if not hub_module_url:\n",
    "        #TODO\n",
    "        print(\"create the model\")\n",
    "        return None\n",
    "#     input_word_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_word_ids')\n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_mask')\n",
    "#     input_type_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_type_ids')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='segment_ids')\n",
    "    return input_ids,input_mask,segment_ids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def get_model_bert(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer,hub_module_url,\n",
    "                   input_ids,input_mask,segment_ids):\n",
    "    tags = set()\n",
    "    tags.add('train')\n",
    "\n",
    "    ### pooled_output will give the representation for [CLS]\n",
    "    ### sequence_output will give representations for all tokens\n",
    "#     bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=tags,signature='tokens',output_key='pooled_output')\n",
    "    bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=None)\n",
    "    print(' bert_model ',bert_model)\n",
    "#     pooled_output,_ = bert_model([input_word_ids,input_mask,input_type_ids]) \n",
    "#     pooled_output,_ = bert_model(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids) \n",
    "#     pooled_output,_ = bert_model(inputs = [input_ids,input_mask,segment_ids]) \n",
    "#     pooled_output,temp = bert_model(inputs = {'input_ids':input_ids,'input_mask':input_mask,'segment_ids':segment_ids})\n",
    "#     pooled_output, _ = bert_model([input_word_ids, input_mask, input_type_ids])\n",
    "    pooled_output, _ = bert_model([input_ids, input_mask, segment_ids])\n",
    "    output = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(pooled_output)                                                       \n",
    "#     pooled_output = bert_model(inputs = {'input_ids':input_ids,'input_mask':input_mask,'segment_ids':segment_ids})\n",
    "#     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\n",
    "#     pooled_output = bert_outputs['pooled_output']\n",
    "#     output = pooled_output\n",
    "#     print('pooled_output ',pooled_output,' temp '+temp)\n",
    "    print('pooled_output ',pooled_output)\n",
    "#     output = bert_outputs['pooled_output']\n",
    "    return output,bert_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t, tf.int32)\n",
    "        example[name] = t\n",
    "\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def single_file_dataset(input_file, name_to_features):\n",
    "    \"\"\"Creates a single-file dataset to be passed for BERT custom training.\"\"\"\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "    d = tf.data.TFRecordDataset(input_file)\n",
    "    d = d.map(lambda record: decode_record(record, name_to_features))\n",
    "\n",
    "    # When `input_file` is a path to a single file or a list\n",
    "    # containing a single path, disable auto sharding so that\n",
    "    # same input file is sent to all workers.\n",
    "    if isinstance(input_file, str) or len(input_file) == 1:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_distribute.auto_shard_policy = (\n",
    "                tf.data.experimental.AutoShardPolicy.OFF)\n",
    "        d = d.with_options(options)\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_classifier_dataset(file_path,\n",
    "                              seq_length,\n",
    "                              batch_size,\n",
    "                              is_training=True,\n",
    "                              input_pipeline_context=None):\n",
    "  \"\"\"Creates input dataset from (tf)records files for train/eval.\"\"\"\n",
    "  name_to_features = {\n",
    "      'input_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'label_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "#       'is_real_example': tf.io.FixedLenFeature([], tf.int64),\n",
    "  }\n",
    "  dataset = single_file_dataset(file_path, name_to_features)\n",
    "\n",
    "  # The dataset is always sharded by number of hosts.\n",
    "  # num_input_pipelines is the number of hosts rather than number of cores.\n",
    "  if input_pipeline_context and input_pipeline_context.num_input_pipelines > 1:\n",
    "    dataset = dataset.shard(input_pipeline_context.num_input_pipelines,\n",
    "                            input_pipeline_context.input_pipeline_id)\n",
    "\n",
    "  def _select_data_from_record(record):\n",
    "#     x = {\n",
    "#         'input_word_ids': record['input_ids'],\n",
    "#         'input_mask': record['input_mask'],\n",
    "#         'input_type_ids': record['segment_ids']\n",
    "#     }\n",
    "    x = {\n",
    "        'input_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'segment_ids': record['segment_ids']\n",
    "    }\n",
    "    y = record['label_id']\n",
    "    return (x, y)\n",
    "\n",
    "  dataset = dataset.map(_select_data_from_record)\n",
    "\n",
    "  if is_training:\n",
    "    dataset = dataset.shuffle(100)\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=is_training)\n",
    "  dataset = dataset.prefetch(1024)\n",
    "  return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_fn(input_file_pattern, max_seq_length, global_batch_size,\n",
    "                   is_training):\n",
    "  \"\"\"Gets a closure to create a dataset.\"\"\"\n",
    "  def _dataset_fn(ctx=None):\n",
    "    \"\"\"Returns tf.data.Dataset for distributed BERT pretraining.\"\"\"\n",
    "    batch_size = ctx.get_per_replica_batch_size(\n",
    "        global_batch_size) if ctx else global_batch_size\n",
    "#     dataset = input_pipeline.create_classifier_dataset(\n",
    "    dataset = create_classifier_dataset(\n",
    "        input_file_pattern,\n",
    "        max_seq_length,\n",
    "        batch_size,\n",
    "        is_training=is_training,\n",
    "        input_pipeline_context=ctx)\n",
    "    return dataset\n",
    "  return _dataset_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = get_dataset_fn(\n",
    "#       FLAGS.train_data_path,\n",
    "      train_data_path,\n",
    "      max_seq_length,\n",
    "#       FLAGS.train_batch_size,\n",
    "      train_batch_size,\n",
    "      is_training=True)\n",
    "eval_input_fn = get_dataset_fn(\n",
    "#       FLAGS.eval_data_path,\n",
    "      eval_data_path,\n",
    "      max_seq_length,\n",
    "#       FLAGS.eval_batch_size,\n",
    "      eval_batch_size,\n",
    "      is_training=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @tf.function\n",
    "def get_model_part3(bert_output,num_labels,final_layer_initializer):\n",
    "    if final_layer_initializer is not None:  \n",
    "        initializer = final_layer_initializer\n",
    "    else:\n",
    "        initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "    #     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\n",
    "    output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(bert_output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def combine_model(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer=None,hub_module_url=None):\n",
    "    input_ids,input_mask,segment_ids = get_model_part1(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer,hub_module_url)\n",
    "    bert_output,bert_model = get_model_bert(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer,hub_module_url,input_ids,input_mask,segment_ids)\n",
    "    print('bert_output',bert_output)\n",
    "    output = get_model_part3(bert_output,num_labels,final_layer_initializer)\n",
    "    return tf.keras.Model(inputs={'input_ids':input_ids,\n",
    "                                 'input_mask':input_mask,\n",
    "                                 'segment_ids':segment_ids},\n",
    "                         outputs=output),bert_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @tf.function\n",
    "def get_classifier_model(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer=None,hub_module_url=None):\n",
    "    if final_layer_initializer is not None:  \n",
    "        initializer = final_layer_initializer\n",
    "    else:\n",
    "        initializer = tf.keras.initializers.TruncatedNormal(stddev=bert_config.initializer_range)\n",
    "\n",
    "    if not hub_module_url:\n",
    "        #TODO\n",
    "        print(\"create the model\")\n",
    "        return None\n",
    "#     input_word_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_word_ids')\n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_mask')\n",
    "#     input_type_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='input_type_ids')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length),dtype=tf.int32,name='segment_ids')\n",
    "    tags = set()\n",
    "    tags.add('train')\n",
    "#     bert_module = hub.Module(hub_module_url,trainable=True)\n",
    "    bert_module = hub.load(hub_module_url,tags=tags)\n",
    "    bert_inputs = {'input_ids':input_ids,\n",
    "                   'input_mask':input_mask,\n",
    "                   'segment_ids':segment_ids}\n",
    "    # https://www.tensorflow.org/hub/common_issues\n",
    "#     bert_outputs = bert_module.signatures['tokens'](\n",
    "#       inputs=bert_inputs,\n",
    "#       signature=\"tokens\",\n",
    "#       as_dict=True)\n",
    "\n",
    "#     bert_outputs = bert_module.signatures['tokens'](\n",
    "#       bert_inputs)\n",
    "    bert_outputs = bert_module.signatures['tokens'](input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\n",
    "    print(bert_outputs)\n",
    "    \n",
    "#     bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=tags,signature='tokens',signature_outputs_as_dict=True)\n",
    "#     pooled_output,_ = bert_model([input_word_ids,input_mask,input_type_ids]) \n",
    "#     pooled_output,_ = bert_model([segment_ids,input_ids,input_mask]) \n",
    "#     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\n",
    "#     pooled_output = bert_outputs['pooled_output']\n",
    "    output = bert_outputs['pooled_output']\n",
    "#     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\n",
    "    output = tf.keras.layers.Dense(num_labels,kernel_initializer=initializer,name='output',dtype=tf.float32)(output)\n",
    "    return tf.keras.Model(inputs={'input_ids':input_ids,\n",
    "                                 'input_mask':input_mask,\n",
    "                                 'segment_ids':segment_ids},\n",
    "                         outputs=output),bert_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tfhub.dev/google/albert_base/2'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_hub_url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def get_model_bert_old(bert_config,float_type,num_labels,max_seq_length,final_layer_initializer,hub_module_url,\n",
    "                   input_ids,input_mask,segment_ids):\n",
    "    tags = set()\n",
    "    tags.add('train')\n",
    "    print(hub_module_url)\n",
    "#     bert_module = hub.Module(hub_module_url,trainable=True)\n",
    "\n",
    "#     bert_module = hub.load(hub_module_url,tags=tags)\n",
    "#     bert_inputs = {'input_ids':input_ids,\n",
    "#                    'input_mask':input_mask,\n",
    "#                    'segment_ids':segment_ids}\n",
    "\n",
    "    # https://www.tensorflow.org/hub/common_issues\n",
    "#     bert_outputs = bert_module.signatures['tokens'](\n",
    "#       inputs=bert_inputs,\n",
    "#       signature=\"tokens\",\n",
    "#       as_dict=True)\n",
    "\n",
    "#     bert_outputs = bert_module.signatures['tokens'](bert_inputs) #bert_outputs\n",
    "#     bert_outputs = bert_module.signatures['tokens'](input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\n",
    "#     print(bert_outputs)\n",
    "    \n",
    "#     bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=tags,signature='tokens',signature_outputs_as_dict=True)\n",
    "    \n",
    "    ### pooled_output will give the representation for [CLS]\n",
    "    ### sequence_output will give representations for all tokens\n",
    "#     bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=tags,signature='tokens',output_key='pooled_output')\n",
    "    bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=None)\n",
    "    print(' bert_model ',bert_model)\n",
    "#     pooled_output,_ = bert_model([input_word_ids,input_mask,input_type_ids]) \n",
    "#     pooled_output,_ = bert_model(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids) \n",
    "#     pooled_output,_ = bert_model(inputs = [input_ids,input_mask,segment_ids]) \n",
    "#     pooled_output,temp = bert_model(inputs = {'input_ids':input_ids,'input_mask':input_mask,'segment_ids':segment_ids})\n",
    "    pooled_output = bert_model(inputs = {'input_ids':input_ids,'input_mask':input_mask,'segment_ids':segment_ids})\n",
    "#     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\n",
    "#     pooled_output = bert_outputs['pooled_output']\n",
    "    output = pooled_output\n",
    "#     print('pooled_output ',pooled_output,' temp '+temp)\n",
    "    print('pooled_output ',pooled_output)\n",
    "#     output = bert_outputs['pooled_output']\n",
    "    return output,bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/extra/users/jgeorge/tf2.0/input/dish/models/albert_en_large'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_checkpoint=output_folder\n",
    "init_checkpoint=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(albert_hub_url,trainable=True,tags=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config=albert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bert_model  <tensorflow_hub.keras_layer.KerasLayer object at 0x7f70b5d017d0>\n",
      "pooled_output  Tensor(\"keras_layer_15/Identity:0\", shape=(None, 1024), dtype=float32)\n",
      "bert_output Tensor(\"dropout_4/Identity:0\", shape=(None, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model,core_model = combine_model(bert_config=albert_config,\n",
    "                                                               float_type=tf.float32,\n",
    "                                                              num_labels=num_classes,\n",
    "                                                              max_seq_length=max_seq_length,\n",
    "                                                               hub_module_url=albert_hub_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tfhub.dev/tensorflow/albert_en_large/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The SavedModel at /tmp/tfhub_modules/d0ceaf43f67b8744561ebeeaea4c7c188a6e6f78 has one MetaGraph with tags ['serve'], but got an incompatible argument tags={'train'} to tf.saved_model.load. You may omit it, pass 'None', or pass matching tags.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-6425cb3f7ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       use_keras_compile_fit=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-71fcfd2258d0>\u001b[0m in \u001b[0;36mrun_bert_classifier\u001b[0;34m(strategy, bert_config, input_meta_data, model_dir, epochs, steps_per_epoch, steps_per_loop, eval_steps, warmup_steps, initial_lr, init_checkpoint, train_input_fn, eval_input_fn, custom_callbacks, run_eagerly, use_keras_compile_fit)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mmetric_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mcustom_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       run_eagerly=run_eagerly)\n\u001b[0m",
      "\u001b[0;32m/var/extra/users/jgeorge/tf2.0/git/models/official/modeling/model_training_utils.py\u001b[0m in \u001b[0;36mrun_customized_training_loop\u001b[0;34m(_sentinel, strategy, model_fn, loss_fn, scale_loss, model_dir, train_input_fn, steps_per_epoch, steps_per_loop, epochs, eval_input_fn, eval_steps, metric_fn, init_checkpoint, custom_callbacks, run_eagerly, sub_model_export_name, explicit_allreduce, pre_allreduce_callbacks, post_allreduce_callbacks)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# To correctly place the model weights on accelerators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# model and optimizer should be created in scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       raise ValueError('User should set optimizer attribute to model '\n",
      "\u001b[0;32m<ipython-input-114-71fcfd2258d0>\u001b[0m in \u001b[0;36m_get_classifier_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                                   \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                   \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                                                    hub_module_url=albert_hub_url)\n\u001b[0m\u001b[1;32m     32\u001b[0m         classifier_model.optimizer = optimization.create_optimizer(init_lr=initial_lr,\n\u001b[1;32m     33\u001b[0m                                                                    \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-2662d067a25b>\u001b[0m in \u001b[0;36mcombine_model\u001b[0;34m(bert_config, float_type, num_labels, max_seq_length, final_layer_initializer, hub_module_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcombine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_part1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_part3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-e276c6602062>\u001b[0m in \u001b[0;36mget_model_bert\u001b[0;34m(bert_config, float_type, num_labels, max_seq_length, final_layer_initializer, hub_module_url, input_ids, input_mask, segment_ids)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m### pooled_output will give the representation for [CLS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m### sequence_output will give representations for all tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbert_hub_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pooled_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' bert_model '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     pooled_output,_ = bert_model([input_word_ids,input_mask,input_type_ids])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m           _convert_nest_to_shapes(output_shape))\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \"\"\"\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    597\u001b[0m            \u001b[0;34m\"incompatible argument tags={} to tf.saved_model.load. You may omit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m            \"it, pass 'None', or pass matching tags.\")\n\u001b[0;32m--> 599\u001b[0;31m           .format(export_dir, meta_graph_def.meta_info_def.tags, tags))\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The SavedModel at /tmp/tfhub_modules/d0ceaf43f67b8744561ebeeaea4c7c188a6e6f78 has one MetaGraph with tags ['serve'], but got an incompatible argument tags={'train'} to tf.saved_model.load. You may omit it, pass 'None', or pass matching tags."
     ]
    }
   ],
   "source": [
    "trained_model = run_bert_classifier(\n",
    "      strategy,\n",
    "      albert_config,\n",
    "      input_meta_data,\n",
    "      albert_model_dir,\n",
    "      epochs,\n",
    "      steps_per_epoch,\n",
    "      steps_per_loop,\n",
    "      eval_steps,\n",
    "      warmup_steps,\n",
    "      learning_rate,\n",
    "      init_checkpoint,\n",
    "      train_input_fn,\n",
    "      eval_input_fn,\n",
    "      run_eagerly=False,\n",
    "      use_keras_compile_fit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the existing tensorflow graph\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bert_classifier(strategy,\n",
    "                        bert_config,\n",
    "                        input_meta_data,\n",
    "                        model_dir,\n",
    "                        epochs,\n",
    "                        steps_per_epoch,\n",
    "                        steps_per_loop,\n",
    "                        eval_steps,\n",
    "                        warmup_steps,\n",
    "                        initial_lr,\n",
    "                        init_checkpoint,\n",
    "                        train_input_fn,\n",
    "                        eval_input_fn,\n",
    "                        custom_callbacks=None,\n",
    "                        run_eagerly=False,\n",
    "                        use_keras_compile_fit=False):\n",
    "    \"\"\"Run BERT classifier training using low-level API.\"\"\"\n",
    "    max_seq_length = input_meta_data['max_seq_length']\n",
    "    num_classes = input_meta_data['num_labels']\n",
    "    def _get_classifier_model():\n",
    "#     bert_models.classifier_model\n",
    "#     classifier_model,core_model = get_classifier_model(bert_config=bert_config,\n",
    "#                                                                float_type=tf.float32,\n",
    "#                                                               num_labels=num_classes,\n",
    "#                                                               max_seq_length=max_seq_length,\n",
    "#                                                                hub_module_url=albert_hub_url)\n",
    "        classifier_model,core_model = combine_model(bert_config=bert_config,\n",
    "                                                                   float_type=tf.float32,\n",
    "                                                                  num_labels=num_classes,\n",
    "                                                                  max_seq_length=max_seq_length,\n",
    "                                                                   hub_module_url=albert_hub_url)\n",
    "        classifier_model.optimizer = optimization.create_optimizer(init_lr=initial_lr,\n",
    "                                                                   num_train_steps=steps_per_epoch*epochs,\n",
    "                                                                   num_warmup_steps=warmup_steps)\n",
    "        return classifier_model,core_model\n",
    "    loss_multiplier = 1\n",
    "    loss_fn = get_loss_fn(num_classes,loss_multiplier)\n",
    "    \n",
    "    def metric_fn():\n",
    "        return tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy',dtype=tf.float32)\n",
    "    return model_training_utils.run_customized_training_loop(\n",
    "      strategy=strategy,\n",
    "      model_fn=_get_classifier_model,\n",
    "      loss_fn=loss_fn,\n",
    "      model_dir=model_dir,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      steps_per_loop=steps_per_loop,\n",
    "      epochs=epochs,\n",
    "      train_input_fn=train_input_fn,\n",
    "      eval_input_fn=eval_input_fn,\n",
    "      eval_steps=eval_steps,\n",
    "      init_checkpoint=init_checkpoint,\n",
    "      metric_fn=metric_fn,\n",
    "      custom_callbacks=custom_callbacks,\n",
    "      run_eagerly=run_eagerly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/extra/users/jgeorge/tf2.0/input/albert_base'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.experimental_run_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_dish=os.path.join(main_exp_folder,'models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/extra/users/jgeorge/tf2.0/input/dish/data/jan17_2020/models'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir_dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_checkpoint=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<official.nlp.albert.configs.AlbertConfig at 0x7f74029d7ad0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bert_model  <tensorflow_hub.keras_layer.KerasLayer object at 0x7f7402ebb150>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:206 call  *\n        self._check_trainability()\n    /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:265 _check_trainability  *\n        raise ValueError(\n\n    ValueError: Setting hub.KerasLayer.trainable = True is unsupported when loading from the hub.Module format of TensorFlow 1.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-6425cb3f7ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       use_keras_compile_fit=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-71fcfd2258d0>\u001b[0m in \u001b[0;36mrun_bert_classifier\u001b[0;34m(strategy, bert_config, input_meta_data, model_dir, epochs, steps_per_epoch, steps_per_loop, eval_steps, warmup_steps, initial_lr, init_checkpoint, train_input_fn, eval_input_fn, custom_callbacks, run_eagerly, use_keras_compile_fit)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mmetric_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mcustom_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       run_eagerly=run_eagerly)\n\u001b[0m",
      "\u001b[0;32m/var/extra/users/jgeorge/tf2.0/git/models/official/modeling/model_training_utils.py\u001b[0m in \u001b[0;36mrun_customized_training_loop\u001b[0;34m(_sentinel, strategy, model_fn, loss_fn, scale_loss, model_dir, train_input_fn, steps_per_epoch, steps_per_loop, epochs, eval_input_fn, eval_steps, metric_fn, init_checkpoint, custom_callbacks, run_eagerly, sub_model_export_name, explicit_allreduce, pre_allreduce_callbacks, post_allreduce_callbacks)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# To correctly place the model weights on accelerators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# model and optimizer should be created in scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       raise ValueError('User should set optimizer attribute to model '\n",
      "\u001b[0;32m<ipython-input-114-71fcfd2258d0>\u001b[0m in \u001b[0;36m_get_classifier_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                                   \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                   \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                                                    hub_module_url=albert_hub_url)\n\u001b[0m\u001b[1;32m     32\u001b[0m         classifier_model.optimizer = optimization.create_optimizer(init_lr=initial_lr,\n\u001b[1;32m     33\u001b[0m                                                                    \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-2662d067a25b>\u001b[0m in \u001b[0;36mcombine_model\u001b[0;34m(bert_config, float_type, num_labels, max_seq_length, final_layer_initializer, hub_module_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcombine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_part1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_part3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_layer_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-0556aeefba5b>\u001b[0m in \u001b[0;36mget_model_bert\u001b[0;34m(bert_config, float_type, num_labels, max_seq_length, final_layer_initializer, hub_module_url, input_ids, input_mask, segment_ids)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     pooled_output,_ = bert_model(inputs = [input_ids,input_mask,segment_ids])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     pooled_output,temp = bert_model(inputs = {'input_ids':input_ids,'input_mask':input_mask,'segment_ids':segment_ids})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'segment_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#     output = tf.keras.layers.Dropout(rate = bert_config.hidden_dropout_prob)(pooled_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     pooled_output = bert_outputs['pooled_output']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:206 call  *\n        self._check_trainability()\n    /opt/custom/python/anaconda3/envs/tf2.2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:265 _check_trainability  *\n        raise ValueError(\n\n    ValueError: Setting hub.KerasLayer.trainable = True is unsupported when loading from the hub.Module format of TensorFlow 1.\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_bert_classifier(\n",
    "      strategy,\n",
    "      albert_config,\n",
    "      input_meta_data,\n",
    "      albert_model_dir,\n",
    "      epochs,\n",
    "      steps_per_epoch,\n",
    "      steps_per_loop,\n",
    "      eval_steps,\n",
    "      warmup_steps,\n",
    "      learning_rate,\n",
    "      init_checkpoint,\n",
    "      train_input_fn,\n",
    "      eval_input_fn,\n",
    "      run_eagerly=False,\n",
    "      use_keras_compile_fit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-81e796e74545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    634\u001b[0m                     use_multiprocessing=False):\n\u001b[1;32m    635\u001b[0m   \u001b[0;34m\"\"\"Process the inputs for fit/eval/predict().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m   standardize = functools.partial(\n\u001b[1;32m    638\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 998\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    999\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "trained_model.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn():\n",
    "    return tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy',dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_input_fn,model):\n",
    "    eval_iter = iter(strategy.experimental_distribute_datasets_from_function(eval_input_fn))\n",
    "    \n",
    "    def _test_step_fn(inputs,label):\n",
    "#         inputs,label = inputs\n",
    "        model_outputs = model(inputs,training=False)\n",
    "        metric.update_state(label,model_outputs)\n",
    "    strategy.experimental_run_v2(_test_step_fn,args=(next(eval_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(eval_input_fn,trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.125>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_export_dir = '/var/extra/users/jgeorge/tf2.0/input/albert_base_custom/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model = os.path.join(model_dir, \"assets\", \"30k-clean.model\")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(spm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.sp_model_file = tf.saved_model.Asset(spm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.tracking.Asset at 0x7f54e0bc8310>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.sp_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/extra/users/jgeorge/tf2.0/input/albert_base_custom/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/extra/users/jgeorge/tf2.0/input/albert_base_custom/assets\n"
     ]
    }
   ],
   "source": [
    "trained_model.save(model_export_dir,include_optimizer=False,save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.125>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown signature default in https://tfhub.dev/google/albert_base/2 (available signatures: _SignatureMap({'tokenization_info': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f550be41450>, 'mlm': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f57ec038a50>, 'tokens': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f55086cf990>})).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-a847214142b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbert_hub_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                        \"a signature (or using a legacy Hub.Module).\")\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m_get_callable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signature\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       raise ValueError(\"Unknown signature %s in %s (available signatures: %s).\"\n\u001b[0;32m--> 250\u001b[0;31m                        % (self._signature, self._handle, self._func.signatures))\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown signature default in https://tfhub.dev/google/albert_base/2 (available signatures: _SignatureMap({'tokenization_info': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f550be41450>, 'mlm': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f57ec038a50>, 'tokens': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f55086cf990>}))."
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(albert_hub_url,trainable=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(albert_hub_url,trainable=True,signature='tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:209 call  *\n        result = f()\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1551 __call__  *\n        return self._call_impl(args, kwargs)\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1570 _call_impl\n        ).format(self._num_positional_args, self._arg_keywords, args))\n\n    TypeError: Expected at most 0 positional arguments (and the rest keywords, of ['segment_ids', 'input_ids', 'input_mask']), got ([<tf.Tensor 'segment_ids:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'input_ids:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'input_mask:0' shape=(None, 128) dtype=int32>],). When calling a concrete function, positional arguments may not be bound to Tensors within nested structures.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-49c96daf56c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       use_keras_compile_fit=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-6373bbe5532a>\u001b[0m in \u001b[0;36mrun_bert_classifier\u001b[0;34m(strategy, bert_config, input_meta_data, model_dir, epochs, steps_per_epoch, steps_per_loop, eval_steps, warmup_steps, initial_lr, init_checkpoint, train_input_fn, eval_input_fn, custom_callbacks, run_eagerly, use_keras_compile_fit)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                               \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                               \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                                hub_module_url=albert_hub_url)\n\u001b[0m\u001b[1;32m     26\u001b[0m     classifier_model.optimizer = optimization.create_optimizer(init_lr=initial_lr,\n\u001b[1;32m     27\u001b[0m                                                                \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-fef5ea442f65>\u001b[0m in \u001b[0;36mget_classifier_model\u001b[0;34m(bert_config, float_type, num_labels, max_seq_length, final_layer_initializer, hub_module_url)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbert_hub_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignature_outputs_as_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     pooled_output,_ = bert_model([input_word_ids,input_mask,input_type_ids])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dropout_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:209 call  *\n        result = f()\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1551 __call__  *\n        return self._call_impl(args, kwargs)\n    /opt/custom/python/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1570 _call_impl\n        ).format(self._num_positional_args, self._arg_keywords, args))\n\n    TypeError: Expected at most 0 positional arguments (and the rest keywords, of ['segment_ids', 'input_ids', 'input_mask']), got ([<tf.Tensor 'segment_ids:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'input_ids:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'input_mask:0' shape=(None, 128) dtype=int32>],). When calling a concrete function, positional arguments may not be bound to Tensors within nested structures.\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_bert_classifier(\n",
    "      strategy,\n",
    "      bert_config,\n",
    "      input_meta_data,\n",
    "      albert_model_dir,\n",
    "      epochs,\n",
    "      steps_per_epoch,\n",
    "      steps_per_loop,\n",
    "      eval_steps,\n",
    "      warmup_steps,\n",
    "      learning_rate,\n",
    "      init_checkpoint,\n",
    "      train_input_fn,\n",
    "      eval_input_fn,\n",
    "      run_eagerly=False,\n",
    "      use_keras_compile_fit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set()\n",
    "tags.add('train')\n",
    "\n",
    "loaded_albert_model = tf.saved_model.load(albert_model_dir,tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'mlm': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f551de1d9d0>, 'tokens': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f551d98e090>, 'tokenization_info': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f551d5d5050>})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_albert_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.wrap_function.WrappedFunction at 0x7f551de1d9d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_albert_model.signatures['mlm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.keras.utils.register_keras_serializable(package=\"Text\")\n",
    "#keeping one with print statements\n",
    "class SentencepieceTokenization2(tf.keras.layers.Layer):\n",
    "#     def __init__(self,model_proto):\n",
    "    def __init__(self,model_path):\n",
    "#         super(SentencepieceTokenization, self).__init__(trainable=False,dynamic=True,dtype=tf.int32)\n",
    "        super(SentencepieceTokenization, self).__init__(trainable=False,dtype=tf.int32)\n",
    "        #     self.sp_model_proto = model_proto\n",
    "#         self.model_path = tf.saved_model.Asset(model_path)\n",
    "        self.model_path = model_path\n",
    "        \n",
    "#         model_proto = tf.io.gfile.GFile(self.model_path, 'rb').read()\n",
    "#         self.sp_model = tftext.SentencepieceTokenizer(model=model_proto)\n",
    "    def build(self,input_shape):\n",
    "#         self.model_proto = tf.io.gfile.GFile(self.model_path.asset_path, 'rb').read()\n",
    "#         self.model_proto = tf.io.gfile.GFile(self.model_path, 'rb').read()\n",
    "#         self.sp_model = tftext.SentencepieceTokenizer(model=self.model_proto)\n",
    "        ## pad_id is usually 0 \n",
    "        [self.CLS_ID,self.SEP_ID,self.PAD_ID]  = tfs.piece_to_id(['[CLS]','[SEP]','<pad>'],model_file=self.model_path)\n",
    "        self.built=True\n",
    "        \n",
    "#     @tf.function    \n",
    "    def call(self, input_text):\n",
    "#         encoded_text = self.sp_model.tokenize(input_text).to_tensor()\n",
    "        ##tensorflow sentence piece works while exporting to graph while, tf_text sentencepiece doesn't\n",
    "#         encoded_text = tfs.encode(input_text,model_proto=self.model_proto)\n",
    "        model_proto = tf.io.gfile.GFile(self.model_path, 'rb').read()\n",
    "        encoded_text = self.get_encoded_text(input_text,model_proto=model_proto,max_sequence_length=20)\n",
    "        \n",
    "#         encoded_text = tf.RaggedTensor.from_tensor(encoded_text.values)\n",
    "#         return encoded_text.to_tensor()        \n",
    "        return encoded_text\n",
    "\n",
    "\n",
    "    def get_encoded_text(self,input_text_batch,model_proto,max_sequence_length):\n",
    "#         tf.print(\"input_text_batch is \",input_text_batch)\n",
    "#         tf.print(\"type of input_text_batch \",type(input_text_batch))\n",
    "\n",
    "        def process_invidual_line_encoding(x):\n",
    "#             tf sentencepiece requires a list as input, while the individual value that we get here\n",
    "#             is a single sentence, so adding one more dimension (i.e adding batch dimension = 1)\n",
    "            list_x = tf.expand_dims(x,axis=0)\n",
    "            sp_encoded = tfs.encode(list_x,model_proto=model_proto)\n",
    "    #         removing the batch dim with size=1 (which we added in the previous step)\n",
    "            values = tf.squeeze(sp_encoded.values,name='squeezed_values')\n",
    "            sequence_length = tf.squeeze(sp_encoded.sequence_length)\n",
    "#             tf.print('squeezed_values ' ,values)\n",
    "    #         trimming to max_length-2 (-2 to incorporate [CLS], [SEP])\n",
    "            trimmed_max_length = max_sequence_length-2\n",
    "    #         values_trimmed = tf.slice(values,begin=[0],size=[trimmed_max_length],name='trimmed_out')\n",
    "            values_trimmed = tf.cond(tf.greater(sequence_length,trimmed_max_length), \n",
    "                                    lambda : tf.slice(values,begin=[0],size=[trimmed_max_length],name='trimmed_out'),lambda : values)\n",
    "#             tf.print('values_trimmed ',values_trimmed)\n",
    "            concat = tf.concat([[self.CLS_ID],values_trimmed,[self.SEP_ID]],axis=0,name='concat_out')\n",
    "#             tf.print('concat_out ',concat)\n",
    "#             tf.print('size of concat ',tf.size(concat))\n",
    "#             tf.print('shape of concat ',tf.shape(concat))\n",
    "    #         actual_token_length = tf.size(concat) #this would also work since we are processing line by line in this function\n",
    "            # tf.shape dynamic shape & variable.shape = static shape with dynamic entries = None\n",
    "            actual_token_length = tf.shape(concat)[-1]\n",
    "    #         need not prepend anything so 0 for 1st entry in padding, \n",
    "    #         & next value for padding is how many dimensions required at the end of tensor\n",
    "            padded = tf.pad(concat,paddings=[[0,max_sequence_length-actual_token_length]],name='input_ids')\n",
    "    #         segment_ids = tf.zeros(shape=tf.shape(padded),dtype=tf.int32)\n",
    "    #         or\n",
    "            segment_ids = tf.zeros_like(padded,dtype=tf.int32,name='segment_ids')\n",
    "\n",
    "            input_mask = tf.scatter_nd(indices=tf.expand_dims(tf.range(0,actual_token_length),axis=1),\n",
    "                                       updates=tf.ones(shape=[actual_token_length],dtype=tf.int32),\n",
    "                                       shape=[max_sequence_length],name='input_mask')\n",
    "            return (padded,segment_ids,input_mask)\n",
    "    #     Issue running map_fn on gpu https://github.com/tensorflow/tensorflow/issues/28007 \n",
    "    #     https://www.tensorflow.org/api_docs/python/tf/device\n",
    "        with tf.device('/device:CPU:0'):\n",
    "            encoded = tf.map_fn(lambda x: process_invidual_line_encoding(x),input_text_batch,dtype=(tf.int32,tf.int32,tf.int32))\n",
    "#         tf.print('encoded map_fn ',encoded)\n",
    "#         tf.print('encoded map_fn type ',type(encoded))\n",
    "#         tf.print('encoded map_fn shape ',tf.shape(encoded))\n",
    "    #     stacked = tf.stack(encoded)\n",
    "        stacked = encoded\n",
    "#         tf.print('stacked size ',tf.size(stacked))\n",
    "#         tf.print('stacked shape ',tf.shape(stacked))\n",
    "        return stacked\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(SentencepieceTokenization, self).get_config()\n",
    "        config.update({'model_path': self.model_path})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "[CLS_ID,SEP_ID]  = tfs.piece_to_id(['[CLS]','[SEP]'],model_proto=sp_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 0], dtype=int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.piece_to_id(['[CLS]','[SEP]','<pad>'],model_proto=sp_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(CLS_ID,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.repeat(CLS_ID,repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[2],\n",
       "       [2]], dtype=int32)>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.repeat(CLS_ID,repeats=tf.shape(encoded.values)[0]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[2],\n",
       "       [2]], dtype=int32)>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.broadcast_to(CLS_ID,(tf.shape(encoded.values)[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(encoded.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tile()\n",
    "tf.stack()\n",
    "tf.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[4148,   48,   25,   21, 1289, 5123,    2],\n",
       "       [ 328, 1289, 5123,    0,    0,    0,    2]], dtype=int32)>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([encoded.values,tf.expand_dims(tf.repeat(CLS_ID,repeats=2),axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentencepieceEncodeDense(values=<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[4148,   48,   25,   21, 1289, 5123],\n",
       "       [ 328, 1289, 5123,    0,    0,    0]], dtype=int32)>, sequence_length=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 3], dtype=int32)>)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tfs.encode(['hi this is a test sentence','next test sentence'],model_proto=sp_model_proto)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[4148,   48,   25,   21, 1289, 5123]], dtype=int32)>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_single = tfs.encode(['next test sentence'],model_proto=sp_model_proto)\n",
    "tf.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = ['hi this is a test sentence','next test sentence']\n",
    "e_sparse  = tfs.encode_sparse(sample_sentences,model_proto=sp_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[4148,   48,   25,   21, 1289, 5123],\n",
       "       [ 328, 1289, 5123,    0,    0,    0]], dtype=int32)>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=string, numpy=\n",
       "array([[b'\\xe2\\x96\\x81hi', b'\\xe2\\x96\\x81this', b'\\xe2\\x96\\x81is',\n",
       "        b'\\xe2\\x96\\x81a', b'\\xe2\\x96\\x81test', b'\\xe2\\x96\\x81sentence'],\n",
       "       [b'\\xe2\\x96\\x81next', b'\\xe2\\x96\\x81test',\n",
       "        b'\\xe2\\x96\\x81sentence', b'<pad>', b'<pad>', b'<pad>']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.id_to_piece(encoded.values.numpy(),model_proto=sp_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[4148, 48, 25, 21, 1289, 5123], [328, 1289, 5123]]>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp3 = tftext.SentencepieceTokenizer(model=sp_model_proto)\n",
    "encoded_text3 = sp3.tokenize(sample_sentences)\n",
    "encoded_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentencepieceEncodeDense(values=<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[4148,   48,   25,   21, 1289, 5123],\n",
       "       [ 328, 1289, 5123,    0,    0,    0]], dtype=int32)>, sequence_length=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 3], dtype=int32)>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tfs.encode(['hi this is a test sentence','next test sentence'],model_proto=sp_model_proto)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[4148,   48,   25,   21, 1289, 5123]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[ 328, 1289, 5123,    0,    0,    0]], dtype=int32)>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.split(encoded.values,num_or_size_splits=encoded.values.shape[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       "array([[   2, 4148,   48,   25,   21, 1289, 5123,    3],\n",
       "       [   2,  328, 1289, 5123,    0,    0,    0,    3]], dtype=int32)>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_values(CLS_ID,encoded.values,SEP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenated_values(CLS_ID,encoded_values,SEP_ID):\n",
    "    batch_size = encoded_values.shape[0]\n",
    "#     Note that we are not using tf.shape to get the shape as it doesn't get the runtime shape\n",
    "#     batch_size = tf.shape(encoded_values)[0]\n",
    "    ##we need the CLS_ID to be prepended & SEP_ID to be appended to encoded_values from sentence_piece\n",
    "    ## the encoded_values have shape = (batch_size,sequence_length)\n",
    "    \n",
    "    ## to concat values we need all dimension except the ones where are concat is happening to be the same\n",
    "    ## here it is 2d with 1st dimension being batch_size, so getting tensors of shape (batch_size,1)\n",
    "    CLS_IDS = tf.broadcast_to(CLS_ID,(batch_size,1))\n",
    "    SEP_IDS = tf.broadcast_to(SEP_ID,(batch_size,1))\n",
    "#     or another way to get shape = (batch_size,1)\n",
    "#     CLS_IDS = tf.expand_dims(tf.repeat(CLS_ID,repeats=batch_size),axis=1)\n",
    "#     SEP_IDS = tf.expand_dims(tf.repeat(SEP_ID,repeats=batch_size),axis=1)\n",
    "\n",
    "    return tf.concat([CLS_IDS,encoded_values,SEP_IDS],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       "array([[   2, 4148,   48,   25,   21, 1289, 5123,    3],\n",
       "       [   2,  328, 1289, 5123,    0,    0,    0,    3]], dtype=int32)>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_values(CLS_ID,encoded.values,SEP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, None, 10) dtype=float32>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.keras.layers.Input((None, 10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, None, 10])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - tensorflow 2.2 (tf2.2)",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
